#+TITLE:Disentangle Things
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* Download
- [[/lib/disentangle_1.0.zip][Windows Version is Downloadable Here]]
- Linux and Mac users can just run this R code
#+begin_src R :session *R* :eval no
  require(devtools)
  install_github("disentangle", "ivanhanigan")
#+end_src


* Introduction
This project is my collection of notes and customised software tools for data management, manipulation and analysis.

#+name:install-tools
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
  ################################################################
  # devtools is recommended
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
#+end_src
** DESCRIPTION-code
#+name:DESCRIPTION
#+begin_src R :session *R* :tangle DESCRIPTION :exports none :eval no :padline no
Package: Disentangle
Type: Package
Title: Disentangle
Version: 1.1
Date: 2014-03-26
Author: ivanhanigan
Maintainer: <ivan.hanigan@gmail.com>
Depends: ggmap, maps, maptools, rgdal
Description:  Functions I modified or created.
License: GPL (>= 2)
#+end_src

* Test Data
** COMMENT blog-test-data-for-classification-trees
#+name:test-data-for-classification
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-test-data-for-classification-trees.md :exports none :eval no :padline no
  ---
  name: test-data-for-classification-trees
  layout: post
  title: test-data-for-classification-trees
  date: 2013-10-10
  categories:
  - Data Documentation
  ---
#+end_src
** Test Data for Classification Trees
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-test-data-for-classification-trees.md :exports reports :eval no :padline no
  
  #### A fictitious sample dataset
  For discussion, I'll use a fictional example dataset that I'm using to work through some statistical theory related to Classification and Regression Trees (CART).
  In the motivating example use case we are interested in predicting the civil status (married, single, divorced/widowed) of individuals from their sex (male, female) and sector of activity (primary, secondary, tertiary). The data set is composed of 273 cases.
  
  The data (and related statistical theory) come from:
  
  - Ritschard, G. (2006). Computing and using the deviance with classification trees. In Compstat 2006 - Proceedings in Computational Statistics 17th Symposium Held in Rome, Italy, 2006. Retrieved from [This Link](http://mephisto.unige.ch/pub/publications/gr/ritschard_compstat06.pdf)
  
  - Ritschard, G., Pisetta, V., & Zighed, D. (2008). Inducing and evaluating classification trees with statistical implicative criteria. Statistical Implicative Analysis. Studies in Computational Intelligence Volume 127, pp 397-419. Retrieved from [This Link](http://mephisto.unige.ch/pub/publications/gr/ritsch-pisetta-zighed_bookGras_rev.pdf)
  
  #### Code:
      # copy and paste the data from the PDF (Table 1 in both papers)
      civst_gend_sector  <- read.csv(textConnection(
          "civil_status gender activity_sector number_of_cases
               married   male         primary              50
               married   male       secondary              40
               married   male        tertiary               6
               married female         primary               0
               married female       secondary              14
               married female        tertiary              10
                single   male         primary               5
                single   male       secondary               5
                single   male        tertiary              12
                single female         primary              50
                single female       secondary              30
                single female        tertiary              18
      divorced/widowed   male         primary               5
      divorced/widowed   male       secondary               8
      divorced/widowed   male        tertiary              10
      divorced/widowed female         primary               6
      divorced/widowed female       secondary               2
      divorced/widowed female        tertiary               2
      "),sep = "")
  
      # save this to my personal R utilities package "disentangle" 
      # for use later when I am exploring functions
      dir.create("inst/extdata", recursive=T)
      write.csv(civst_gend_sector, "inst/extdata/civst_gend_sector.csv", row.names = F)
  
  <p></p>
  
  That is fine and good, we can use the case weights option to include number of cases but sometimes we want to use one row per person.
  In the next chunk of code I;ll reformat the data, and also add another fictitious variable called income and contrive an example where a certain group earns less based on their activity sector.
  
  #### Code:
      df <- as.data.frame(matrix(NA, nrow = 0, ncol = 3))
      for(i in 1:nrow(civst_gend_sector))
          {
          #    i <- 1
              n <- civst_gend_sector$number_of_cases[i]
              if(n == 0) next
              for(j in 1:n)
                  {
                    df <- rbind(df, civst_gend_sector[i,1:3])              
                  }
       
          }
  
      df$income  <- rnorm(nrow(df), 1000,200)
      # Let us say secondary men earn less
      df$income[df$gender == "male" & df$activity == "secondary"]  <- df$income[df$gender == "male" & df$activity == "secondary"] - 500
      str(df)
      # save this for use later
      write.csv(df, "inst/extdata/civst_gend_sector_full.csv", row.names = F)
  
  #### Motivating reason for using these data
  Classification and Regression Tree models (also referred to as Decision Trees) are one of the building blocks of data mining and a great tool for Exploratory Data Analysis.
  
  I've mostly used Regression Trees in the past but recently got some work with social science data where Classification Trees were needed.  I wanted to assess the deviance as well as the misclassification error rate for measuring the descriptive power of the tree.  While this is a easy with Regression Trees it became obvious that it was not so easy with Classification Trees.  This is because Classification Trees are most often evaluated by means of the error rate. The problem with the error rate is that it is not that helpful for assessing the descriptive capacity of the tree.
  
  For example if we look at the reduction in deviance between the Null model and the fitted tree we can say that the tree explains about XYZ% of the variation. We can also test if this is a statistically significant reduction based on a chi-squared test.
  
  Consider this example from page 310 of Hastie, T., Tibshirani, R., & Friedman, J. (2001). The elements of statistical learning. 2nd Edition:
  
  - in a two-class problem with 400 observations in each class (denote this by (400, 400))
  - suppose one split created nodes (300, 100) and (100, 300), 
  - the other created nodes (200, 400) and (200, 0). 
  - Both splits produce a misclassification rate of 0.25, but the second split produces a pure node and is probably preferable.
  
  During the course of my research to try to identify the best available method to implement in my analysis I found a useful series of papers by Ritschard, with a worked example using SPSS.  I hope to translate that to R in the future, but the first thing I did was grab the example data used in several of those papers out of the PDF.  So seeing as this was a public dataset (I use a lot of restricted data) and because I want to be able to use it to demonstrate the use of any R functions I find or write... I thought would publish it properly.  
  
  #### The Tree Model
  So just before we leave Ritschard and the CART method, let's just fit the model.  Let's also install my R utilities package "disentangle", to test that we can access the data from it.
  
  In this analysis the civil status is the outcome (or response or decision or dependent) variable, while sex and activity sector are the predictors (or condition or independent variables). 
  
  #### Code: 
      # func
      require(rpart)
      require(partykit) 
      require(devtools)
      install_github("disentangle", "ivanhanigan")
      
      # load
      fpath <- system.file(file.path("extdata", "civst_gend_sector.csv"),
                           package = "disentangle"
                           )
      civst_gend_sector <- read.csv(fpath)
  
      # clean
      str(civst_gend_sector)
      
      # do
      fit <- rpart(civil_status ~ gender + activity_sector,
                   data = civst_gend_sector, weights = number_of_cases,
                   control=rpart.control(minsplit=1))
      # NB need minsplit to be adjusted for weights.
      summary(fit)
        
      # report
      dir.create("images")
      png("images/fit1.png", 1000, 480)
      plot(as.party(fit))
      dev.off()
  
  #### The Result
#+end_src
** COMMENT tail
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-test-data-for-classification-trees.md :exports none :eval no :padline no

  ![fit1.png](/images/fit1.png)

#+end_src
* Data Input - Remote
** Database Connection
*** TODO connect2postgres
*** TODO connect2oracle
*** TODO libre office base to postgres
install base with software centre and 
sudo apt-get install libreoffice-sdbc-postgresql
http://dcparris.net/2012/07/06/connecting-libreoffice-to-postgresql-natively/
localhost didnt work but 127.0.0.1 did
*** kexi
using software centre
kexi and
kexi-postgresql-driver
*** 2014-05-10-ms-access-to-postgresql-in-64-bit-windows
#+name:ms-access-to-postgresql-in-64-bit-windows-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-05-10-ms-access-to-postgresql-in-64-bit-windows.md :exports none :eval no :padline no
---
name: ms-access-to-postgresql-in-64-bit-windows
layout: post
title: ms-access-to-postgresql-in-64-bit-windows
date: 2014-05-10
categories:
- research methods
---

- In 2011 we published a paper on "Creating an integrated historical record of extreme particulate air pollution events in australian cities from 1994 to 2007".
- I used a PostGIS/PostgreSQL server to host the database and MS Access clients for data entry by my co-author's at their own institutions (thousands of kms away) 
- This worked great but recently I realised that updating to windows 64 bit has broken the ODBC connection
- to fix it I followed the instructions [here](http://www.youlikeprogramming.com/2011/09/postgresql-and-odbc-in-64-bit-windows/)
- You need to install both the 32 and 64 bit executables
- Assuming you use the 32 bit windows office suite (recommended) then use the command below to open the ODBC connections tool and add a DSN for your postgres database

#### Code:
    Go to Start -> Run (or Press Windows+R keys) and enter 
    %WINDIR%\SysWOW64\odbcad32.exe
    
<p></p>

- On either the User DSN (DSNs available for only that user) or System DSN (DSNs available to every user) tab, click the Add button.
Scroll down the list and find the PostgreSQL ODBC Driver. 
- You may select ANSI or UNICODE (For future support I personally prefer UNICODE), and click Finish.
- Data Source refers to the programmable name of the DSN Entry. Stick to lower-case letters and underscores. Ex: psql_server
- Specify the Database, Server, User Name and Password to your PostgreSQL server.
- Click the Test button to ensure everything has been specified correctly.
- Click the Save button to create the DSN.

#+end_src

** Database Input
*** TODO readOGR2
*** PSQL dump and restore
#+name:psql-dump-restore
#+begin_src sh :tangle no :exports reports :eval no
  # name:psql-dump-restore
  "C:\Program Files\pgAdmin III\1.8\pg_dump.exe" -h ip_address -p 5432 -U user_name -F t -v -i -f "z:pathtobackup_file.backup" -t \"public\".\"table\" databaseName
  
  # Or for an entire schema
  
  "C:\Program Files\pgAdmin III\1.8\pg_dump.exe" -h ip_address -p 5432 -U user_name -F t -v -i -f "z:\path\to\backup_file.backup" -n \"public\" databaseName
  
  #You can dump and restore in a single line directly to your local postgres server
  
  pg_dump -h ip_address -U username -i -t schema.table weather | psql -h localhost postgis
  
  #You can dump and restore in a single line between databases
  
  "C:\Program Files\PostgreSQL\8.3\bin\pg_dump" -h ip_address -U username -i -t schema.table database | "C:\Program Files\PostgreSQL\8.3\bin\psql" -h ipaddress -U username database
  
  #To copy to a CSV file
  
  "C:\Program Files\PostgreSQL\8.3\bin\psql" -h ip_address -d weather -U username -c "COPY \"schema\".\"table\" TO STDOUT WITH CSV HEADER;" > "J:\workdir\filename.csv"
  
  "C:\Program Files\PostgreSQL\8.3\bin\psql" -h ip_address -d weather -U username -c "COPY (select * from schema.table where var = X) TO STDOUT WITH CSV HEADEsR;" > "J:\workdir\filename.csv"
#+end_src
* Data Input - Local
** Download File from HTTPS
*** download-file-https-code
#+name:download-file-https
#+begin_src R :session *R* :tangle no :exports reports :eval no
  # use method = curl
  download.file('https://alliance.anu.edu.au/access/content/group/4e0f55f1-b540-456a-000a-24730b59fccb/R%20Resources/Intro%20to%20R/timedata.csv',
                '~/timedata.csv',
                method ='curl'
                )
  timedata <- read.csv('~/timedata.csv')
#+end_src

** R-xls-read-all-worksheets-code
#+name:R-xls-read-all-worksheets
#+begin_src R :session *R* :tangle no :exports none :eval no
#### name:R-xls-read-all-worksheets####
# http://stackoverflow.com/questions/12945687/how-to-read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frame-e
require(XLConnect)
wb <- loadWorkbook("myBook.xlsx")
lst = readWorksheet(wb, sheet = getSheets(wb))
str(lst)

#+end_src

* Data Operation


** COMMENT R-data-munging-blog-posts
*** wickhams-tidy-tools-only-get-you-90-pct-the-way.md
#+name:wickhams-tidy-tools-only-get-you-90-pct-the-way-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way.md :exports none :eval no :padline no
---
name: 2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way
layout: post
title: wickhams-tidy-tools-only-get-you-90-pct-the-way
date: 2013-10-10
categories:
- research methods
---

#### Hadley Wickham's tidy tools
In this video at 8 mins 50 seconds he says "these four tools do 90% of the job" 

- subset, 
- transform, 
- summarise, and 
- arrange
- TODO I noticed [at the website for an Rstudio  course](http://www.rstudio.com/training/curriculum/data-manipulation.html) transform has been replaced by mutate as one of the "four basic verbs of data manipulation".

<iframe src="//player.vimeo.com/video/33727555" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe> <p><a href="http://vimeo.com/33727555">Tidy Data</a> from <a href="http://vimeo.com/user2150538">Drew Conway</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

So I thought what's the other 10?  Here's a few contenders for my work:

- merge
- reshape::cast and reshape::melt
- unlist
- t() transpose
- sprintf or paste

<p></p>
#+end_src
** R-subset
#+name:R-subset
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way.md :exports reports :eval no :padline no
  #### R-subset
      # Filter rows by criteria
      subset(airquality, Temp > 90, select = c(Ozone, Temp))
  
      ## NB This is a convenience function intended for use interactively.  For
      ## programming it is better to use the standard subsetting functions like
      ## ‘[’, and in particular the non-standard evaluation of argument
      ## ‘subset’ can have unanticipated consequences.
  
      with(airquality,
           airquality[Temp > 90, c("Ozone", "Temp")]
           )
  
      # OR
  
      airquality[airquality$Temp > 90,  c("Ozone", "Temp")]
                                                                                 
#+end_src
** R-transform
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way.md :exports reports :eval no :padline no
  #### R-transform
      # New columns that are functions of other columns       
      df <- transform(airquality,
                      new = -Ozone,
                      Temp2 = (Temp-32)/1.8
                      )
      head(df)
  

#+end_src
** R-mutate
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way.md :exports reports :eval no :padline no
  #### R-mutate
      require(plyr)
      # same thing as transform
      df <- mutate(airquality, new = -Ozone, Temp = (Temp - 32) / 1.8)    
      # Things transform can't do
      df <- mutate(airquality, Temp = (Temp - 32) / 1.8, OzT = Ozone / Temp)
      
      # mutate is rather faster than transform
      system.time(transform(baseball, avg_ab = ab / g))
      system.time(mutate(baseball, avg_ab = ab / g))

#+end_src       
** R-summarise
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way.md :exports reports :eval no :padline no
  #### R-summarise
      # New data.frame where columns are functions of existing columns
      require(plyr)    
      df <- ddply(.data = airquality,
                  .variables = "Month",
                  .fun = summarise,
                  tmax = max(Temp),
                  tav = mean(Temp),
                  ndays = length(unique(Day))
                  )
      head(df)
  
  #### Passing variables to ddply for summary
      # Notice how the name of the variable Temp doesn't need quotes?
      # this means that you need to hard code the names
      # But if you want to pass variables to this inside a function we need a
      # different approach.
  
      summarise_df  <- function(x, by, var1, var2, var3)
        {
          data_out <- ddply(x,
                            by,
                            function(df) return(
                              c(
                                tmax = max(df[,var1]),
                                tav = mean(df[,var2]),
                                ndays = length(unique(df[,var3]))
                                )
                              )
                            )
          return(data_out)
        }
  
      df2 <- summarise_df(x = airquality, by = "Month",
                         var1 = "Temp", var2 = "Temp", var3 = "Day"
                         )
      
      head(df2)
      all.equal(df,df2)
      # TRUE
  
  #### Another alternative, if we want to pass the dataset as string too
      summarise_df2  <- function(x, by, var1, var2, var3)
        {
          data_out <- eval(
            parse(
              text =
              sprintf(
                "ddply(.data = %s,
                  .variables = '%s',
                  .fun = summarise,
                  tmax = max(%s),
                  tav = mean(%s),
                  ndays = length(unique(%s))
                  )", x, by, var1, var2, var3
                )
              )
            )
          return(data_out)
        }
  
      df3 <- summarise_df2(x = "airquality", by = "Month",
                           var1 = "Temp", var2 = "Temp", var3 = "Day"
                           )
      head(df3)
      all.equal(df, df3)
      # TRUE
#+end_src
** R-arrange
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-10-wickhams-tidy-tools-only-get-you-90-pct-the-way.md :exports reports :eval no :padline no
  #### R-arrange
      # Re-order the rows of a data.frame
      df <- arrange(airquality, Temp, Ozone)
      head(df)
#+end_src

** R-upcase_string
*** R-upcase_string
#+name:upcase_string
#+begin_src R :session *R* :tangle R/upcase_string.r :exports none :eval no
  # name:upcase_string
  upcase_string <- function(x, tosplit = " ") {
    s <- strsplit(x, tosplit)[[1]]
    paste(toupper(substring(s, 1,1)), substring(s, 2),
        sep="", collapse=tosplit)
  }
#+end_src
*** test-upcase_string
#+name:upcase_string
#+begin_src R :session *R* :tangle tests/test-upcase_string.r :exports none :eval no
  # name:upcase_strin
  require(devtools)
  install_github("disentangle","ivanhanigan")
  require(disentangle)
  x <- c("The", "quick", "Brown", "fox/lazy dog")
  sapply(x, upcase_string)
  sapply(x, upcase_string, tosplit = "/")
  
#+end_src
*** man-upcase_string
#+name:upcase_string
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:upcase_string

#+end_src

*** blog
#+name:r-upcase-string-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-17-really-useful-r-upcase-string.md :exports none :eval no :padline no
  ---
  name: 2013-11-17-really-useful-r-upcase-string
  layout: post
  title: really-useful-r-upcase-string
  date: 2013-11-17
  categories:
  - research methods
  ---
  
  Here is a really useful R snippet from  [http://stackoverflow.com/a/6364905](http://stackoverflow.com/a/6364905) with a minor modification to allow differnt splits
  
  #### Code:r-upcase-string
      x <- c("The", "quick", "Brown", "fox/lazy dog")
       
      simpleCap <- function(x, tosplit = " ") {
        s <- strsplit(x, tosplit)[[1]]
        paste(toupper(substring(s, 1,1)), substring(s, 2),
            sep="", collapse=tosplit)
      }
      sapply(x, simpleCap)
      sapply(x, simpleCap, tosplit = "/")
  
  
  
      
#+end_src

** R-levenshtein
*** R-levenshtein
#+name:levenshtein
#+begin_src R :session *R* :tangle R/levenshtein.r :exports none :eval no
  ################################################################
  # name:levenshtein
  levenshtein <- function(string1, string2, case=TRUE, map=NULL) {
          if(!is.null(map)) {
                  m <- matrix(map, ncol=2, byrow=TRUE)
                  s <- c(ifelse(case, string1, tolower(string1)), ifelse(case, string2, tolower(string2)))
                  for(i in 1:dim(m)[1]) s <- gsub(m[i,1], m[i,2], s)
                  string1 <- s[1]
                  string2 <- s[2]
          }
   
          if(ifelse(case, string1, tolower(string1)) == ifelse(case, string2, tolower(string2))) return(1)
   
          s1 <- strsplit(paste(" ", ifelse(case, string1, tolower(string1)), sep=""), NULL)[[1]]
          s2 <- strsplit(paste(" ", ifelse(case, string2, tolower(string2)), sep=""), NULL)[[1]]
          
          l1 <- length(s1)
          l2 <- length(s2)
          
          d <- matrix(nrow = l1, ncol = l2)
   
          for(i in 1:l1) d[i,1] <- i-1
          for(i in 1:l2) d[1,i] <- i-1
          for(i in 2:l1) for(j in 2:l2) d[i,j] <- min((d[i-1,j]+1) , (d[i,j-1]+1) , (d[i-1,j-1]+ifelse(s1[i] == s2[j], 0, 1)))
          
          d[l1,l2]
          
          (max(l1,l2) - d[l1,l2]) / (max(l1,l2))
          
  }
  
  
#+end_src
*** test-levenshtein
#+name:levenshtein
#+begin_src R :session *R* :tangle tests/test-levenshtein.r :exports none :eval no
  ################################################################
  # name:levenshtein
  #debug(levenshtein)
  require(devtools)
  install_github("disentangle","ivanhanigan")
  require(disentangle)
  
  levenshtein("lazy","1 lasy")
#+end_src

*** COMMENT text2test-code
#+name:text2test
#+begin_src R :session *R* :tangle tests/test-levenshtein-text2test.r :exports none :eval yes
  # http://www.tintinologist.org/guides/lists/curses.html
  text2test  <- read.csv(textConnection("curse, ref
  Aardvark! 
  Abecedarians! 
  Aborigine! 
  Addle-pated lumps of anthracite! 
  (old) Alcoholic ! 
  Anachronisms! 
  Anacoluthons!
  Antediluvian bulldozer [Tibet p60 B2]!
  Anthracite!
  Anthropithecus!
  Anthropophagus!
  Arabian Nightmare!
  Artichokes!
  Autocrats!
  Aztecs! [15]
  Baboons!
  Baby-snatchers!
  Bagpipers!
  Bald-headed budgerigar!
  Bandits!
  Bashi-bazouks!
  Bath-tub Admiral!
  Beast!
  Belemnite!
  Big-head, [Tibet p35 B3]!
  Billions of blue blistering boiled and barbecued barnacles, [The Seven Crystal Balls, p14 frame 10]!
  Billions of billious barbecued blue blistering barnacles!
  Billions of Bilious Blue Blistering Barnacles!
  Billions of bilious blue blistering barnacles in a thundering typhoon, [The Seven Crystal Balls]!
  Billions of Blue Blistering Barnacles!
  Billions of blue bistering barnacles, Tibet 1967 on page 4 
  Billions of blistering barnacles in a thundering typhoon!, Tibet 1967 p11
  Black beetles!
  Black Marketers!
  Blackamoor! Blackbird!
  Blackguards!
  Blithering Bombardier!
  Blistering Barnacles!
  Blistereing blundering bird-brain [Prisoners p9 E4]!
  Bloodsuckers! Blue blistering barnacles!
  Blue Blistering Bell-Bottomed Balderdash!
  Blunderbuss!
  Bodysnatcher!
  Bootlegger!
  Borgia!
  Bougainvillea!
  Brat!
  Breathalyser!
  Brigands!
  Brutes!
  Bucaneers!
  Bully!
  Butcher! [37]
  Cachinnating cockatoo!
  Cannibals!
  Carpetsellers!
  Caterpillars!
  Centipede!
  Cercopithecus!
  Certified Diplodocuses, [Calculus Affair p30]!
  Coconut[Crab p58 panel 5]!
  Coelcanth!
  Colocynths!
  Corsair!
  Cowards!
  Crabapples!
  Cro-Magnon!
  Crooks!
  Cushion footed quadrupeds!
  Cyclotron! [17]
  Diplodocus!
  Dizzards [Unicorn p54 C1/frame 7]!
  Dogs!
  Doryphore!
  Doryphores!
  Duck-billed platypus!
  Dunderheaded coconuts!
  Dynamiter! [8]
  Ectoplasms!
  Egoists! [2]
  Fancy-dress Facist!
  Fancy-dress Fatima!
  Fancy-dress freebooter [Unicorn p24 C1]!
  Fatfaces!
  Filibuster(s)!
  Fourlegged Cyrano!
  Freshwater pirate [Unicorn p24 C1]!
  Freshwater swabs!
  Fuzzy wuzzy! [9]
  Gallows-fodder!
  Gangof Theives! Gangsters!
  Gibbering anthropoids!
  Great flat-footed grizzly bear!
  Gobbledgook!
  Gogglers!
  Goosecaps!
  Guano-gatherers [Prisoners p9 A1]!
  Gyroscope! [10]
  Harlequin!
  Heretic!
  Highwayman!
  Hydrocarbon! [4]
  Iconoclasts!
  Idiots!
  '... you, Imitation Incas, you', [Prisoners p47 B2]!
  'You, interplantary goat, you', [Explorers on the Moon p62 C3]! [4]
  Jellied eel!
  Jellyfish!
  Jobbernowl [Tibet p60 B2]! [3]
  Kleptomaniacs!
  Koua Kouakouin Kouinkouin Koua Kouin Koua [Emerald p30 panel 8]! [2]
  Lily-livered landlubbers!
  Liquorice[Crab p59 panel 2]!
  Loathsome brute!
  Logarithim!
  Lubberscum! [5]
  Macrocephalic baboon!
  Megacycle [Tibet p60 B3]!
  Megacycle Pyromaniac!
  Mameluke!
  Miserable blundering barbecued blister!
  Miserable earth worms!
  Miserable miser!
  Miserable molecule of mildew!
  Misguided missles!
  MisterMule!
  Monopolizers!
  Monster! Morons!
  Moujiks!
  Mountebanks!
  Musical morons! [16]
  Nanny Goat!
  Nitwits!
  Nitwitted ninepins!
  Nyctalops! [4]
  Odd-toed ungulate!
  Ophicleides!
  Orangoutang!
  Ostrogoth! [4]
  Pachyrhizus!
  Parasites!
  Patagonians!
  Pestilential Pachyderm!
  Phylloxera!
  Pickled herrings!
  Pirates!
  Pithecanthropic montebanks!
  Pithecanthropic pickpocket [Tibet p37 A3]!
  Pithecanthropus [Unicorn p24 C1]!
  Pockmarks!
  Politican!
  Poltroons!
  Polygraphs!
  Polynesian!
  Profiteers!
  Psychopath!
  Purple profiteering jellyfish!
  Pyrographers!
  Pyromaniac! [20]
  Raggle taggle ruminants!
  Rapscallion!
  Rats!
  Revenge [Crab p58 panel 4]!
  Rhizopods!
  RKRPXZKRMTFRZ!
  Road roller [Secret of the Unicorn]!
  Roadhogs! [8]  
  Saucy tramp!
  Savages!
  Scorpion!
  Sea-gherkin(s)!
  Sea-lice!
  Sea lion!, [Prisoners p9 frame 6]
  Shipwreckers!
  Slavertrader!
  Slubberdegullions!
  Sparrows!
  Spitfire!
  Steamroller!
  Stoolpigeon!
  Subtropical sea-louse!
  Swine! [15]
  Squawking popinjay, - in The Secret of the Unicorn on page 24 Captain Francis Haddock says it to Red Rackham--but since Captain Archibald Haddock is narrating this to Tintin some one may say that it is one of his many curse words. Also a parrot says it in Red Rackham's Treasure on page 29. [NAB]
  Technocrat!
  Ten thousand thundering typhoons!
  Terrapins!
  Terrorists!
  Thundering typhoons!
  Tin hatted tyrants!
  Toads!
  Toffee-noses!
  Traitors!
  Tramps!
  Tribe of Polynesians [Destination Moon p5 D1]!
  Troglodytes!
  Turncoats!
  Twister!
  Two-timing Troglodytes! [15]
  Ungulate (see O for odd-toed ungulate)
  Vandal!
  Vegetarian!
  Vermicellis!
  Viper!
  Visigoths!
  Vulture! [6]
  Weevils!
  Whippersnapper!
  Wildcat!
  Woodlice! [4]
  Young monkey [Tibet p54 A4]! [1]
  Zapotecs! [1]
  "), stringsAsFactor=F)
#+end_src

#+RESULTS: text2test
| Aardvark!                                                             |                                                                                                                                                                                                                                                                                      |
| Abecedarians!                                                         |                                                                                                                                                                                                                                                                                      |
| Aborigine!                                                            |                                                                                                                                                                                                                                                                                      |
| Addle-pated lumps of anthracite!                                      |                                                                                                                                                                                                                                                                                      |
| (old) Alcoholic !                                                     |                                                                                                                                                                                                                                                                                      |
| Anachronisms!                                                         |                                                                                                                                                                                                                                                                                      |
| Anacoluthons!                                                         |                                                                                                                                                                                                                                                                                      |
| Antediluvian bulldozer [Tibet p60 B2]!                                |                                                                                                                                                                                                                                                                                      |
| Anthracite!                                                           |                                                                                                                                                                                                                                                                                      |
| Anthropithecus!                                                       |                                                                                                                                                                                                                                                                                      |
| Anthropophagus!                                                       |                                                                                                                                                                                                                                                                                      |
| Arabian Nightmare!                                                    |                                                                                                                                                                                                                                                                                      |
| Artichokes!                                                           |                                                                                                                                                                                                                                                                                      |
| Autocrats!                                                            |                                                                                                                                                                                                                                                                                      |
| Aztecs! [15]                                                          |                                                                                                                                                                                                                                                                                      |
| Baboons!                                                              |                                                                                                                                                                                                                                                                                      |
| Baby-snatchers!                                                       |                                                                                                                                                                                                                                                                                      |
| Bagpipers!                                                            |                                                                                                                                                                                                                                                                                      |
| Bald-headed budgerigar!                                               |                                                                                                                                                                                                                                                                                      |
| Bandits!                                                              |                                                                                                                                                                                                                                                                                      |
| Bashi-bazouks!                                                        |                                                                                                                                                                                                                                                                                      |
| Bath-tub Admiral!                                                     |                                                                                                                                                                                                                                                                                      |
| Beast!                                                                |                                                                                                                                                                                                                                                                                      |
| Belemnite!                                                            |                                                                                                                                                                                                                                                                                      |
| Big-head                                                              | [Tibet p35 B3]!                                                                                                                                                                                                                                                                      |
| Billions of blue blistering boiled and barbecued barnacles            | [The Seven Crystal Balls                                                                                                                                                                                                                                                             |
| p14 frame 10]!                                                        |                                                                                                                                                                                                                                                                                      |
| Billions of billious barbecued blue blistering barnacles!             |                                                                                                                                                                                                                                                                                      |
| Billions of Bilious Blue Blistering Barnacles!                        |                                                                                                                                                                                                                                                                                      |
| Billions of bilious blue blistering barnacles in a thundering typhoon | [The Seven Crystal Balls]!                                                                                                                                                                                                                                                           |
| Billions of Blue Blistering Barnacles!                                |                                                                                                                                                                                                                                                                                      |
| Billions of blue bistering barnacles                                  | Tibet 1967 on page 4                                                                                                                                                                                                                                                                 |
| Billions of blistering barnacles in a thundering typhoon!             | Tibet 1967 p11                                                                                                                                                                                                                                                                       |
| Black beetles!                                                        |                                                                                                                                                                                                                                                                                      |
| Black Marketers!                                                      |                                                                                                                                                                                                                                                                                      |
| Blackamoor! Blackbird!                                                |                                                                                                                                                                                                                                                                                      |
| Blackguards!                                                          |                                                                                                                                                                                                                                                                                      |
| Blithering Bombardier!                                                |                                                                                                                                                                                                                                                                                      |
| Blistering Barnacles!                                                 |                                                                                                                                                                                                                                                                                      |
| Blistereing blundering bird-brain [Prisoners p9 E4]!                  |                                                                                                                                                                                                                                                                                      |
| Bloodsuckers! Blue blistering barnacles!                              |                                                                                                                                                                                                                                                                                      |
| Blue Blistering Bell-Bottomed Balderdash!                             |                                                                                                                                                                                                                                                                                      |
| Blunderbuss!                                                          |                                                                                                                                                                                                                                                                                      |
| Bodysnatcher!                                                         |                                                                                                                                                                                                                                                                                      |
| Bootlegger!                                                           |                                                                                                                                                                                                                                                                                      |
| Borgia!                                                               |                                                                                                                                                                                                                                                                                      |
| Bougainvillea!                                                        |                                                                                                                                                                                                                                                                                      |
| Brat!                                                                 |                                                                                                                                                                                                                                                                                      |
| Breathalyser!                                                         |                                                                                                                                                                                                                                                                                      |
| Brigands!                                                             |                                                                                                                                                                                                                                                                                      |
| Brutes!                                                               |                                                                                                                                                                                                                                                                                      |
| Bucaneers!                                                            |                                                                                                                                                                                                                                                                                      |
| Bully!                                                                |                                                                                                                                                                                                                                                                                      |
| Butcher! [37]                                                         |                                                                                                                                                                                                                                                                                      |
| Cachinnating cockatoo!                                                |                                                                                                                                                                                                                                                                                      |
| Cannibals!                                                            |                                                                                                                                                                                                                                                                                      |
| Carpetsellers!                                                        |                                                                                                                                                                                                                                                                                      |
| Caterpillars!                                                         |                                                                                                                                                                                                                                                                                      |
| Centipede!                                                            |                                                                                                                                                                                                                                                                                      |
| Cercopithecus!                                                        |                                                                                                                                                                                                                                                                                      |
| Certified Diplodocuses                                                | [Calculus Affair p30]!                                                                                                                                                                                                                                                               |
| Coconut[Crab p58 panel 5]!                                            |                                                                                                                                                                                                                                                                                      |
| Coelcanth!                                                            |                                                                                                                                                                                                                                                                                      |
| Colocynths!                                                           |                                                                                                                                                                                                                                                                                      |
| Corsair!                                                              |                                                                                                                                                                                                                                                                                      |
| Cowards!                                                              |                                                                                                                                                                                                                                                                                      |
| Crabapples!                                                           |                                                                                                                                                                                                                                                                                      |
| Cro-Magnon!                                                           |                                                                                                                                                                                                                                                                                      |
| Crooks!                                                               |                                                                                                                                                                                                                                                                                      |
| Cushion footed quadrupeds!                                            |                                                                                                                                                                                                                                                                                      |
| Cyclotron! [17]                                                       |                                                                                                                                                                                                                                                                                      |
| Diplodocus!                                                           |                                                                                                                                                                                                                                                                                      |
| Dizzards [Unicorn p54 C1/frame 7]!                                    |                                                                                                                                                                                                                                                                                      |
| Dogs!                                                                 |                                                                                                                                                                                                                                                                                      |
| Doryphore!                                                            |                                                                                                                                                                                                                                                                                      |
| Doryphores!                                                           |                                                                                                                                                                                                                                                                                      |
| Duck-billed platypus!                                                 |                                                                                                                                                                                                                                                                                      |
| Dunderheaded coconuts!                                                |                                                                                                                                                                                                                                                                                      |
| Dynamiter! [8]                                                        |                                                                                                                                                                                                                                                                                      |
| Ectoplasms!                                                           |                                                                                                                                                                                                                                                                                      |
| Egoists! [2]                                                          |                                                                                                                                                                                                                                                                                      |
| Fancy-dress Facist!                                                   |                                                                                                                                                                                                                                                                                      |
| Fancy-dress Fatima!                                                   |                                                                                                                                                                                                                                                                                      |
| Fancy-dress freebooter [Unicorn p24 C1]!                              |                                                                                                                                                                                                                                                                                      |
| Fatfaces!                                                             |                                                                                                                                                                                                                                                                                      |
| Filibuster(s)!                                                        |                                                                                                                                                                                                                                                                                      |
| Fourlegged Cyrano!                                                    |                                                                                                                                                                                                                                                                                      |
| Freshwater pirate [Unicorn p24 C1]!                                   |                                                                                                                                                                                                                                                                                      |
| Freshwater swabs!                                                     |                                                                                                                                                                                                                                                                                      |
| Fuzzy wuzzy! [9]                                                      |                                                                                                                                                                                                                                                                                      |
| Gallows-fodder!                                                       |                                                                                                                                                                                                                                                                                      |
| Gangof Theives! Gangsters!                                            |                                                                                                                                                                                                                                                                                      |
| Gibbering anthropoids!                                                |                                                                                                                                                                                                                                                                                      |
| Great flat-footed grizzly bear!                                       |                                                                                                                                                                                                                                                                                      |
| Gobbledgook!                                                          |                                                                                                                                                                                                                                                                                      |
| Gogglers!                                                             |                                                                                                                                                                                                                                                                                      |
| Goosecaps!                                                            |                                                                                                                                                                                                                                                                                      |
| Guano-gatherers [Prisoners p9 A1]!                                    |                                                                                                                                                                                                                                                                                      |
| Gyroscope! [10]                                                       |                                                                                                                                                                                                                                                                                      |
| Harlequin!                                                            |                                                                                                                                                                                                                                                                                      |
| Heretic!                                                              |                                                                                                                                                                                                                                                                                      |
| Highwayman!                                                           |                                                                                                                                                                                                                                                                                      |
| Hydrocarbon! [4]                                                      |                                                                                                                                                                                                                                                                                      |
| Iconoclasts!                                                          |                                                                                                                                                                                                                                                                                      |
| Idiots!                                                               |                                                                                                                                                                                                                                                                                      |
| '... you                                                              | Imitation Incas                                                                                                                                                                                                                                                                      |
| you'                                                                  | [Prisoners p47 B2]!                                                                                                                                                                                                                                                                  |
| 'You                                                                  | interplantary goat                                                                                                                                                                                                                                                                   |
| you'                                                                  | [Explorers on the Moon p62 C3]! [4]                                                                                                                                                                                                                                                  |
| Jellied eel!                                                          |                                                                                                                                                                                                                                                                                      |
| Jellyfish!                                                            |                                                                                                                                                                                                                                                                                      |
| Jobbernowl [Tibet p60 B2]! [3]                                        |                                                                                                                                                                                                                                                                                      |
| Kleptomaniacs!                                                        |                                                                                                                                                                                                                                                                                      |
| Koua Kouakouin Kouinkouin Koua Kouin Koua [Emerald p30 panel 8]! [2]  |                                                                                                                                                                                                                                                                                      |
| Lily-livered landlubbers!                                             |                                                                                                                                                                                                                                                                                      |
| Liquorice[Crab p59 panel 2]!                                          |                                                                                                                                                                                                                                                                                      |
| Loathsome brute!                                                      |                                                                                                                                                                                                                                                                                      |
| Logarithim!                                                           |                                                                                                                                                                                                                                                                                      |
| Lubberscum! [5]                                                       |                                                                                                                                                                                                                                                                                      |
| Macrocephalic baboon!                                                 |                                                                                                                                                                                                                                                                                      |
| Megacycle [Tibet p60 B3]!                                             |                                                                                                                                                                                                                                                                                      |
| Megacycle Pyromaniac!                                                 |                                                                                                                                                                                                                                                                                      |
| Mameluke!                                                             |                                                                                                                                                                                                                                                                                      |
| Miserable blundering barbecued blister!                               |                                                                                                                                                                                                                                                                                      |
| Miserable earth worms!                                                |                                                                                                                                                                                                                                                                                      |
| Miserable miser!                                                      |                                                                                                                                                                                                                                                                                      |
| Miserable molecule of mildew!                                         |                                                                                                                                                                                                                                                                                      |
| Misguided missles!                                                    |                                                                                                                                                                                                                                                                                      |
| MisterMule!                                                           |                                                                                                                                                                                                                                                                                      |
| Monopolizers!                                                         |                                                                                                                                                                                                                                                                                      |
| Monster! Morons!                                                      |                                                                                                                                                                                                                                                                                      |
| Moujiks!                                                              |                                                                                                                                                                                                                                                                                      |
| Mountebanks!                                                          |                                                                                                                                                                                                                                                                                      |
| Musical morons! [16]                                                  |                                                                                                                                                                                                                                                                                      |
| Nanny Goat!                                                           |                                                                                                                                                                                                                                                                                      |
| Nitwits!                                                              |                                                                                                                                                                                                                                                                                      |
| Nitwitted ninepins!                                                   |                                                                                                                                                                                                                                                                                      |
| Nyctalops! [4]                                                        |                                                                                                                                                                                                                                                                                      |
| Odd-toed ungulate!                                                    |                                                                                                                                                                                                                                                                                      |
| Ophicleides!                                                          |                                                                                                                                                                                                                                                                                      |
| Orangoutang!                                                          |                                                                                                                                                                                                                                                                                      |
| Ostrogoth! [4]                                                        |                                                                                                                                                                                                                                                                                      |
| Pachyrhizus!                                                          |                                                                                                                                                                                                                                                                                      |
| Parasites!                                                            |                                                                                                                                                                                                                                                                                      |
| Patagonians!                                                          |                                                                                                                                                                                                                                                                                      |
| Pestilential Pachyderm!                                               |                                                                                                                                                                                                                                                                                      |
| Phylloxera!                                                           |                                                                                                                                                                                                                                                                                      |
| Pickled herrings!                                                     |                                                                                                                                                                                                                                                                                      |
| Pirates!                                                              |                                                                                                                                                                                                                                                                                      |
| Pithecanthropic montebanks!                                           |                                                                                                                                                                                                                                                                                      |
| Pithecanthropic pickpocket [Tibet p37 A3]!                            |                                                                                                                                                                                                                                                                                      |
| Pithecanthropus [Unicorn p24 C1]!                                     |                                                                                                                                                                                                                                                                                      |
| Pockmarks!                                                            |                                                                                                                                                                                                                                                                                      |
| Politican!                                                            |                                                                                                                                                                                                                                                                                      |
| Poltroons!                                                            |                                                                                                                                                                                                                                                                                      |
| Polygraphs!                                                           |                                                                                                                                                                                                                                                                                      |
| Polynesian!                                                           |                                                                                                                                                                                                                                                                                      |
| Profiteers!                                                           |                                                                                                                                                                                                                                                                                      |
| Psychopath!                                                           |                                                                                                                                                                                                                                                                                      |
| Purple profiteering jellyfish!                                        |                                                                                                                                                                                                                                                                                      |
| Pyrographers!                                                         |                                                                                                                                                                                                                                                                                      |
| Pyromaniac! [20]                                                      |                                                                                                                                                                                                                                                                                      |
| Raggle taggle ruminants!                                              |                                                                                                                                                                                                                                                                                      |
| Rapscallion!                                                          |                                                                                                                                                                                                                                                                                      |
| Rats!                                                                 |                                                                                                                                                                                                                                                                                      |
| Revenge [Crab p58 panel 4]!                                           |                                                                                                                                                                                                                                                                                      |
| Rhizopods!                                                            |                                                                                                                                                                                                                                                                                      |
| RKRPXZKRMTFRZ!                                                        |                                                                                                                                                                                                                                                                                      |
| Road roller [Secret of the Unicorn]!                                  |                                                                                                                                                                                                                                                                                      |
| Roadhogs! [8]                                                         |                                                                                                                                                                                                                                                                                      |
| Saucy tramp!                                                          |                                                                                                                                                                                                                                                                                      |
| Savages!                                                              |                                                                                                                                                                                                                                                                                      |
| Scorpion!                                                             |                                                                                                                                                                                                                                                                                      |
| Sea-gherkin(s)!                                                       |                                                                                                                                                                                                                                                                                      |
| Sea-lice!                                                             |                                                                                                                                                                                                                                                                                      |
| Sea lion!                                                             | [Prisoners p9 frame 6]                                                                                                                                                                                                                                                               |
| Shipwreckers!                                                         |                                                                                                                                                                                                                                                                                      |
| Slavertrader!                                                         |                                                                                                                                                                                                                                                                                      |
| Slubberdegullions!                                                    |                                                                                                                                                                                                                                                                                      |
| Sparrows!                                                             |                                                                                                                                                                                                                                                                                      |
| Spitfire!                                                             |                                                                                                                                                                                                                                                                                      |
| Steamroller!                                                          |                                                                                                                                                                                                                                                                                      |
| Stoolpigeon!                                                          |                                                                                                                                                                                                                                                                                      |
| Subtropical sea-louse!                                                |                                                                                                                                                                                                                                                                                      |
| Swine! [15]                                                           |                                                                                                                                                                                                                                                                                      |
| Squawking popinjay                                                    | - in The Secret of the Unicorn on page 24 Captain Francis Haddock says it to Red Rackham--but since Captain Archibald Haddock is narrating this to Tintin some one may say that it is one of his many curse words. Also a parrot says it in Red Rackham's Treasure on page 29. [NAB] |
| Technocrat!                                                           |                                                                                                                                                                                                                                                                                      |
| Ten thousand thundering typhoons!                                     |                                                                                                                                                                                                                                                                                      |
| Terrapins!                                                            |                                                                                                                                                                                                                                                                                      |
| Terrorists!                                                           |                                                                                                                                                                                                                                                                                      |
| Thundering typhoons!                                                  |                                                                                                                                                                                                                                                                                      |
| Tin hatted tyrants!                                                   |                                                                                                                                                                                                                                                                                      |
| Toads!                                                                |                                                                                                                                                                                                                                                                                      |
| Toffee-noses!                                                         |                                                                                                                                                                                                                                                                                      |
| Traitors!                                                             |                                                                                                                                                                                                                                                                                      |
| Tramps!                                                               |                                                                                                                                                                                                                                                                                      |
| Tribe of Polynesians [Destination Moon p5 D1]!                        |                                                                                                                                                                                                                                                                                      |
| Troglodytes!                                                          |                                                                                                                                                                                                                                                                                      |
| Turncoats!                                                            |                                                                                                                                                                                                                                                                                      |
| Twister!                                                              |                                                                                                                                                                                                                                                                                      |
| Two-timing Troglodytes! [15]                                          |                                                                                                                                                                                                                                                                                      |
| Ungulate (see O for odd-toed ungulate)                                |                                                                                                                                                                                                                                                                                      |
| Vandal!                                                               |                                                                                                                                                                                                                                                                                      |
| Vegetarian!                                                           |                                                                                                                                                                                                                                                                                      |
| Vermicellis!                                                          |                                                                                                                                                                                                                                                                                      |
| Viper!                                                                |                                                                                                                                                                                                                                                                                      |
| Visigoths!                                                            |                                                                                                                                                                                                                                                                                      |
| Vulture! [6]                                                          |                                                                                                                                                                                                                                                                                      |
| Weevils!                                                              |                                                                                                                                                                                                                                                                                      |
| Whippersnapper!                                                       |                                                                                                                                                                                                                                                                                      |
| Wildcat!                                                              |                                                                                                                                                                                                                                                                                      |
| Woodlice! [4]                                                         |                                                                                                                                                                                                                                                                                      |
| Young monkey [Tibet p54 A4]! [1]                                      |                                                                                                                                                                                                                                                                                      |
| Zapotecs! [1]                                                         |                                                                                                                                                                                                                                                                                      |

*** test-stringdist-code
#+name:test-stringdist
#+begin_src R :session *R* :tangle tests/test-stringdist.r :exports none :eval no
  #### name:test-stringdist####
  require(disentangle)
  source("tests/test-levenshtein-text2test.r")
  test <- text2test[grep("barnacles", tolower(text2test[,1])),1]
  str(test)
  # get source and target
  matrix(test)
  test[5]
  z2 <- expand.grid(test[4], test, stringsAsFactors = F)
  list(z2)
  z2
  z <- z2
  mapply(z2,
         function(z) levenshtein(z[,1],z[,2]))
  list(test[1],
  test[-1])
  
  test <- tolower(test)
  i  <-  5
  cbind(test[i], test[-i],  (nchar(test[i]) - stringdist(test[i], test[-i])) / nchar(test[i]))
#+end_src

*** man-levenshtein
#+name:levenshtein
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:levenshtein
#http://rwiki.sciviews.org/doku.php?id=tips:data-strings:levenshtein
#http://wiki.r-project.org/rwiki/doku.php?id=tips:data-strings:levenshtein


#+end_src

** 2014-02-27-yearmon-class-and-interoperability-with-excel-and-access
#+name:yearmon-class-and-interoperability-with-excel-and-access-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-02-27-yearmon-class-and-interoperability-with-excel-and-access.md :exports none :eval no :padline no
  ---
  name: 2014-02-27-yearmon-class-and-interoperability-with-excel-and-access
  layout: post
  title: yearmon-class-and-interoperability-with-excel-and-access
  date: 2014-02-27
  categories:
  - research methods
  - Data Documentation
  ---
  
  
  #### Toward a standard and unambiguous format for sharing Year-Month data
    
  - I am working in a new job where we are recieving data from a lot of different groups
  - we aim to review these datasets and then publish them for a wide audience of potential users
  - therefore usability and interoperability is a key concern
  - we recieved some data with Month and Year as Apr.12
  - I know this is easy to convert to a date/time class with in R but wondered what a better format would be to recommend for our datasets to use to maximise utility downstream (especially for non R users)
  - Apr.12 is assumed to be text in excel so need something else
  - Apr-12 is assumed to be the twelfth of April this year (ie 12/4/2014)
  
  #### In R the solution might be to use the zoo package
      require(zoo)
      as.yearmon("Apr.12", "%b.%y")
      # [1] "Apr 2012"
  
      # other options abound
      as.yearmon("apr12", "%b%y")
  
      # the default is YYYY-MM or similar
      as.yearmon("2012-04")
      as.yearmon("2012-4")
  
  <p></p>
  
  - So I went looking at how Excel and Access deal with this
  - found that the best appeard to be MMM-YYYY in terms of how these software assume the data should look
  
  #### R Code:
      as.yearmon("Apr-2012", "%b-%Y")
  
      # but will need to specify format because otherwise fails
      as.yearmon("Apr-2012")
      # NA
  
  <p></p>
  
  #### Conclusion
  
  - I recommend the MMM-YYYY option
  - it is pretty good that in Excel it is assumed 1/04/2012 
  - and if MS access is set to date/time and format = mmm-yyyy is ok for data entry (but not importing)
  - to import this use a shorttext type, then post-import, change to date/time with mmm-yyyy (the . failed)
  
  
  
#+end_src


** TODO working-with-dates

#+name:working-with-dates
#+begin_src R :session *R* :tangle src/working-with-dates.r :exports none :eval no
#### name:working-with-dates####
http://stackoverflow.com/questions/15686451/dates-from-excel-to-r-platform-dependency

  Quoting `?as.Date'

  ## date given as number of days since 1900-01-01 (a date in 1989)
  as.Date(32768, origin = "1900-01-01")
  ## Excel is said to use 1900-01-01 as day 1 (Windows default) or
  ## 1904-01-01 as day 0 (Mac default), but this is complicated by Excel
  ## treating 1900 as a leap year.
  ## So for dates (post-1901) from Windows Excel
  as.Date(35981, origin = "1899-12-30") # 1998-07-05
  ## and Mac Excel
  as.Date(34519, origin = "1904-01-01") # 1998-07-05
  ## (these values come from http://support.microsoft.com/kb/214330)
#+end_src

** R-spatial
*** TODO xy2shp
#+name:xy2shp
#+begin_src R :session *R* :tangle no :exports none :eval no
  # func

  if(!require(ggmap)) install.packages('ggmap'); require(ggmap)
  if (!require(rgdal)) install.packages('rgdal'); require(rgdal)
  epsg <- make_EPSG()
  # load
  latlong <- read.table(tc <- textConnection(
  "ID  POINT_Y   POINT_X
  1  150.5556 -35.09305
  2  150.6851 -35.01535
  3  150.6710 -35.06412
  4  150.6534 -35.08666
  "), header = TRUE); close(tc)
  # do
  for(i in 1:nrow(latlong)){
    coords <- as.numeric(latlong[i,c('POINT_Y', 'POINT_X')])
    e <- as.data.frame(cbind(i, t(coords), revgeocode(coords)))
    write.table(e, "test.csv", sep = ',', append = i > 1, col.names = i == 1, row.names = F)
  }
  d <- read.csv('test.csv')
  head(d)
  ## Treat data frame as spatial points
  pts <- SpatialPointsDataFrame(cbind(d$V2,d$V3),d,
    proj4string=CRS(epsg$prj4[epsg$code %in% '4283']))
  writeOGR(pts, 'test.shp', 'test', driver='ESRI Shapefile')
  
#+end_src

** TODO reshape
*** TODO base:reshape

#+name:reshape
#+begin_src R :eval no
  #### name:reshape####
  
  rshaped<-reshape(selected2,direction="long",idvar="Date",ids=row.names(selected2),
      timevar="pharmacy",times=names(selected2)[5:ncol(selected2)],
      varying=list(names(selected2)[5:ncol(selected2)]),v.names="sales")
  
  rshaped<-reshape(data,direction="long",varying=list(c( "a1_salm_cnt",    "a2_salm_cnt",    "a3_a5_salm_cnt"),c( "a1_pop",         "a2_pop","a3_a5_pop" )),v.names=c("counts","pops"),timevar="agegroup",times=c("a1","a2","a3"))  
  
  selectedSLAERP<-reshape(selectedSLA, times=names(selectedSLA)[3:ncol(selectedSLA)],timevar="agesex",varying=list(names(selectedSLA)[3:ncol(selectedSLA)]),v.name=paste(i),direction="long") 
  
  reshape(test,direction="long",varying=list(names(test)[2:ncol(test)]),times=names(test)[2:ncol(test)])
  # all you need is varying (list of col names) and times (not a list), timevar and v.name are useful
  
  reshape(Commands[,c(1,5)],direction="wide",v.names="codes",idvar="disease",timevar="codes")
  
  
  #when d2=
  ##     station           Time TemperatureC DewpointC PressurehPa WindDirection WindDirectionDegrees WindSpeedKMH
  ## 1 INSWGUND1 1/01/2009 0:01         13.8       3.6      1005.3            NW                  308          3.2
  ## 2 INSWGUND1 1/01/2009 0:30         14.5       3.6      1005.3            NW                  308          1.6
  ## 3 INSWGUND1 1/01/2009 1:00         14.2       3.7      1005.0            NW                  308          3.2
  ## 4 INSWGUND1 1/01/2009 1:30         14.3       3.8      1004.6            NW                  306          8.0
  ## 5 INSWGUND1 1/01/2009 2:00         13.8       3.9      1004.6            NW                  315          8.0
  ## 6 INSWGUND1 1/01/2009 2:30         13.5       3.8      1004.3            NW                  321          8.0
  
  reshape(d,direction="wide",idvar="Time",timevar="station")
  
#+end_src

*** TODO reshape Packages
http://psychwire.wordpress.com/2011/05/16/reshape-package-in-r-long-data-format-to-wide-back-to-long-again/

Reshape Package in R: Long Data format, to Wide, back to Long again
May 16, 2011 Hayward Godwin Leave a comment Go to comments

In this post, I describe how to use the reshape package to modify a dataframe from a long data format, to a wide format, and then back to a long format again. It’ll be an epic journey; some of us may not survive (especially me!).
Wide versus Long Data Formats

I’ll begin by describing what is meant by ‘wide’ versus ‘long’ data formats. Long data look like this:

As you can see, there is one row for each value that you have. Many statistical tests in R need data in this shape (e.g., ANOVAs and the like). This is the case even when running tests with repeated factors.

In the example above, lets say that iv1 is a between-subjects factor and iv2 is a within-subjects factor. The same table, in a wide format, would look like this:

Here, each column represents a unique pairing of the various factors. SPSS favours this method for repeated-measures tests (such as repeated-measures ANOVAs or paired t-tests), and being able to move between the two formats is helpful when multiple people are working on a single dataset but using different packages (e.g., R vs SPSS).
Get in Shape! The Reshape Package

I’ll begin by going back to a dataset that I’ve been messing around with for some time. I’m going to select out the columns I need, and rename one of them. One of them ended up getting called “X.” because of the way the data were tabbed. Here, I rename the “X.” column into “rank”, which is what it really should have been in the first place.

1	full_list_cutdown = data.frame("rank"=full_list_dps$X., "class"=full_list_dps$class,
2	"spec"=full_list_dps$spec, "dps"=full_list_dps$DPS)

The data look like this:

Rows truncated to prevent from filling entire page

Let’s begin by converting these data into a wide format. To do that, all we need to do is use the cast function. This has the general format of:
1	cast(dataset, factor1 ~ factor2 ~ etc., value=value column, fun=aggregation method)

Here, dataset refers to your target dataset. factor1 ~ factor2 ~ etc lists the columns/factors that you want to split up the data by. value deals with the column that you want to select and calculate a value for. You can run all sorts of aggregation functions using the fun= command. The default is len, the count of the number of cells for that combination of factor levels. To make my dataset into a wide format, all I need to run is:
1		

Here, I create a wide dataframe based on the rank and class columns. The computed value is the mean of the dps column. It looks like this:

There and Back Again: Getting from Wide to Long Format

Say that we want to go back to the long format again (or, indeed, convert from wide to long in the first place!). How can we do that? We use the melt function!
1	melt(wide_frame, id=c("rank"))

This takes us right back to the start, where our exciting journey began. 

*** TODO reshapes
Also consider reshape2 by same author as reshape.

He mentions it may be 'considerably faster and more memory efficient'
http://r.789695.n4.nabble.com/R-pkgs-reshape2-a-reboot-of-the-reshape-package-td2534378.html

#+name:reshapes
#+begin_src R :session *R* :eval no
#### name:reshapes####


# tools
require(reshape2)
sort_df<-function (data, vars = names(data), decreasing=F) {
    if (length(vars) == 0 || is.null(vars)) 
        return(data)
    data[do.call("order", c(data[, vars, drop = FALSE], decreasing = decreasing)), , drop = FALSE]
 }
 
# load
d<-as.data.frame(rbind(
 c(1,1970,3,3,8,12,23,20,26,25,25,16,8,4),
 c(2,1970,5,4,10,13,26,20,27,28,27,18,9,5)
 ))
d$climate <- 'frst' 
names(d)<-c('ID','Year','1','2','3','4','5','6','7','8','9','10','11','12','climate')
str(d)

# do
d2 <- melt(d,id=c('ID','Year', 'climate'))
str(d2)
d2$variable <- as.numeric(as.character(d2$variable) )
sort_df(d2)






#OR

# load
t<-"ID,Year,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec,climate
1,1970,3,3,8,12,23,20,26,25,25,16,8,4,frst
2,1970,5,4,10,13,26,20,27,28,27,18,9,5,frst
"
t<-read.csv(textConnection(t))

library(reshape)

#convert wide form to long form
t2<-melt(t,id.var=c("ID","climate","Year"))
names(t2)<-c("ID","Surf","Year","Month","Value")

#turn named months into indices
t2$Month<-match(t2$Month,month.abb)
#+end_src

*** TODO reshape more

#+name:rshapemore
#+begin_src R :session *R* :eval no

seasonalCountsPMmeans <- data.frame(cast(qc2, adjustedyear ~ season, value=c('pm10_av'), fun=mean, na.rm=T))
#+end_src

** TODO catenate columns

#+name:catenate
#+begin_src R :session *R* :eval no
#### name:catenate####


dat <- data.frame(a = c("what is", "it is hard"),
                          b = c("going on with", "to know what to"),
                          c = c("this data file?", "make of it all!"),
                          stringsAsFactors = FALSE)
                         
dat$b                    
v <- unlist(unname(dat[1,]))
paste(v)[1]
paste(v, sep="", collapse = "")[1]
paste(v, sep="", collapse = " ")[1]
 
apply(dat, 1, function(x) paste(x, sep='', collapse=' '))
 
 


#+end_src

** TODO fill ragged matrix

#+name:fill
#+begin_src R :session *R* :eval no
#### name:fill####


      person        fruit    suburb something
1        Tom      oranges   Scullin       3.0
2                  apples                 6.0
3                   pears                 9.0
4                tim tams                 2.0
5   Gertrude       durian Charnwood       3.7
6            dragon fruit                 7.0
7                 lychees                 4.9
8               pineapple               100.9
9                  apples                98.0
10 Pennelope      cashews   Higgins       2.0
11              beer nuts                 5.6
12               Pringles                 4.0
 
 
fill.col <- function(x, col.name) {
      s <- which(!x[[col.name]] == "")
      item <- x[[col.name]][s]
      hold <- vector('list', length(item))      
      for(i in 1: length(hold)) hold[[i]] <- rep(item[i], ifelse(is.na(s[i+1]), dim(x)[1] + 1, s[i+1]) - s[i])
      x[[col.name]] <- unlist(hold)
      x
      }
     
d <- fill.col(d, 'person')   
fill.col(d, 'suburb')  
 
      person        fruit    suburb something
1        Tom      oranges   Scullin       3.0
2        Tom       apples   Scullin       6.0
3        Tom        pears   Scullin       9.0
4        Tom     tim tams   Scullin       2.0
5   Gertrude       durian Charnwood       3.7
6   Gertrude dragon fruit Charnwood       7.0
7   Gertrude      lychees Charnwood       4.9
8   Gertrude    pineapple Charnwood     100.9
9   Gertrude       apples Charnwood      98.0
10 Pennelope      cashews   Higgins       2.0
11 Pennelope    beer nuts   Higgins       5.6
12 Pennelope     Pringles   Higgins       4.0
#+end_src

* Data Output
* Data Documentation
** COMMENT data-documentation-blogposts
*** 2013-10-11-two-main-types-of-data-documentation-workflow
#+name:two-main-types-of-data-documentation-workflow-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-11-two-main-types-of-data-documentation-workflow.md :exports none :eval no :padline no
  ---
  name: two-main-types-of-data-documentation-workflow
  layout: post
  title: two-main-types-of-data-documentation-workflow
  date: 2013-10-11
  categories:
  - Data Documentation
  ---
  
  This post introduces a new series of blog posts in which I want to experiment with a few tools for data documentation, which I'll present as Case Studies.  This series of posts will be pitched to an audience mixture of data librarians and data analysts.
    
  Data documentation occurs in a spectrum from simple notes through to elaborate systems.  I've been working on a conceptual framework about how the actual process can be done in two distinct ways:
  
  - Graphical User Interface (GUI) solutions
  - Programmatic (Scripted/Automagic) solutions
   
  I think the GUI tools are in general pretty user friendly and useful
  for simple projects with only a small number of datasets, but have a
  major drawback for the challenge of heterogeneous data integration.  I
  think the problem is expressed nicely [In This Post By Carl Boettiger](http://carlboettiger.info/2013/06/23/notes-on-leveraging-the-ecological-markup-language.html)  in reference to Morpho:
  
  - "looks like a rather useful if tedious tool for generating EML
  files. Unfortunately, without the ability to script inputs or
  automatically detect existing data structures, we are forced through
  the rather arduous process of adding all metadata annotation each
  time...."
  - "...A package could also provide utilities to generate EML from R objects, leveraging the metadata implicit in R objects that is not present in a CSV (in which there is no built-in notion of whether  a column is numeric or character string, what missing value characters it uses, or really if it is consistent at all. Avoiding manual specification of these things makes the metadata annotation less tedious as well."
    
  # Centralised Repository, Distributed Users
  A key aspect of current approaches is the existence of a centralised data management system.  All the examples I consider include at least a metadata catalogue and some also include a data repository.  An additional feature sometimes exists for managing users permissions.
  
  The relationship between users and centralised services is a really complicated space, but essentially consists of the ability for users to create the documentation and push it (perhaps along with the data) to the metadata catalogue  and/or repository.  So given these assumptions I propose the following types of arrangement:
  
  - user sends metadata to metadata catalogue
  - user sends metadata and data to metadata catalogue and data repository 
  - user sends metadata and data and permissions information to metadata catalogue and data repository and permissions system.
    
  The Case Studies I've identified that I want to explore are listed below, names follow the format 'client tool'-and-'data repository or metadata catalogue'-and-optionally-'permissions system':
  
  #### Programmatic solutions
  - reml-and-rfigshare
  - reml-and-knb (when/if this becomes available)
  - make_ddixml-and-ddiindex-and-orapus
  - r2ddi-ddiindex
  - dc-uploader-and-ANU-DataCommons
  - dc-uploader-and-RDA
  
  #### Graphical User Interface solutions
  - morpho-and-knb-metacat
  - nesstar-publisher-and-nesstar-and-whatever-Steve-calls-the-ADA-permissions-system
  - xmet-and-Australian-Spatial-Data-Directory
  - sdmx-editor-and-sdmx-registry
  
  
#+end_src

*** COMMENT getting the test data
#+name:get-test-data
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:get-test-data
  
  #### Code:dc-uploader-and-ANU-DataCommons
      # func
      require(devtools)
      install_github("disentangle", "ivanhanigan")
      require(disentangle)
      # load
      fpath <- system.file(
          file.path("extdata",
                    "civst_gend_sector.csv"
                    ),
          package = "disentangle"
          )
      df <- read.csv(fpath)
      # clean
      str(df)

#+end_src

*** 2013-10-25-dm blog document-first-ask-questions-later
#+name:document-first-ask-questions-later-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-25-document-first-ask-questions-later.md :exports none :eval no :padline no
  ---
  name: document-first-ask-questions-later
  layout: post
  title: document-first-ask-questions-later
  date: 2013-10-25
  categories:
  - research methods
  - Data Documentation
  ---
  
  This post is just a short note about something I'm thinking of calling "documentation-driven development".
  It is based on the concept of ["test-driven development"](http://en.wikipedia.org/wiki/Test-driven_development), and more recently:
  
  - ["test-driven analysis"](http://lamages.blogspot.in/2013/04/test-driven-analysis.html) 
  - or even ["Evidence-based Data Analysis"](http://simplystatistics.org/2013/09/05/implementing-evidence-based-data-analysis-treading-a-new-path-for-reproducible-research-part-3/)).
  - It is also a kind of a critique on the paradigm suggested by the BCCVL statement on ["Just-In-Time metadata"](http://bccvl.org.au/blog/2013/08/20/just-in-time-metadata/). 
  
  Anyway, it is a small thing but hopefully big things will grow.

#+end_src

*** 2013-11-06-what-do-scientists-who-write-metadata-use-to-do-it-and-why

#+name:what-do-scientists-who-write-metadata-use-to-do-it-and-why-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-06-what-do-scientists-who-write-metadata-use-to-do-it-and-why.md :exports none :eval no :padline no
---
name: what-do-scientists-who-write-metadata-use-to-do-it-and-why
layout: post
title: What Do Scientists Who Write Metadata Use To Do It? And Why?
date: 2013-11-06
categories:
- Data Documentation
---


- The extent to which scientists write metadata is probably lower than it ought to be
- The level of metadata written during science projects is probably described generally as 'bare-minimum' and "the minimum needed for one-self to come back to and understand what one did"
- It sometimes seems that even the bare minimum for one-self is not being kept very often
- I argue that the reasons for less-than-adequate metadata can be understood by looking at 
- 1) the culture of the scienctists displinary background via training
- 2) the tools available and 
- 3) institutional  requirements to produce metadata (both about data or access to data)
- In my ongoing [series of blog posts I am exploring the tools available](http://ivanhanigan.github.io/2013/10/two-main-types-of-data-documentation-workflow/).  
- In this post I just wanted to start the discussion about discipline culture and institutional requirements.

### Discipline Culture

- I trained in Geography in the age of GIS and this community uses metadata a lot
- Due to the prevalance of the digital map (collection of layers) which is a derivative data output
- Need to know the source of all the layers
- first law of GIS is "garbage in, garbage out" 
- I was trained in the ANSLIC standard from the start
- ArcGIS has a tool called ArcCatalog which makes metadata easy to create and view

### Institutional Requirements

- The ARC and NHMRC say they are going to require more metadata (and even data deposit)
- Restrictions on data access make it necessary to describe at least the metadata around provision agreements, licence, allowable access
- A supporting management level who value the metadata as research output (alongside a peer reviewed paper metadata pales in comparison)
- My old boss used to say "Work Not Published Is Work Not Done".

### This reminds me of Approaches and Barriers to Reproducible Research

- In 2011 BiostatMatt (Matt Shotwell) published [a survey of biostatisticians](http://biostatmatt.com/uploads/shotwell-interface-2011.pdf)
 VUMC Dept. of Biostatistics to assess:
- the prevalence of fully scripted data analyses
- the prevalence of literate programming practices

To assess the perceived barriers to reproducible research the also asked:

    What The biggest obstacle to always reproducibly scripting your work?

<p></p>


    | Barrier                                                  | Staff | Faculty |
    |----------------------------------------------------------+-------+---------|
    | No signifcant obstacles.                                 |     8 |      10 |
    | I havent learned how.                                    |     0 |       0 |
    | It takes more time.                                      |     7 |       7 |
    | It makes collaboration difficult (eg. file compatibility)|     4 |       2 |
    | The software I use doesnt facilitate reproducibility.    |     0 |       0 |
    | Its not always necessary for my work to be reproducible. |     2 |       0 |
    | Other                                                    |     2 |       1 |
    |----------------------------------------------------------+-------+---------|

### So what about the Approaches and Barriers to Me Writing Metadata?

With a sample size of one I asked myself these questions:


    | Q                                                  | A                                                                    |
    |----------------------------------------------------+----------------------------------------------------------------------|
    | Do I fully document data (to a metadata standard?) | Occasionally, using DDI for high value raw inputs and final products |
    | Do I employ data documentation practices           | I use a tool I created to write minimal metadata occasionally        |
    | What are the main barriers?                        | takes more time, The software doesnt facilitate, not always necessary|

### Conclusions

- The tools need to help write metadata
- the Institution needs to require metadata
- 

### References

- Shotwell, M.S. and Alvarez, J.M. 2011. Approaches and Barriers to Reproducible Practices in Biostatistics.
http://biostatmatt.com/uploads/shotwell-interface-2011.pdf


    
#+end_src

*** 2013-11-06-handling-survey-data-with-r
#+name:handling-survey-data-with-r-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-06-handling-survey-data-with-r.md :exports none :eval no :padline no
  ---
  name: handling-survey-data-with-r
  layout: post
  title: handling-survey-data-with-r
  date: 2013-11-06
  categories:
  - Data Documentation
  ---
  
  R is generally very good for handling many different data types but
  
  ### R has problems with survey data
  
  This post is a stub about what packages Ive found with methods allowing to handle efficiently survey data: handle variable labels, values labels, and retrieve information about missing values
  
  #### Base R:
      ## Not run:
      require(foreign)
      analyte  <- read.spss(filename, to.data.frame=T) 
      varslist <- as.data.frame(attributes(analyte)$variable.labels)
      # this gives a pretty useful thing to use
  <p></p>
  
  While I was digging around in [TraMineR](http://mephisto.unige.ch/traminer) I found this link to Dataset, Emmanuel Rousseaux's package for handling, documenting and describing data sets of survey data. 
  
  #### Code:Dataset, a package for handling-survey-data-with-r
      if(!require(Dataset)) install.packages("Dataset", repos="http://R-Forge.R-project.org");
      require(Dataset)
      data(dds)
      str(dds)
      # cool
      description(dds$sexe)
      # excellent!
  
  <p></p>
  
  ### Conclusions
  
  I'm sure there are plenty of other approaches.  I'll add them as I find them'
#+end_src

*** 2013-12-16-links-to-useful-data-munging-posts
#+name:links-to-useful-data-munging-posts-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-16-links-to-useful-data-munging-posts.md :exports none :eval no :padline no
---
name: 2013-12-16-links-to-useful-data-munging-posts
layout: post
title: links-to-useful-data-munging-posts
date: 2013-12-16
categories:
- research methods
- Data Documentation
---

Here are a few links to some recent data munging tips I picked up last week:

#### Database Relationships

1. [This is a a very quick way to look at the relationships in a database](http://pirategrunt.com/2013/12/13/24-days-of-r-day-13/)

#### MS Access field (column) descriptions:

- I'm looking for methods to access the metadata related to the columns.
- In general MS Access seems to hide these:
- http://blogannath.blogspot.com.au/2010/03/microsoft-access-tips-tricks-list-table.html
- "Field descriptions can be entered by the user when creating the table in design view. It is a highly encouraged practice since the description can provided valuable documentation about the purpose of each field in a table. The inability to extract the field descriptions as part of the table documentation using Access's built-in documenter is therefore quite inconvenient."
- I can see there is [a C# method, but I'd need visual studio or someone to compile this I suppose?](http://stackoverflow.com/questions/7041824/retrieve-msaccess-database-column-description)
- My mate Francis said: "you'll have to use a script that uses the Microsoft OLE-DB, as in the stackoverflow answers. However, you don't need Visual Studio or C# to do this, just any language that can interface with Windows COM objects. Python can do this, so this might be your excuse to finally learn it. I imagine there might even by a R library out there somewhere, although it would probably be more convenient to go the python route here."
- To get started with COM and python, you [could do worse than to start with](http://timgolden.me.uk/pywin32-docs/html/com/win32com/HTML/QuickStartClientCom.html)

#### Data manipulation

1. [This guy has created some custom functions that look helpful](http://christophergandrud.blogspot.com.au/2013/12/three-quick-and-simple-data-cleaning.html)
1. [Revolutions Blog links to several Data Wrangling resources](http://blog.revolutionanalytics.com/2013/12/tutorial-basic-data-processing-with-r.html)

#### Code editor / IDE

1. [Updates to Rstudio server are always worth checking out](http://www.r-bloggers.com/new-version-of-rstudio-v0-98/)
 
     
#+end_src

*** 2013-12-24-extend-Rs-data-frame-class-with-metadata
#+name:extend-Rs-data-frame-class-with-metadata-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-24-extend-Rs-data-frame-class-with-metadata.md :exports none :eval no :padline no
---
name: extend-rs-data-frame-class-with-metadata
layout: post
title: extend-Rs-data-frame-class-with-metadata
date: 2013-12-24
categories:
- research methods
---

"reml now extends R's data.frame class by introducing the data.set class which includes additional metadata required by EML"
[https://github.com/ropensci/reml](https://github.com/ropensci/reml)

and
"I’d like to define a class that acts just like a data.frame, just like the data.table class does, but contains some additional metadata (e.g. the units associated with the columns) and has some additional methods associated with it (e.g. that might do something with those units) while also working with any function that simply knows how to handle data.frame objects.
How might this be done?"
[http://carlboettiger.info/2013/09/11/extending-data-frame-class.html](http://carlboettiger.info/2013/09/11/extending-data-frame-class.html)


Also this guys attempt was interesting (I like TraMineR too!)
[http://ivanhanigan.github.io/2013/11/handling-survey-data-with-r/](http://ivanhanigan.github.io/2013/11/handling-survey-data-with-r/)

    
#+end_src

** 2013-09-19-transform


#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-09-20-toward-a-unified-ecology-dataset.md :exports none :eval no :padline no
  ---
  name: toward-a-unified-ecology-dataset
  layout: post
  title: toward-a-unified-ecology-dataset
  categories:
  - Data Documentation
  ---
  
  # Ecology datasets
  These are my notes from a meeting that Kathryn and I had with a group of Ecologists at the ANU (primarily Luciana Porforio and Nasreen Khan).  We asked them to discuss how they search for and use Ecology datasets, especially how to best package up the parts of an ecological field data collection (ie weather, vegetation, biodiversity, soils, topography etc).
  
  Lu started off the discussion by stating that the most important thing to acknowledge is that every ecologist will start off with a main research question and then search for data that will address their specific research question.  It is difficult to work from a 'top-down' perspective that hopes to pre-empt the range of possible questions.  Lu felt that it may therefore be best to just keep all the data together in the biggest bundle that is possible and the end user can pick it apart once downloaded.  

  We explained that LTERN datasets can be quite expansive with many dimensions and it seemed preferable to at least untangle the main 'themes' for packaging up.

  Nasreen pointed out that there is always a protocol for how data are collected and this should give the data collection it's structure.  However I felt that ecology collections are so diverse they have been made (by necessity) very flexible and specific to the needs of the individual plot network.  Therefore generalisations across data collections are very hard to make (apart from easy things like "weather" or "aboveground dead biomass"). 

  # Toward a Unified Ecology
  I always fall back on the text book "Toward a Unified Ecology: Timothy F. H. Allen, Thomas W. Hoekstra 1992".  I wondered if it can guide us?  On pages 42-53 they describe the following framework and use the image below (the letters in the middle disc correspond to the criteria ie O = Organism).  In this framework it is possible to summarise ANY ecological study as they ALWAYS incorporate these scale-independent criteria:
  
  - Organism: genetic integrity, discrete body, autonomy from other organisms
  - Population: relative similarity within the group
  - Community: inter-species competition, interference, mutualism
  - Ecosystem: biotic and abiotic interactions
  - Landscape: spatial structure/contiguity
  - Biome: characteristic physiognomy, disturbance and climate

  I thought that if these dimensions were identified in a data collection first then they might become the discrete packages by which each plot network publishes their collection?
  
  ![datadoco-layercake.png](/images/datadoco-layercake.png)
  
 
  
  # Aekos
  Over at [AEKOS](http://www.aekos.org.au/why_aekos#diversity) they have a similar conceptual framework
  
      Observations can range from that of individual organisms and
      interactions, through to populations, communities, ecosystems and
      across broad global landscapes.
  
  # Conclusions
  This is an open issue.  More discussions are needed internally for the Data Custodians.

  Lu also pointed out that the end users are the key stakeholders and perhaps more input from them (via surveys and workshops?) is needed?
#+end_src

** R-reml-and-rfigshare
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-12-data-documentation-case-study-reml-and-rfigshare.md :exports reports :eval no :padline no
  ---
  name: data-documentation-case-study-reml-and-rfigshare
  layout: post
  title: data-documentation-case-study-reml-and-rfigshare
  date: 2013-10-12
  categories:
  - Data Documentation
  ---
  
  #### Case Study: reml-and-rfigshare
  First we will look at the work of the ROpenSci team and the reml
  package.  In the vignette they show how to publish data to figshare
  using rfigshare package.  [figshare](http://figshare.com/) is a site
  where scientists can share datasets/figures/code. The goals are to
  encourage researchers to share negative results and make reproducible
  research efforts user-friendly. It also uses a tagging system for
  scientific research discovery. They give you unlimited public space
  and 1GB of private space.  
  
  Start by getting the reml package.
  
  #### Code:
      # func
      require(devtools)
      install_github("reml", "ropensci")
      require(reml)
      ?eml_write
  <p></p>
  This is the Top-level API function for writing eml.  Help page is a bit sparse.  See [This Link](https://github.com/ropensci/reml) for more.  For eg "for convenience, dat could simply be a data.frame and reml will launch it's metadata wizard to assist in constructing the metadata based on the data.frame provided. While this may be helpful starting out, regular users will find it faster to define the columns and units directly in the format above."
  
  
  Now load up the test data for classification trees I described in [This Post](/2013/10/test-data-for-classification-trees/)
  
  #### Code:
      install_github("disentangle", "ivanhanigan") # for the data
                                                   # described in prev post
  
      # load
      fpath <- system.file(file.path("extdata", "civst_gend_sector.csv"),
                           package = "disentangle"
                           )
      civst_gend_sector <- read.csv(fpath)
  
      # clean
      str(civst_gend_sector)
  
      # do
      eml_write(civst_gend_sector,
                creator = "Ivan Hanigan <ivanhanigan@gmail.com>")
  
  
                
  
  
      # Starts up the wizard, a section is shown below.  The wizard
      # prompts in the console and the user writes the answer.
  
      # Enter description for column 'civil_status':
      #  marriage status
      # column civil_status appears to contain categorical data.
      #  
      # Categories are divorced/widowed, married, single
      #  Please define each of the categories at the prompt
      # define 'divorced/widowed':
      # was once married
      # define 'married':
      # still married
      # define 'single':
      # never married
  
      # TODO I don't really know what activity_sector is.  I assumed
      # school because Categories are primary, secondary, tertiary.
  
      # this created "metadata.xml" and "metadata.csv"
      file.remove(c("metadata.xml","metadata.csv"))
  <p></p>  
  This was a very minimal data documentation effort.  A bit more detail would be better.  Because I would now need to re-write all that in the wizard I will take the advice of the help file that "regular users will find it faster to define the columns and units directly in the format"
  
  #### Code:
      ds <- data.set(civst_gend_sector,
                     col.defs = c("Marriage status", "sex", "education", "counts"),
                     unit.defs = list(c("was once married","still married","never married"),
                         c("women", "men"),
                         c("primary school","secondary school","tertiary school"),
                         c("persons"))
                     )
      ds
      # this prints the dataset and the metadata
      # now run the EML function
      eml_write(ds, 
                title = "civst_gend_sector",  
                description = "An example, fictional dataset for Decision Tree Models",
                creator = "Ivan Hanigan <ivanhanigan@gmail.com>",
                file = "inst/extdata/civst_gend_sector_eml.xml"
                )
      # this created the xml and csv with out asking anything
      # but returned a
      ## Warning message:
      ## In `[<-.data.frame`(`*tmp*`, , value = list(civil_status = c(2L,  :
      ##   Setting class(x) to NULL;   result will no longer be an S4 object
  
      # TODO investigate this?
  
      # now we can access the local EML
      obj <- eml_read("inst/extdata/civst_gend_sector_eml.xml")
      obj 
      str(dataTable(obj))
      # returns an error
      ## Error in plyr::compact(lapply(slotNames(from), function(s) if (!isEmpty(slot(from,  (from attribute.R#300) : 
      ##   subscript out of bounds
  <p></p>
  
  # Conclusions
  So this looks like a useful tool.  Next steps are to:
  
  - look at sending these data to figshare
  - describe a really really REALLY simple workflow (3 lines? create metadata, eml_write, push to figshare)
    
    
#+end_src
** R-reml-and-rfigshare-part-2
#+name:reml-and-rfigshare-part-2-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-12-reml-and-rfigshare-part-2.md :exports reports :eval no :padline no
  ---
  name: reml-and-rfigshare-part-2
  layout: post
  title: reml-and-rfigshare-part-2
  date: 2013-10-12
  categories:
  - Data Documentation
  ---
  
  In the last post I explored the functionality of reml.
  This time I will try to send data to figshare.
  
  - First follow [These Instructions](https://github.com/ropensci/rfigshare) to get rfigshare set up.  In particular store your figshare credentials in ~/.Rprofile
  
  #### Code:reml-and-rfigshare-part-2
      # func
      require(devtools)
      install_github("reml", "ropensci")
      require(reml)
      install_github("rfigshare", "ropensci")
      require(rfigshare)
      install_github("disentangle", "ivanhanigan")
      require(disentangle)
      # load
      fpath <- system.file(file.path("extdata","civst_gend_sector_eml.xml"), package = "disentangle")
      setwd(dirname(fpath))
      obj <- eml_read(fpath)
      # clean
      obj
      # do
  
      ## STEP 1: find one of the preset categories
      # available. We can ask the API for
      # a list of all the categories:
      list <- fs_category_list()
      list[grep("Survey", list)]
  
      ## STEP 2: PUBLISH TO FIGSHARE
      id <- eml_publish(fname,
                        description="Example EML
                          A fictional dataset",
                        categories = "Survey results",
                        tags = "EML",
                        destination="figshare"
                        )
      # there are several warnings
      # but go to figshare and it has sent the metadata and data OK
  
      # make public using either the figshare web interface, the
      # rfigshare package (using fs_make_public(id)) or just by adding
      # the argument visibility = TRUE to the above eml_publish
      fs_make_public(id)
  
      
  <p></p>
  # Now these data are on figshare
  
  Now I have published the data they are visible and have a DOI
  
  
  <iframe src="http://wl.figshare.com/articles/820158/embed?show_title=1" width="568" height="157" frameborder="0"></iframe>
  
  
#+end_src

** dc-uploader-and-ANU-DataCommons
#+name:dc-uploader-and-ANU-DataCommons-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-13-dc-uploader-and-ANU-DataCommons.md :exports none :eval no :padline no
  ---
  name: dc-uploader-and-ANU-DataCommons
  layout: post
  title: dc-uploader-and-ANU-DataCommons
  date: 2013-10-13
  categories:
  - Data Documentation
  ---
  
  In this post I use the tool produced at the ANU by the DataCommons team.  This requires Python3.
  
  # What does it do?
  The script only creates new collection records. The functionality to edit records didn’t make it into the script as the expectation is that automated ingests will only require creation of new datasets to which files will be uploaded. 
  
  Users can feel free to tweak the collection parameter file to their liking in the development environment until happy with the results.
  
  # Create the metadata.txt
  
  You need to get the python scripts and conf file from the ANU DataCommons team.  Store these somewhere handy and move to that directory.
  
  change the anudc.conf: to test out the scripts by creating some sample records, please uncomment the “host” field in the file that points to dc7-dev2.anu.edu.au:8443 , and comment out the one that points to datacommons.anu.edu.au:8443.
  
  Also you get a different token in dev and prod servers for security reasons you cannot use the same token. Also, storing your username and password in plain text is not recommended and is to be used only for debugging purposes. Also, in my case I had to change the owner group to ‘5’ when creating records in dev. In prod, it’s 6.
  
  You can look int the "Keys.txt" file that contains the full list of values that can be specified in this metadata.txt file.     
  
  #### Code:
      setwd("~/tools/dcupload")
      sink("metadata.txt")
      cat("
      # This file, referred to as a collection parameter file, consists of
      # data in key=value pairs. This data is sent to the ANU Data Commons
      # to create a collection, establish relations with other records,
      # and/or upload files to those collections.
       
      # The metadata section consists of metadata for use in creation (not
      # for modification) of record metadata in ANU Data Commons. The
      # following fields are required for the creation of a record. The file
      # Keys.txt contains the full list of values that can be specified in
      # this file. Based on this information below, a collection record of
      # type databaset with the title "Test Collection 6/05/2013" will be
      # created owned by Meteorology and Health group.
      [metadata]
      type = Collection
      subType = dataset
      ownerGroup = 5
      # 6 on production, 5 on dev
      name = Civil Status, Gender and Activity Sector
      briefDesc = An example, fictional dataset for Decision Tree Models
      citationCreator = Ritschard, G. (2006). Computing and using the deviance with classification trees. In Compstat 2006 - Proceedings in Computational Statistics 17th Symposium Held in Rome, Italy, 2006.
      email = ivan.hanigan@anu.edu.au
      anzforSubject = 1601
       
      # The relations section allows you to specify the relation this record
      # has with other records in the system.  Currently relations with NLA
      # identifiers is not supported.
      [relations]
      isOutputOf = anudc:123
       
      # This section contains a line of the form 'pid = anudc:123' once a
      # record has been created so executing the uploader script with the
      # same collection parameter file doesnt create a new record with the
      # same metadata.
      [pid]
      ")
      sink()
  
      # run the dcload
      system("python3 dcuploader.py -c metadata.txt")
  
  <p></p>
  # What happened?
  
  - Looking in the metadata.txt file it now has a pid like "pid = test:3527"        
  - And we have created a new record in our account on the DataCommons server.
  
      
  # go to the website
  Now go to [the dev site](https://dc7-dev2.anu.edu.au:8443/DataCommons/) and you can continue editing the record manually in the browser.
      
  Or if we have ironed out the wrinkles you could go straight to the production server at [This Link](https://datacommons.anu.edu.au:8443/DataCommons)
  
  
  # Uploading the data
  The dataset gets sent using a Java applet in the browser while you are manually editing the record using the browser.
  
  # Notes
  
  - After the records get created, the script tries to relate the record to other records as you’ve specified in the collection parameter file in the relations section. If you’re creating a record in dev2, you cannot relate it to a record in production because that record doesn’t exist in dev2. Remember that IDs for records in dev environments have the prefix “test:” while those in production have “anudc:”.
   
  - Also, when you ran the script against production the created records were linked with the record with the ID anudc:123. I have now removed those relations. You might want to change that value in your metadata.txt file so the links are established to records that created records actually can be related to. Or for testing purposes, simply delete the entire [relations] section.     
       
  
  
#+end_src

** morpho-and-rfigshare
#+name:morpho-and-rfigshare-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-14-morpho-and-rfigshare.md :exports none :eval no :padline no
  ---
  name: morpho-and-rfigshare
  layout: post
  title: morpho-and-rfigshare
  date: 2013-10-14
  categories:
  - Data Documentation
  ---
  
  In this Case Study I will use Morpho to compare directly with reml.
  
  # Step one: Set up morpho
  
  - Follow the instructions at the ASN SuperSite website and install Morpho 1.8 rather than latest version because it has technical issues that stop it from setting permissions.    
  - [Configure morpho](http://www.tern-supersites.net.au/index.php/data/repository-tutorial).  (I will follow the ASN SuperSite instructions as a future Case Study will be to use their KNB Metacat service).
  - Do not configure to connect to the Metacat repository, will need a password to be assigned by ASN data manager.
  
  # Step 2: Look at the REML created metadata using Morpho
  
  - Morpho offers to open existing sets for modification.
  
  #### Code: get location of my example dataset
      require(disentangle)
      fpath <- system.file(file.path("extdata", "civst_gend_sector.csv"), package="disentangle")
      fpath
      dirname(fpath)
      # [1] "/home/ivan_hanigan/Rlibs/disentangle/extdata"
  
  - Morpho > File > import = civst_gend_sector_eml.xml
  - (not the figshare_civst_gend_sector_eml.xml that was created when sending to figshare)
  - Error encountered.  could not open metadata, open empty data package.  Offered to upgrade (unable to edit > accepted)
  - unable to display data, empty data package will be shown
  - top menu > Documentation > Add/Edit ion
  # Step 3: Create new datasets with Morpho
      
#+end_src

** morpho-and-reml-boilerplate-streamline-the-process-of-metadata-entry
*** Background
    
- The Morpho/Metacat system is great for a data repository
- Morpho also claims to be suitable for Ecologists to document their data
- But in my experience it leaves a little to be desired in ease of use for both purposes
- Specifically the speed that documentation can be entered into Morpho is slow
- This post is a first attempt to create some boilerplate code to quickly generate EML metadata using REML.

*** Speed and Rigour
As I noted in a previous post, there are [two types of data documentation workflow](http://ivanhanigan.github.io/2013/10/two-main-types-of-data-documentation-workflow/).  
  
- GUI
- Programatic
  
I also think there are two types of users with different motivations and constraints:

- 1) Data Analysts
- 2) Data Librarians

*** Analysts can often trade-off completeness of documentation for speed
In my view the Analysts group of users need a tool that will very rapidly document their data and workflow steps and can live with a bit less rigour in the quality of documentation.  Obviously this is not ideal but seems an inevitable trade-off needed to enable analysts to keep up the momentum of the data processing and modelling without getting distracted by tedious (and potentially unnecessary) data documentation tasks.

*** Librarians produce gold plated documentation and can take longer to produce this
On the other hand the role of the Librarian group is to produce documentation to the best level possible (given time and resource constraints) the datasets and methodologies that lead to the creation of the datasets.  For that group Rigour will take precedence and there will be a trade-off in terms of the amount of time needed to produce the documentation.

*** An example
As an example of the two different groups, an analyst working with weather data in Australia may want to specify that their variable "temperature" is the average of the daily maxima and minima, but might not need to specify that the observations were taken inside a Stevenson Screen, or even if they are in Celsius, Farenhiet or Kelvin.  They will be very keen to start the analysis to identify any associations between weather variables and the response variable they are investigating.   The data librarian on the other hand will be more likely to need to include this information so that the users of the temperature data do not mis-interpret it.

*** Embracing Inaccuracy and Incompleteness
  
- I've been talking about this for a while got referred to this document by Ben Davies at the ANUSF
[http://thedailywtf.com/Articles/Documentation-Done-Right.aspx](http://thedailywtf.com/Articles/Documentation-Done-Right.aspx)
- It has this bit:
#+begin_src R :session *R* :tangle no :exports reports :eval no :padline no  
  
   
    Embracing Inaccuracy and Incompleteness 
        
    The immediate answer to what’s the right way to do documentation is
    clear: produce the least amount of documentation needed to facilitate
    the most understanding, and be very explicit about which documentation
    is to be maintained and which is to be archived (i.e., read-only and
    left to rot).
#+end_src 
 
- Roughly speaking, a full EML document produced by Morpho is a bit like a whole bunch of cruft that isnt needed and gets in the way (and is more confusing)
- Whereas a minimal version Im thinking of covers almost all the generic entries providing the "minimum amount of stuff to make it work right".
  
*** Aim
  
- This experiment aims to speed up the creation of a minimal "skeleton" of metadata to a level that both the groups above can be comfortable with AS A FIRST STEP.
- It is assumed that additional steps will then need to be taken to complete the documentation, but the automation of the first part of the process should shave off enough time to suit the purposes of both groups
- It is an imperative that the quick-start creation of the metadata does not end up costing the documentor more time later on down the track if they need to go back to many of the elements for additional editing.
  
  


*** Step 1: load a simple example dataset
I've been using a [fictitious dataset from a Statistics Methodology paper by Ritschard 2006](http://ivanhanigan.github.io/2013/10/test-data-for-classification-trees/).  It will do as a first cut but when it comes to actually test this out it would be good to have something that would take a bit longer (so that the frustrations of using Morpho become very apparent).

#+begin_src R :session *R* :tangle :eval no :exports reports :padline no
  
    #### R Code:
        # func
        require(devtools)
        install_github("disentangle", "ivanhanigan")
        require(disentangle)
        # load
        fpath <- system.file(
            file.path("extdata", "civst_gend_sector_full.csv"),
            package = "disentangle"
            )
        data_set <- read.csv(fpath)
        summary(data_set)
        # store it in the current project workspace
        write.csv(data_set, "data/civst_gend_sector_full.csv", row.names = F)
        
  
  
  
  ## | divorced/widowed: 33 | female:132 | primary  :116 | Min.   : 128.9 |
  ## | married         :120 | male  :141 | secondary: 99 | 1st Qu.: 768.3 |
  ## | single          :120 | nil        | tertiary : 58 | Median : 922.8 |
  ## | nil                  | nil        | nil           | Mean   : 908.4 |
  ## | nil                  | nil        | nil           | 3rd Qu.:1079.1 |
  ## | nil                  | nil        | nil           | Max.   :1479.4 |
  
#+end_src



*** Step 2 create a function to deliver the minimal metadata object
- the package REML will create a EML metadata document quite easily
- I will assume that a lot of the data elements are self explanatory and take column names and factor levels as the descriptions

*** reml_boilerplate-code
#+name:reml_boilerplate
#+begin_src R :session *R* :tangle R/reml_boilerplate.r :exports reports :eval no
  ################################################################
  # name:reml_boilerplate
   
  # func
  ## if(!require(EML)) {
  ##   require(devtools)
  ##   install_github("EML", "ropensci")
  ##   } 
  ## require(EML)
  
  reml_boilerplate <- function(data_set, created_by = "Ivan Hanigan <ivanhanigan@gmail.com>", data_dir = getwd(), titl = NA, desc = "")
  {
  
    # essential
    if(is.na(titl)) stop(print("must specify title"))
    # we can get the col names easily
    col_defs <- names(data_set)
    # next create a list from the data
    unit_defs <- list()
    for(i in 1:ncol(data_set))
      {
        # i = 4
        if(is.numeric(data_set[,i])){
          unit_defs[[i]] <- "number"
        } else {
          unit_defs[[i]] <- names(table(data_set[,i]))          
        }
      }
    # unit_defs
    
    ds <- data.set(data_set,
                   col.defs = col_defs,
                   unit.defs = unit_defs
                   )
    # str(ds)
  
    # metadata  <- ds #metadata(ds)
    # needs names
    ## for(i in 1:ncol(data_set))
    ##   {
    ##     # i = 4
    ##     if(is.numeric(data_set[,i])){
    ##       names(metadata[[i]][[3]]) <- "number"
    ##     } else {
    ##       names(metadata[[i]][[3]]) <- metadata[[i]][[3]]
    ##     }
    ##   }
    # metadata
    eml_config(creator=created_by)
    oldwd <- getwd()
    setwd(data_dir)
    #
    ## >   eml_write(dat=ds, file = paste(titl, "xml", sep = "."), title = titl)
    ## Error in is(dat, "data.set") : object 'dat' not found
    ## > traceback()
    ## 7: is(dat, "data.set") at dataTable_methods.R#14
    ## 6: eml_dataTable(dat = dat, title = title)
    ## 5: initialize(value, ...)
    ## 4: initialize(value, ...)
    ## 3: new("dataset", title = title, creator = who$creator, contact = who$contact, 
    ##        coverage = coverage, methods = methods, dataTable = c(eml_dataTable(dat = dat, 
    ##            title = title)), ...) at eml_methods.R#61
    ## 2: eml(dat = dat, title = title, creator = creator, contact = contact, 
    ##        ...) at eml_write.R#27
    ## 1: eml_write(dat = ds, file = paste(titl, "xml", sep = "."), title = titl)
    dat <- ds
    eml_write(dat, file = paste(titl, "xml", sep = "."), title = titl)
    setwd(oldwd)
    sprintf("your metadata has been created in the '%s' directory", data_dir)
    }
#+end_src  
*** reml_boilerplate-test-code
#+name:reml_boilerplate-test
#+begin_src R :session *R* :tangle no :exports reports :eval no
  ################################################################
  # name:reml_boilerplate-test
  
  analyte <- read.csv("data/civst_gend_sector_full.csv")
  reml_boilerplate(
    data_set = analyte,
    created_by = "Ivan Hanigan <ivanhanigan@gmail.com>",
    data_dir = "data",
    titl = "civst_gend_sector_full",
    desc = "An example, fictional dataset"
    )
  
  dir("data")
#+end_src
*** Results: This loads into Morpho with some errors
- Notably unable to import the data file

![morpho-reml-boilerplate.png](/images/morpho-reml-boilerplate.png)

- Also "the saved document is not valid for some reason"

![morpho-reml-boilerplate.png](/images/morpho-reml-boilerplate.png)
*** Conclusions
- This needs testing
- A failure would be that even if it is quicker to get started if it takes a long time and is difficult to fix up it might increase the risk of misunderstandings.

** COMMENT blog-morpho-and-reml-boilerplate-streamline-the-process-of-metadata-entry
#+name:morpho-and-reml-streamline-the-process-of-metadata-entry-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-29-morpho-and-reml-streamline-the-process-of-metadata-entry.md :exports none :eval no :padline no
---
name: morpho-and-reml-boilerplate-streamline-the-process-of-metadata-entry
layout: post
title: morpho-and-reml-boilerplate-streamline-the-process-of-metadata-entry
date: 2013-10-29
categories:
- Data Documentation
---


<body>

<div id="preamble">

</div>

<div id="content">
<h1 class="title">Disentangle Things</h1>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 morpho-and-reml-boilerplate-streamline-the-process-of-metadata-entry</a>
<ul>
<li><a href="#sec-1-1">1.1 Background</a></li>
<li><a href="#sec-1-2">1.2 Speed and Rigour</a></li>
<li><a href="#sec-1-3">1.3 Analysts can often trade-off completeness of documentation for speed</a></li>
<li><a href="#sec-1-4">1.4 Librarians produce gold plated documentation and can take longer to produce this</a></li>
<li><a href="#sec-1-5">1.5 An example</a></li>
<li><a href="#sec-1-6">1.6 Embracing Inaccuracy and Incompleteness</a></li>
<li><a href="#sec-1-7">1.7 Aim</a></li>
<li><a href="#sec-1-8">1.8 Step 1: load a simple example dataset</a></li>
<li><a href="#sec-1-9">1.9 Step 2 create a function to deliver the minimal metadata object</a></li>
<li><a href="#sec-1-10">1.10 reml<sub>boilerplate</sub>-code</a></li>
<li><a href="#sec-1-11">1.11 reml<sub>boilerplate</sub>-test-code</a></li>
<li><a href="#sec-1-12">1.12 Results: This loads into Morpho with some errors</a></li>
<li><a href="#sec-1-13">1.13 Conclusions</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-3">
<h3 id="sec-1"><span class="section-number-3">1</span> morpho-and-reml-boilerplate-streamline-the-process-of-metadata-entry</h3>
<div class="outline-text-3" id="text-1">


</div>

<div id="outline-container-1-1" class="outline-4">
<h4 id="sec-1-1"><span class="section-number-4">1.1</span> Background</h4>
<div class="outline-text-4" id="text-1-1">


<ul>
<li>The Morpho/Metacat system is great for a data repository
</li>
<li>Morpho also claims to be suitable for Ecologists to document their data
</li>
<li>But in my experience it leaves a little to be desired in ease of use for both purposes
</li>
<li>Specifically the speed that documentation can be entered into Morpho is slow
</li>
<li>This post is a first attempt to create some boilerplate code to quickly generate EML metadata using REML.
</li>
</ul>


</div>

</div>

<div id="outline-container-1-2" class="outline-4">
<h4 id="sec-1-2"><span class="section-number-4">1.2</span> Speed and Rigour</h4>
<div class="outline-text-4" id="text-1-2">

<p>As I noted in a previous post, there are [two types of data documentation workflow](<a href="http://ivanhanigan.github.io/2013/10/two-main-types-of-data-documentation-workflow/">http://ivanhanigan.github.io/2013/10/two-main-types-of-data-documentation-workflow/</a>).  
</p>
<ul>
<li>GUI
</li>
<li>Programatic
</li>
</ul>


<p>  
I also think there are two types of users with different motivations and constraints:
</p>
<ul>
<li>1) Data Analysts
</li>
<li>2) Data Librarians
</li>
</ul>


</div>

</div>

<div id="outline-container-1-3" class="outline-4">
<h4 id="sec-1-3"><span class="section-number-4">1.3</span> Analysts can often trade-off completeness of documentation for speed</h4>
<div class="outline-text-4" id="text-1-3">

<p>In my view the Analysts group of users need a tool that will very rapidly document their data and workflow steps and can live with a bit less rigour in the quality of documentation.  Obviously this is not ideal but seems an inevitable trade-off needed to enable analysts to keep up the momentum of the data processing and modelling without getting distracted by tedious (and potentially unnecessary) data documentation tasks.
</p>
</div>

</div>

<div id="outline-container-1-4" class="outline-4">
<h4 id="sec-1-4"><span class="section-number-4">1.4</span> Librarians produce gold plated documentation and can take longer to produce this</h4>
<div class="outline-text-4" id="text-1-4">

<p>On the other hand the role of the Librarian group is to produce documentation to the best level possible (given time and resource constraints) the datasets and methodologies that lead to the creation of the datasets.  For that group Rigour will take precedence and there will be a trade-off in terms of the amount of time needed to produce the documentation.
</p>
</div>

</div>

<div id="outline-container-1-5" class="outline-4">
<h4 id="sec-1-5"><span class="section-number-4">1.5</span> An example</h4>
<div class="outline-text-4" id="text-1-5">

<p>As an example of the two different groups, an analyst working with weather data in Australia may want to specify that their variable "temperature" is the average of the daily maxima and minima, but might not need to specify that the observations were taken inside a Stevenson Screen, or even if they are in Celsius, Farenhiet or Kelvin.  They will be very keen to start the analysis to identify any associations between weather variables and the response variable they are investigating.   The data librarian on the other hand will be more likely to need to include this information so that the users of the temperature data do not mis-interpret it.
</p>
</div>

</div>

<div id="outline-container-1-6" class="outline-4">
<h4 id="sec-1-6"><span class="section-number-4">1.6</span> Embracing Inaccuracy and Incompleteness</h4>
<div class="outline-text-4" id="text-1-6">


<ul>
<li>I've been talking about this for a while got referred to this document by Ben Davies at the ANUSF
</li>
</ul>

<p>[http://thedailywtf.com/Articles/Documentation-Done-Right.aspx](<a href="http://thedailywtf.com/Articles/Documentation-Done-Right.aspx">http://thedailywtf.com/Articles/Documentation-Done-Right.aspx</a>)
</p><ul>
<li>It has this bit:
</li>
</ul>




<pre class="src src-R">  
   
Embracing Inaccuracy and Incompleteness 
    
The immediate answer to what&#8217;s the right way to do documentation is
clear: produce the least amount of documentation needed to facilitate
the most understanding, and be very explicit about which documentation
is to be maintained and which is to be archived (i.e., read-only and
left to rot).
</pre>


<ul>
<li>Roughly speaking, a full EML document produced by Morpho is a bit like a whole bunch of cruft that isnt needed and gets in the way (and is more confusing)
</li>
<li>Whereas a minimal version Im thinking of covers almost all the generic entries providing the "minimum amount of stuff to make it work right".
</li>
</ul>


</div>

</div>

<div id="outline-container-1-7" class="outline-4">
<h4 id="sec-1-7"><span class="section-number-4">1.7</span> Aim</h4>
<div class="outline-text-4" id="text-1-7">


<ul>
<li>This experiment aims to speed up the creation of a minimal "skeleton" of metadata to a level that both the groups above can be comfortable with AS A FIRST STEP.
</li>
<li>It is assumed that additional steps will then need to be taken to complete the documentation, but the automation of the first part of the process should shave off enough time to suit the purposes of both groups
</li>
<li>It is an imperative that the quick-start creation of the metadata does not end up costing the documentor more time later on down the track if they need to go back to many of the elements for additional editing.
</li>
</ul>





</div>

</div>

<div id="outline-container-1-8" class="outline-4">
<h4 id="sec-1-8"><span class="section-number-4">1.8</span> Step 1: load a simple example dataset</h4>
<div class="outline-text-4" id="text-1-8">

<p>I've been using a [fictitious dataset from a Statistics Methodology paper by Ritschard 2006](<a href="http://ivanhanigan.github.io/2013/10/test-data-for-classification-trees/">http://ivanhanigan.github.io/2013/10/test-data-for-classification-trees/</a>).  It will do as a first cut but when it comes to actually test this out it would be good to have something that would take a bit longer (so that the frustrations of using Morpho become very apparent).
</p>



<pre class="src src-R">  <span style="color: #586e75;">#### </span><span style="color: #586e75;">R Code:</span>
      <span style="color: #586e75;"># </span><span style="color: #586e75;">func</span>
      <span style="color: #268bd2; font-weight: bold;">require</span>(devtools)
      install_github(<span style="color: #2aa198;">"disentangle"</span>, <span style="color: #2aa198;">"ivanhanigan"</span>)
      <span style="color: #268bd2; font-weight: bold;">require</span>(disentangle)
      <span style="color: #586e75;"># </span><span style="color: #586e75;">load</span>
      fpath <span style="color: #268bd2; font-weight: bold;">&lt;-</span> system.file(
          file.path(<span style="color: #2aa198;">"extdata"</span>, <span style="color: #2aa198;">"civst_gend_sector_full.csv"</span>),
          package = <span style="color: #2aa198;">"disentangle"</span>
          )
      data_set <span style="color: #268bd2; font-weight: bold;">&lt;-</span> read.csv(fpath)
      summary(data_set)
      <span style="color: #586e75;"># </span><span style="color: #586e75;">store it in the current project workspace</span>
      write.csv(data_set, <span style="color: #2aa198;">"data/civst_gend_sector_full.csv"</span>, row.names = F)
      



<span style="color: #586e75;">## </span><span style="color: #586e75;">| divorced/widowed: 33 | female:132 | primary  :116 | Min.   : 128.9 |</span>
<span style="color: #586e75;">## </span><span style="color: #586e75;">| married         :120 | male  :141 | secondary: 99 | 1st Qu.: 768.3 |</span>
<span style="color: #586e75;">## </span><span style="color: #586e75;">| single          :120 | nil        | tertiary : 58 | Median : 922.8 |</span>
<span style="color: #586e75;">## </span><span style="color: #586e75;">| nil                  | nil        | nil           | Mean   : 908.4 |</span>
<span style="color: #586e75;">## </span><span style="color: #586e75;">| nil                  | nil        | nil           | 3rd Qu.:1079.1 |</span>
<span style="color: #586e75;">## </span><span style="color: #586e75;">| nil                  | nil        | nil           | Max.   :1479.4 |</span>

</pre>




</div>

</div>

<div id="outline-container-1-9" class="outline-4">
<h4 id="sec-1-9"><span class="section-number-4">1.9</span> Step 2 create a function to deliver the minimal metadata object</h4>
<div class="outline-text-4" id="text-1-9">

<ul>
<li>the package REML will create a EML metadata document quite easily
</li>
<li>I will assume that a lot of the data elements are self explanatory and take column names and factor levels as the descriptions
</li>
</ul>


</div>

</div>

<div id="outline-container-1-10" class="outline-4">
<h4 id="sec-1-10"><span class="section-number-4">1.10</span> reml<sub>boilerplate</sub>-code</h4>
<div class="outline-text-4" id="text-1-10">




<pre class="src src-R"><span style="color: #586e75;">################################################################</span>
<span style="color: #586e75;"># </span><span style="color: #586e75;">name:reml_boilerplate</span>
 
<span style="color: #586e75;"># </span><span style="color: #586e75;">func</span>
<span style="color: #859900; font-weight: bold;">if</span>(!<span style="color: #268bd2; font-weight: bold;">require</span>(reml)) {
  <span style="color: #268bd2; font-weight: bold;">require</span>(devtools)
  install_github(<span style="color: #2aa198;">"reml"</span>, <span style="color: #2aa198;">"ropensci"</span>)
  } 
<span style="color: #268bd2; font-weight: bold;">require</span>(reml)

<span style="color: #268bd2;">reml_boilerplate</span> <span style="color: #268bd2; font-weight: bold;">&lt;-</span> <span style="color: #859900; font-weight: bold;">function</span>(data_set, created_by = <span style="color: #2aa198;">"Ivan Hanigan &lt;<a href="mailto:ivanhanigan&#64;gmail.com">ivanhanigan&#64;gmail.com</a>&gt;"</span>, data_dir = getwd(), titl = <span style="color: #b58900;">NA</span>, desc = <span style="color: #2aa198;">""</span>)
{

  <span style="color: #586e75;"># </span><span style="color: #586e75;">essential</span>
  <span style="color: #859900; font-weight: bold;">if</span>(is.na(titl)) <span style="color: #859900; font-weight: bold;">stop</span>(print(<span style="color: #2aa198;">"must specify title"</span>))
  <span style="color: #586e75;"># </span><span style="color: #586e75;">we can get the col names easily</span>
  col_defs <span style="color: #268bd2; font-weight: bold;">&lt;-</span> names(data_set)
  <span style="color: #586e75;"># </span><span style="color: #586e75;">next create a list from the data</span>
  unit_defs <span style="color: #268bd2; font-weight: bold;">&lt;-</span> list()
  <span style="color: #859900; font-weight: bold;">for</span>(i <span style="color: #859900; font-weight: bold;">in</span> 1:ncol(data_set))
    {
      <span style="color: #586e75;"># </span><span style="color: #586e75;">i = 4</span>
      <span style="color: #859900; font-weight: bold;">if</span>(is.numeric(data_set[,i])){
        unit_defs[[i]] <span style="color: #268bd2; font-weight: bold;">&lt;-</span> <span style="color: #2aa198;">"numeric"</span>
      } <span style="color: #859900; font-weight: bold;">else</span> {
        unit_defs[[i]] <span style="color: #268bd2; font-weight: bold;">&lt;-</span> names(table(data_set[,i]))          
      }
    }
  <span style="color: #586e75;"># </span><span style="color: #586e75;">unit_defs</span>
  
  ds <span style="color: #268bd2; font-weight: bold;">&lt;-</span> data.set(data_set,
                 col.defs = col_defs,
                 unit.defs = unit_defs
                 )
  <span style="color: #586e75;">#</span><span style="color: #586e75;">str(ds)</span>

  metadata  <span style="color: #268bd2; font-weight: bold;">&lt;-</span> metadata(ds)
  <span style="color: #586e75;"># </span><span style="color: #586e75;">needs names</span>
  <span style="color: #859900; font-weight: bold;">for</span>(i <span style="color: #859900; font-weight: bold;">in</span> 1:ncol(data_set))
    {
      <span style="color: #586e75;"># </span><span style="color: #586e75;">i = 4</span>
      <span style="color: #859900; font-weight: bold;">if</span>(is.numeric(data_set[,i])){
        names(metadata[[i]][[3]]) <span style="color: #268bd2; font-weight: bold;">&lt;-</span> <span style="color: #2aa198;">"number"</span>
      } <span style="color: #859900; font-weight: bold;">else</span> {
        names(metadata[[i]][[3]]) <span style="color: #268bd2; font-weight: bold;">&lt;-</span> metadata[[i]][[3]]
      }
    }
  <span style="color: #586e75;"># </span><span style="color: #586e75;">metadata</span>
  oldwd <span style="color: #268bd2; font-weight: bold;">&lt;-</span> getwd()
  setwd(data_dir)
  eml_write(data_set, metadata,
            title = titl,  
            description = desc,
            creator = created_by
            )
  setwd(oldwd)
  sprintf(<span style="color: #2aa198;">"your metadata has been created in the '%s' directory"</span>, data_dir)
  }
</pre>

</div>

</div>

<div id="outline-container-1-11" class="outline-4">
<h4 id="sec-1-11"><span class="section-number-4">1.11</span> reml<sub>boilerplate</sub>-test-code</h4>
<div class="outline-text-4" id="text-1-11">




<pre class="src src-R"><span style="color: #586e75;">################################################################</span>
<span style="color: #586e75;"># </span><span style="color: #586e75;">name:reml_boilerplate-test</span>

analyte <span style="color: #268bd2; font-weight: bold;">&lt;-</span> read.csv(<span style="color: #2aa198;">"data/civst_gend_sector_full.csv"</span>)
reml_boilerplate(
  data_set = analyte,
  created_by = <span style="color: #2aa198;">"Ivan Hanigan &lt;<a href="mailto:ivanhanigan&#64;gmail.com">ivanhanigan&#64;gmail.com</a>&gt;"</span>,
  data_dir = <span style="color: #2aa198;">"data"</span>,
  titl = <span style="color: #2aa198;">"civst_gend_sector_full"</span>,
  desc = <span style="color: #2aa198;">"An example, fictional dataset"</span>
  )

dir(<span style="color: #2aa198;">"data"</span>)
</pre>

</div>

</div>

<div id="outline-container-1-12" class="outline-4">
<h4 id="sec-1-12"><span class="section-number-4">1.12</span> Results: This loads into Morpho with some errors</h4>
<div class="outline-text-4" id="text-1-12">

<ul>
<li>Notably unable to import the data file
</li>
</ul>


<p>
<img src="/images/morpho-reml-boilerplate.png" alt = "morpho-reml-boilerplate.png">
</p>
<ul>
<li>Also "the saved document is not valid for some reason"
</li>
</ul>


<p>
<img src="/images/morpho-reml-boilerplate2.png" alt = "morpho-reml-boilerplate2.png">
</p></div>

</div>

<div id="outline-container-1-13" class="outline-4">
<h4 id="sec-1-13"><span class="section-number-4">1.13</span> Conclusions</h4>
<div class="outline-text-4" id="text-1-13">

<ul>
<li>This needs testing
</li>
<li>A real deal breaker is if the EML is not valid 
</li>
<li>In some cases not having the data table included will be a deal breaker (ie KNB repositories designed for downloading complete data packs
</li>
<li>A definite failure would be that even if it is quicker to get started if it takes a long time and is difficult to fix up it might increase the risk of misunderstandings.
</li>
</ul>


</div>
</div>
</div>
</div>

</body>
</html>

#+end_src

** COMMENT TODO blog-why-morpho
*** COMMENT 2013-11-27-guest-post-by-marco-fahmi-why-morpho
#+name:guest-post-by-marco-fahmi-why-morpho-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-27-guest-post-by-marco-fahmi-why-morpho.md :exports none :eval no :padline no
  ---
  name: 2013-11-27-guest-post-by-marco-fahmi-why-morpho
  layout: post
  title: guest-post-by-marco-fahmi-why-morpho
  date: 2013-11-27
  categories:
  - research methods
  ---
  
  I asked my colleague [Marco Fahmi](https://twitter.com/fahmiger) to
  post this as a guest post.  It came my way as a part of an email
  exchange in which another colleague had a question regarding their task
  of recording previous work in an ecological field study:
  
      ideally in such a way that we would end up with a complete metadata
      profile of previous work carried out. I would also like to see the
      establishment of a system that could also be used by the group going
      forward to keep track of information and data produced at the
      site. I hear you have been involved with establishing the
      a metadata reporting system. How does this effort currently stand,
      is it online? I was also wondering if you would be amenable to sharing
      what you have with us with the hope that i could use this as a model
      for our own system.
  
  <p></p>
  
  #### Our colleague Sheila responded first that:
  All metadata are created using a standard template document and then transfered into a software package called [Morpho](http://knb.ecoinformatics.org/morphoportal.jsp).  Metadata are then uploaded with the data to the Australian Supersite Network (ASN) Portal [http://www.tern-supersites.net.au/knb/](http://www.tern-supersites.net.au/knb/).   Any other useful documents are uploaded to the website [http://www.tern-supersites.net.au](http://www.tern-supersites.net.au) either under the specific supersite tab on the left hand menu or under the Publications - Resources for SuperSite Users tab.
  
  #### Marco says:
  Morpho is an open source piece of software designed to host all kinds of ecological data. More information about how we use it at ASN can be found here: [http://www.tern-supersites.net.au/index.php/data/repository-tutorial](http://www.tern-supersites.net.au/index.php/data/repository-tutorial)
  
  Morpho should be enough for an individual researcher to organise and describe their personal data collection. If you want to share the data with colleagues or publish them online, then you will also need Metacat. There is a worldwide Metacat server available from the link account. All you need to do is request an account and connect to it via Morpho. Alternatively you can set up your own; but then you will need your own server and tech knowhow to configure it (and maintain it).
  
  For technical reasons, we have our own server running an older version of the Metacat software. You are welcome to use it if you wish (Shiela can issue you an account to log in and upload). We are also happy to provide assistance if you want to set something a standalone server for DRO. (Like any other piece of infrastructure, someone will need to look after the server after it is set up, so that's probably a decision that will need to be considered carefully).
  
  #### My comment:
      "Morpho should be enough for an individual researcher to organise
      and describe their personal data collection"
  
  I agree, but would emphasise the _should_ and then say _but_ ...
  Ultimately I'd like to see something as easy and intuitive as iTunes for music or Endnote and Mendeley for bibliographies, but...
  
  
  
  
      
#+end_src

** COMMENT TODO blog-make-ddixml-and-ddiindex-and-orapus
#+name:make-ddixml-and-ddiindex-and-orapus-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_drafts/2013-11-06-make-ddixml-and-ddiindex-and-orapus.md :exports none :eval no :padline no
---
name: make-ddixml-and-ddiindex-and-orapus
layout: post
title: make-ddixml-and-ddiindex-and-orapus
date: 2013-11-06
categories:
- Data Documentation
---

 make_ddixml-and-ddiindex-and-orapus

#### R Code:make-ddixml-and-ddiindex-and-orapus
    
#+end_src

** COMMENT TODO R-spss-variable-labels-create
#+name:R-spss-variable-labels
#+begin_src R :session *R* :tangle no :exports reports :eval no
  ################################################################
  # name:R-spss-variable-labels
  # from http://stackoverflow.com/q/10181730
  # First I create a dummy dataset
  df <- data.frame(id = c(1:6), p.code = c(1, 5, 4, NA, 0, 5),  
                   p.label = c('Optometrists', 'Nurses', 'Financial analysts',
                   '<NA>', '0', 'Nurses'), foo = LETTERS[1:6])
  
  # Second, I add some variable labels using label from the Hmisc package
  # install.packages('Hmisc', dependencies = TRUE)
  library(Hmisc)
  label(df) <- "Sweet sweet data"
  label(df$id) <- "id !@#$%^" 
  label(df$p.label) <- "Profession with human readable information"
  label(df$p.code) <- "Profession code"
  label(df$foo) <- "Variable label for variable x.var"
  # modify the name of one varibes, just to see what happens when exported.
  names(df)[4] <- "New crazy name for 'foo'"
  
  attributes(df)$variable.labels
  
  # Third I export the data with write.foreign from the foreign package
  # install.packages('foreign', dependencies = TRUE)
  setwd('inst/extdata')
  library(foreign)
  write.foreign(df,"df.wf.txt","df.wf.sps",  package="SPSS")
  
  list.files()
  # [1] "df.wf.sps" "df.wf.txt"
  
  # from http://stackoverflow.com/a/10261534
  # Step 1: Make a backup of your data, just in case
  df.orig = df
  # Step 2: Load the following function
  get.var.labels = function(data) {
    a = do.call(llist, data)
    tempout = vector("list", length(a))
  
    for (i in 1:length(a)) {
      tempout[[i]] = label(a[[i]])
    }
    b = unlist(tempout)
    structure(c(b), .Names = names(data))
  }
  # Step 3: Apply the variable.label attributes
  attributes(df)$variable.labels = get.var.labels(df)
  # Step 4: Load the write.SPSS function available from
  # https://stat.ethz.ch/pipermail/r-help/2006-January/085941.html
  
  write.SPSS <- function (df, datafile, codefile, varnames = NULL)
    {
      adQuote <- function(x){paste("\"", x, "\"", sep = "")}
       dfn <- lapply(df, function(x) if (is.factor(x))
           as.numeric(x)
       else x)
       write.table(dfn, file = datafile, row = FALSE, col = FALSE)
       if(is.null(attributes(df)$variable.labels)) varlabels <- names(df) else varlabels <- attributes(df)$variable.labels
       if (is.null(varnames)) {
           varnames <- abbreviate(names(df), 8)
           if (any(sapply(varnames, nchar) > 8))
               stop("I cannot abbreviate the variable names to eight or fewer letters")
           if (any(varnames != names(df)))
               warning("some variable names were abbreviated")
       }
       cat("DATA LIST FILE=", dQuote(datafile), " free\n", file = codefile)
       cat("/", varnames, " .\n\n", file = codefile, append = TRUE)
       cat("VARIABLE LABELS\n", file = codefile, append = TRUE)
       cat(paste(varnames, adQuote(varlabels), "\n"), ".\n", file = codefile,
           append = TRUE)
       factors <- sapply(df, is.factor)
       if (any(factors)) {
           cat("\nVALUE LABELS\n", file = codefile, append = TRUE)
           for (v in which(factors)) {
               cat("/\n", file = codefile, append = TRUE)
               cat(varnames[v], " \n", file = codefile, append = TRUE)
               levs <- levels(df[[v]])
               cat(paste(1:length(levs), adQuote(levs), "\n", sep = " "),
                   file = codefile, append = TRUE)
           }
           cat(".\n", file = codefile, append = TRUE)
       }
       cat("\nEXECUTE.\n", file = codefile, append = TRUE)
    }
  
  # Step 5: Write your SPSS datafile and codefile
  write.SPSS(df, "df.sav", "df.sps")
  
  ## analyte  <- read.spss("df.sav", to.data.frame = T)
  ## Error in read.spss("df.sav", to.data.frame = T) : 
  ##   file 'df.sav' is not in any supported SPSS format
  
  
  
#+end_src

** R-get.var.labels
*** COMMENT R-get.var.labels
#+name:get.var.labels
#+begin_src R :session *R* :tangle R/get.var.labels.r :exports none :eval no
  ################################################################
  # name:get.var.labels
  # from http://stackoverflow.com/a/10261534
  # this creates the $variable.labels attribute
  get.var.labels = function(data) {
    if(!require(Hmisc)) install.packages('Hmisc', dependencies = TRUE); require(Hmisc)
    a = do.call(llist, data)
    tempout = vector("list", length(a))
  
    for (i in 1:length(a)) {
      tempout[[i]] = label(a[[i]])
    }
    b = unlist(tempout)
    structure(c(b), .Names = names(data))
  }
  
#+end_src
*** test-get.var.labels
#+name:get.var.labels
#+begin_src R :session *R* :tangle no :exports reports :eval no
  ################################################################
  # name:R-variable-labels-create
  # func
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
  require(Hmisc)
  
  # load
  fpath <- system.file(file.path("extdata", "civst_gend_sector.csv"),
                       package = "disentangle"
                       )
  civst_gend_sector <- read.csv(fpath)
    
  # clean
  str(civst_gend_sector)
    
  # do
  label(civst_gend_sector) <- "Fictional data for Classification Trees"
  label(civst_gend_sector$civil_status) <- "married"
  label(civst_gend_sector$gender) <- "sex of person"
  label(civst_gend_sector$activity_sector) <- "level of school"
  label(civst_gend_sector$number_of_cases) <- "persons"
  
  attributes(civst_gend_sector)$variable.labels  <- get.var.labels(civst_gend_sector)
  
  # report
  str(civst_gend_sector)
  as.data.frame(
    attributes(civst_gend_sector)$variable.labels
    )
    
  
#+end_src

*** COMMENT man-get.var.labels
#+name:get.var.labels
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:get.var.labels

#+end_src

** R-spss-variable-labels-read
*** R-spss-variable-labels-read
#+name:R-spss-variable-labels-read
#+begin_src R :session *R* :tangle R/spss_variable_labels_read.r :exports reports :eval no
  ################################################################
  # name:R-spss-variable-labels-read
  spss_variable_labels_read  <- function(x, filter, case_sensitive = FALSE, return_df = FALSE)
  {
    if(case_sensitive)
      {
        col_index  <- grep(filter, attributes(x)$variable.labels)      
      } else {
        col_index  <- grep(tolower(filter), tolower(attributes(x)$variable.labels))      
      }
    names_returned <- attributes(x)$variable.labels[col_index]
    col_names  <- names(names_returned)
    col_refs  <-  as.data.frame(cbind(col_names, names_returned))
    col_refs[,1]  <-  as.character(col_refs[,1])
    col_refs[,2]  <-  as.character(col_refs[,2])
    row.names(col_refs)  <- NULL
    if(return_df)
      {
        names_returned <- paste(names_returned, sep = "", collapse = "', '")
        cat(sprintf("returning the columns '%s'", names_returned))
        data_out <- x[,col_index]
        return(data_out)
      } else {
        return(col_refs)
      }   
  }
#+end_src
*** test-spss-variable-labels-read-code
#+name:test-spss_variable_labels_read
#+begin_src R :session *R* :tangle no :exports reports :eval no
  ################################################################
  # name:test-spss_variable_labels_read
  require(disentangle)
  fpath <- system.file("extdata/civst_gend_sector.csv",package = "disentangle")
  fpath
  civst_gend_sector <- read.csv(fpath)
  str(civst_gend_sector)
  # test
  qc <- spss_variable_labels_read(
    x = civst_gend_sector
    ,
    filter = "number_of_cases"
    ,
    case_sensitive  = TRUE
    ,
    return_df = T
  )
  
  str(qc)
  qc
#+end_src
** R-spss-variable-summary-table-code
#+name:R-summary-table
#+begin_src R :session *R* :tangle no :exports reports :eval no
  ################################################################
  # name:R-summary-table
   
  # now summarise in a tex table
  # func
  require(xtable)
  
  # load
  analyte  <- read.spss(filename, to.data.frame=T)
  
  # clean
  names(analyte)
  varslist <- as.data.frame(attributes(analyte)$variable.labels)
  write.csv(varslist, "variable_labels.csv", row.names = T)
  x <- read.csv('variable_labels.csv')
  head(x)
  names(x)  <- c("variable", "label")
  
  # do
  x.big <- xtable(x,label='tab:table1',caption='Variable Names and Descriptions')
  align(x.big) <-  c( 'l', 'p{1in}', 'p{4in}')
    
  sink('tab1.tex')
  
  print(x.big,tabular.environment='longtable',
          floating=FALSE, caption.placement = "top",
          hline.after = c(-1,nrow(x.big)), 
          add.to.row = list(pos = list(0),command = "\\hline \\endhead "),
          include.rownames=F)
  
  sink()
  
  
#+end_src

** R-reporttools-variable-summary-table
#+name:tableCode
#+begin_src R :session *R* :tangle no :eval no
  ################################################################
  # func
  if(!require(reporttools)) install.packages("reporttools"); require(reporttools)
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
  # load
  fpath <- system.file(file.path("extdata", "civst_gend_sector_full.csv"), package = "disentangle")
  
  analyte  <- read.csv(fpath)
  analyte$random <- rnorm(nrow(analyte), 0 , 1)
  summary(analyte)
  # create a large number of randome variables
  for(i in 1:75)
    {
      analyte[,ncol(analyte) + 1] <- rnorm(nrow(analyte), 10 , 20)    
    }
  names(analyte)
  str(analyte)
  data_continuous <- numeric(0) 
  for(i in 1:length(names(analyte)))
    {
      if(is.numeric(analyte[,i]))
          {
              data_continuous <- c(data_continuous, i)
          }
    }
  # clean        
  str(analyte[,data_continuous])
  str(analyte[,-data_continuous])
  # do
  sink('inst/doc/tabContinuous.tex')
  tableContinuous(vars = analyte[,data_continuous],
                  stats = c("n", "min", "mean", "median",
                    "max", "iqr", "na"),
                  cap = "Table of continuous variables.", lab = "tab:table4",
                  caption.placement = "top",
                  longtable = TRUE, add.to.row = list(pos = list(0), 
                  command = "\\hline \\endhead "))
  sink()
  
  x.big <- analyte[,-data_continuous]
  sink('inst/doc/tabNominal.tex')
  tableNominal(vars = x.big, cap = "Table of nominal variables",
               vertical = FALSE,
               lab = "tab:table5", longtable = TRUE,
               caption.placement = "top")
  
  sink()
     
#+end_src

#+RESULTS: tableCode

** COMMENT R-data_dictionary
*** R-R-data_dict
#+name:R-data_dictionary
#+begin_src R :session *R* :tangle R/data_dict.r :exports none :eval no
  # name:data_dict
  data_dict <- function(.dataframe, .variable, .show_levels = -1)
  {
    if(is.character(.dataframe[ ,.variable])){
      .dataframe[,.variable]  <- factor(.dataframe[,.variable])
    }
  
    summa  <- summary(.dataframe[,.variable])
    summa  <- as.data.frame(
      cbind(
        c(.variable, rep("", length(summa) - 1)),
        names(summa),
        as.vector(as.character(summa))
        )
      )
    summa[,1]  <- as.character(summa[,1])
    summa[,2]  <- as.character(summa[,2])
    # summa
  
    # if char (factor)
    if(is.factor(.dataframe[,.variable])){
    summa$type <- c("character", rep("", nrow(summa) - 1))
    summa$summa  <- as.numeric(as.character(summa$V3))  
    summa$summa2 <- rep(NA, nrow(summa))
        # as.numeric(as.character(summa$V2)) ?
    summa$pct  <- round((summa$summa / sum(summa$summa)) * 100, 2)
    summa <- summa[,c(1,4,2,6,5,7)]
    if(.show_levels > 0){
      if(nrow(summa) > .show_levels){
        summa <- summa[1:.show_levels,]  
        summa <- rbind(summa, c("", "",
                                sprintf("more than %s levels. list truncated.", .show_levels),
                                "","", "")
                       )
        }
      }
    # summa
    } else if (
      is.numeric(.dataframe[,.variable])
      ){
    summa$type <- c("number", rep("", nrow(summa) - 1))
    summa$cnt <- NA
    summa$pct  <- NA
    summa <- summa[,c(1,4,2,3,5,6)]
    } else if (
     !all(
        is.na(as.Date(as.character(.dataframe[,.variable]), origin = "1970-01-01"))
        )
      ){
    # if date
    ## datevar <- as.Date(as.character(
    ##   .dataframe[,.variable]
    ##   ), origin = "1970-01-01")
    # http://stackoverflow.com/questions/18178451/is-there-a-way-to-check-if-a-column-is-a-date-in-r
    # as.Date(as.character(.dataframe[,.variable]),format="%Y-%m-%d")
    ## if(!all(is.na(datevar))){
    ##   summa[,3] <- as.character(datevar)
    ## }
      
    summa$type <- c("date", rep("", nrow(summa) - 1))
    summa$cnt <- NA
    summa$pct  <- NA
    summa <- summa[,c(1,4,2,3,5,6)]
    } else {
      stop("type not character, factor, date or numeric")
    }
    names(summa)  <- c("Variable","Type","Attributes", "Value", "Count", "Percent")
  #summa
    return(summa)
  }
  
#+end_src
*** data_dictionary-code
#+name:data_dictionary
#+begin_src R :session *R* :tangle R/data_dictionary.r :exports none :eval no
  ################################################################
  data_dictionary <- function(dataframe, show_levels = -1){
    out <- matrix(NA, nrow = 0, ncol = 3)
    for(i in 1:ncol(dataframe)){
    #  i = 1
      print(i)
    out2 <- data_dict(
      .dataframe = dataframe
      ,
      .variable = names(dataframe)[i]
      ,
      .show_levels = show_levels
      )
    out <- rbind(out, out2)
    }
    row.names(out) <- NULL
    return(out)
  }
#+end_src

*** test-R-data_dictionary
#+name:R-data_dictionary
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:R-data_dictionary
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
  fpath <- system.file("extdata/civst_gend_sector.csv", package = "disentangle")
  fpath
  civst_gend_sector <- read.csv(fpath)
  civst_gend_sector$datevar <- as.Date(round(rnorm(nrow(civst_gend_sector), Sys.Date(),10)), origin = "1970-01-01")
  str(civst_gend_sector)
  #data_dict
  data_dict(civst_gend_sector, "civil_status")
  data_dict(civst_gend_sector, "datevar")
  data_dict(civst_gend_sector, "number_of_cases")
  
  dataDictionary <- data_dictionary(civst_gend_sector,
                                    show_levels = -1)
  
  dataDictionary
  #write.csv(dataDictionary, "~/dataDictionary.csv", row.names = F)
#+end_src
*** man-R-data_dictionary
#+name:R-data_dictionary
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:R-data_dictionary

#+end_src



** 2014-01-21-morpho-and-reml-use-case-marsupial-mulgara-dasycercus-cristicauda
#+name:morpho-and-reml-use-case-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-01-21-morpho-and-reml-use-case-marsupial-mulgara-dasycercus-cristicauda.md :exports none :eval no :padline no
  ---
  name: 2014-01-21-morpho-and-reml-use-case-marsupial-mulgara-dasycercus-cristicauda
  layout: post
  title: Morpho And R-EML Use Case Marsupial mulgara Dasycercus cristicauda
  date: 2014-01-21
  categories:
  - Data Documentation
  ---
  
  # Aim
    
  - The [EML R package](https://github.com/ropensci/EML) uses the Ecological Metadata Language (EML) approach that allows archiving of very heterogeneous data without having to standardize everything into a narrow and pre-defined syntax.
  - XML files in specificed schemas involve strict criteria and are thus best generated by software.
  - Morpho is an application that provides another GUI based method of generating EML but is a rather tedious tool for generating EML files. Unfortunately, without the ability to script inputs or automatically detect existing data structures, we are forced through the rather arduous process of adding all metadata annotation each time.
  - The aim of this experiment is to use the EML package to create some advanced metadata quickly and then finish this off with Morpho, using ["boilerplate code"](http://en.wikipedia.org/wiki/Boilerplate_code) wherever possible.
  - this builds on my previous post [http://ivanhanigan.github.io/2013/10/morpho-and-reml-streamline-the-process-of-metadata-entry](http://ivanhanigan.github.io/2013/10/morpho-and-reml-streamline-the-process-of-metadata-entry)
  
  # Background
  
  - I am basically very lazy when it comes to entering metadata and when I use the Morpho package for metadata data entry I get frustrated with having to step through ever SINGLE variable and use the drop down menus etc to describe them as essentially "number" or "text"
  - A big reason I like Morpho is because Metacat is a great data portal and Kepler is a promising scientific workflow tool, and all three are produced by the same group so it would be great to get them working together...
  - Morpho and Metacat are open source software designed to host all kinds of ecological data. More information about it can be found [here](http://knb.ecoinformatics.org/index.jsp)
  - More info about the Metacat Data Portal System is [here](https://knb.ecoinformatics.org/knb/docs/).
  - For technical reasons, I'm running an older version of the Morpho software because I'm working with an older version of the  Metacat portal software and so are also constrained to running the older Morpho version too (but will be upgrading soon).
  - You might want to look at the background of the Ecological Metadata Language (EML) standard.  I like this page [http://carlboettiger.info/2013/06/23/notes-on-leveraging-the-ecological-markup-language.html](http://carlboettiger.info/2013/06/23/notes-on-leveraging-the-ecological-markup-language.html) along with the references he cites at the bottom.
  
  # Material
  
  - To tie this experiment back to something that is actually useful for a scientist, I will use the field-based example data on the effects on mulgara of removing spinifex, from:
  
      McCarthy, M. a., & Masters, P. (2005). Profiting from prior
      information in Bayesian analyses of ecological data. Journal of
      Applied Ecology, 42(6),
      1012–1019. doi:10.1111/j.1365-2664.2005.01101.x
    
  - Brief description is:
  
      an experimental manipulation of habitat was conducted by Masters,
      Dickman & Crowther (2003) in which vegetation cover of a site in
      arid inland Australia was reduced and the response of the mammal
      fauna monitored.

  - you can find the data in the download file from [the "Code for analysing the mulgara experiment" from here](http://www.nceas.ucsb.edu/~mccarthy/research.html)
  - I first checked that these data aren;t already on [the KNB repository](https://knb.ecoinformatics.org/m/)
  - I searched for Marsupial, Australia, Mulgara and etc, finding no hits.
  - We will assume that these data are not already published there.
  
  # Methods
  
  - Step one install the github version of EML and [a function I wrote for this a while back](http://ivanhanigan.github.io/2013/10/morpho-and-reml-streamline-the-process-of-metadata-entry/#sec-1-9)
  - Note that I made a few changes since that post [https://github.com/ivanhanigan/disentangle/blob/master/R/reml_boilerplate.r](https://github.com/ivanhanigan/disentangle/blob/master/R/reml_boilerplate.r)
  
  #### R Code:
      # func
      library("devtools")
      install_github("EML", "ropensci")       
      library("EML")
      install_github("disentangle", "ivanhanigan")       
      library("disentangle")

      # load                                                                    
      datatext <- 'Treat, Before, After1, After2
      0,  2.833213344,    1.609437912,    2.48490665
      0,  1.791759469,    2.197224577,    2.079441542
      0,  3.044522438,    2.708050201,    3.135494216
      0,  2.772588722,    1.791759469,    2.197224577
      0,  1.098612289,    1.609437912,    2.63905733
      1,  2.944438979,    0.693147181,    1.791759469
      1,  2.564949357,    0.693147181,    1.791759469
      1,  2.564949357,    1.609437912,    1.609437912
      1,  0.693147181,    1.098612289,    1.098612289
      1,  1.609437912,    0,      1.098612289'
      analyte <- read.csv(textConnection(datatext))

      # check
      analyte

      # do
      ## from a work dir with a subdir for data
      write.csv(analyte, "data/mulgara.csv", row.names = F)
      reml_boilerplate(
        data_set = analyte
        ,
        created_by = "Ivan Hanigan <ivanhanigan@gmail.com>"
        ,
        data_dir = "data"
        ,
        titl = "mulgara"
        ,
        desc = "Experimental data: effect of cover reduction on mulgara Dasycercus cristicauda"
        )
  
  <p></p>
  
  - Now open morpho and under file > import browse to this  data directory and import.
  - Got several warnings, about unable to display data, and an older version that could be updated

                                                                                              
                                                                                              
  # Results
  - Result does not display  in morpho

  ![mulgara-morpho-import.png](/images/mulgara-morpho-import.png)
  
  # Discussion
  
  - There is something different about the way the EML R package writes the data and what Morpho 1.8 is expecting.

  # Conclusions

  - Further research is required.
  
#+end_src

** morpho_bounding_box
*** R-morpho_bounding_box
#+name:bounding_box
#+begin_src R :session *R* :tangle R/morpho_bounding_box.r :exports none :eval no
  ################################################################
  # name:bounding_box
  morpho_bounding_box <- function(x){
    ## Check if spatial obj and proj4string is valid
    #str(x)
    bb <- x@bbox
    #bb
    # TODO polygons
    # TODO only for southern hemisphere, east of GMT?
    loc <- data.frame(
      rbind(
        c(NA, round(abs(bb[2,2]), 5), NA),
        c(round(bb[1,1], 5),  NA, round(bb[1,2],5)),
        c(NA, round(abs(bb[2,1]),5), NA)
        )
      )
    #loc
    loc$X2[c(1,3)] <- sprintf("%s S", abs(loc$X2[c(1,3)]))
    loc[2,c(1,3)] <- sprintf("%s E", abs(loc[2,c(1,3)]))
  
    return(loc)
    }
  
#+end_src
*** test-morpho_bounding_box
#+name:bounding_box
#+begin_src R :session *R* :tangle tests/test-morpho_bounding_box.r :exports none :eval no
  ################################################################
  # name:bounding_box
  require(xtable)
  #if (!require(rgdal)) install.packages('rgdal'); require(rgdal)
  #epsg <- make_EPSG()
  # load
  d <- read.table(textConnection(
  "ID    long       lat
  1  150.555699999 -35.093059999999999
  2  150.685199999 -35.015359999999999 
  3  150.671099999 -35.064129999999999 
  4  150.653499999 -35.086669999999999 
  "), header = TRUE)
  # do
  str(d)
  head(d)
  epsg <- make_EPSG()
  # epsg[grep("GDA94$", epsg$note),]
  projection  <- '4283'
  pts <- SpatialPointsDataFrame(cbind(d$long, d$lat), d,
    proj4string=CRS(epsg$prj4[epsg$code %in% projection]))
  str(pts)
  loc  <- morpho_bounding_box(x = pts)
  loc
  print(xtable(loc), type = 'html')
  
#+end_src
*** man-bounding_box
#+name:bounding_box
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:bounding_box

#+end_src

** 2014-04-20-using-morpho-for-cataloguing-personal-research-data-blog
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-20-using-morpho-for-cataloguing-personal-research-data.md :exports none :eval no :padline no
  ---
  name: 2014-04-20-using-morpho-for-cataloguing-personal-research-data
  layout: post
  title: Using Morpho for Cataloguing Personal Research Data
  date: 2014-04-20
  categories:
  - Data Documentation
  ---
    
    
  
  <div id="table-of-contents">
  <h2>Table of Contents</h2>
  <div id="text-table-of-contents">
  <ul>
  <li><a href="#sec-1">1 2014-04-20-using-morpho-orgmode</a>
  <ul>
  <li><a href="#sec-1-1">1.1 Introduction</a></li>
  <li><a href="#sec-1-2">1.2 Cataloguing Personal Research Data with Morpho</a></li>
  <li><a href="#sec-1-3">1.3 How Morpho Works</a></li>
  <li><a href="#sec-1-4">1.4 Adding a dataset from my collection</a></li>
  <li><a href="#sec-1-5">1.5 the drought dataset:</a></li>
  <li><a href="#sec-1-6">1.6 Step One: define the project that I will keep locally</a></li>
  <li><a href="#sec-1-7">1.7 Contextual Metadata</a></li>
  <li><a href="#sec-1-8">1.8 Abstract</a></li>
  <li><a href="#sec-1-9">1.9 Australian FOR codes</a></li>
  <li><a href="#sec-1-10">1.10 GCMD Keywords</a></li>
  <li><a href="#sec-1-11">1.11 Geographic coverage</a></li>
  <li><a href="#sec-1-12">1.12 Save the metadata</a></li>
  <li><a href="#sec-1-13">1.13 Additional Metadata</a></li>
  </ul>
  </li>
  </ul>
  </div>
  </div>
   
  <div id="outline-container-1" class="outline-3">
  <h3 id="sec-1"><span class="section-number-3">1</span> 2014-04-20-using-morpho-orgmode</h3>
  <div class="outline-text-3" id="text-1">
    
  <?xml version="1.0" encoding="utf-8"?>
  <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
                 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
  <html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
  <meta name="generator" content="Org-mode"/>
  <meta name="generated" content="2014-04-19T22:38+1000"/>
  <meta name="author" content="Ivan Hanigan"/>
  <meta name="description" content=""/>
  <meta name="keywords" content=""/>
  <style type="text/css">
   <!--/*--><![CDATA[/*><!--*/
    html { font-family: Times, serif; font-size: 12pt; }
    .title  { text-align: center; }
    .todo   { color: red; }
    .done   { color: green; }
    .tag    { background-color: #add8e6; font-weight:normal }
    .target { }
    .timestamp { color: #bebebe; }
    .timestamp-kwd { color: #5f9ea0; }
    .right  {margin-left:auto; margin-right:0px;  text-align:right;}
    .left   {margin-left:0px;  margin-right:auto; text-align:left;}
    .center {margin-left:auto; margin-right:auto; text-align:center;}
    p.verse { margin-left: 3% }
    pre {
          border: 1pt solid #AEBDCC;
          background-color: #F3F5F7;
          padding: 5pt;
          font-family: courier, monospace;
          font-size: 90%;
          overflow:auto;
    }
    table { border-collapse: collapse; }
    td, th { vertical-align: top;  }
    th.right  { text-align:center;  }
    th.left   { text-align:center;   }
    th.center { text-align:center; }
    td.right  { text-align:right;  }
    td.left   { text-align:left;   }
    td.center { text-align:center; }
    dt { font-weight: bold; }
    div.figure { padding: 0.5em; }
    div.figure p { text-align: center; }
    div.inlinetask {
      padding:10px;
      border:2px solid gray;
      margin:10px;
      background: #ffffcc;
    }
    textarea { overflow-x: auto; }
    .linenr { font-size:smaller }
    .code-highlighted {background-color:#ffff00;}
    .org-info-js_info-navigation { border-style:none; }
    #org-info-js_console-label { font-size:10px; font-weight:bold;
                                 white-space:nowrap; }
    .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                   font-weight:bold; }
    /*]]>*/-->
  </style>
  <script type="text/javascript">
  /*
  @licstart  The following is the entire license notice for the
  JavaScript code in this tag.
  
  Copyright (C) 2012-2013 Free Software Foundation, Inc.
  
  The JavaScript code in this tag is free software: you can
  redistribute it and/or modify it under the terms of the GNU
  General Public License (GNU GPL) as published by the Free Software
  Foundation, either version 3 of the License, or (at your option)
  any later version.  The code is distributed WITHOUT ANY WARRANTY;
  without even the implied warranty of MERCHANTABILITY or FITNESS
  FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.
  
  As additional permission under GNU GPL version 3 section 7, you
  may distribute non-source (e.g., minimized or compacted) forms of
  that code without the copy of the GNU GPL normally required by
  section 4, provided you include this license notice and a URL
  through which recipients can access the Corresponding Source.
  
  
  @licend  The above is the entire license notice
  for the JavaScript code in this tag.
  ,*/
  <!--/*--><![CDATA[/*><!--*/
   function CodeHighlightOn(elem, id)
   {
     var target = document.getElementById(id);
     if(null != target) {
       elem.cacheClassElem = elem.className;
       elem.cacheClassTarget = target.className;
       target.className = "code-highlighted";
       elem.className   = "code-highlighted";
     }
   }
   function CodeHighlightOff(elem, id)
   {
     var target = document.getElementById(id);
     if(elem.cacheClassElem)
       elem.className = elem.cacheClassElem;
     if(elem.cacheClassTarget)
       target.className = elem.cacheClassTarget;
   }
  /*]]>*///-->
  </script>
  
  </head>
  <body>
  
  <div id="preamble">
  
  </div>
  
  <div id="content">
    
    
  </div>
  
  <div id="outline-container-1-1" class="outline-4">
  <h4 id="sec-1-1"><span class="section-number-4">1.1</span>Introduction</h4>
  <div class="outline-text-4" id="text-1-1">
  
  
  <p>
  The collection of scientific data is undertaken at an individual level
  by everybody in their own way. The layout of data collections that I
  have seen is incredibly varied; spread across multiple files and folders which can
  be difficult to navigate or search through. In some cases
  these collections are incomprehensible to all but the individual themselves. Given
  that a lot of projects are collaborative in nature and require
  extensive sharing, it is important that scientists maintain their
  data collection by some form of system that allows easy data extraction and
  use in other projects. Therefore, the maintenance of a personal catalogue of datasets is an
  important activity for scientists.
  </p>
  <p>
  By cataloguing I mean that a file or database is kept that stores all the
  information about the names of the datasets (and any other files the
  data may be spread across), where the datasets are located, any
  references (papers) that were developed from it and finally
  important information regarding the conditions it
  was formed under.
  </p>
  <p>
  While this may seem laborious, it keeps track of all the data that one
  has collected over time and gives one a reference system to find a
  dataset of interest when sharing with collaborators. Datasets can be
  saved in any filing system the scientist chooses, but with the help of
  their personal data catalogue they will always know the status of
  their data collection.
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-2" class="outline-4">
  <h4 id="sec-1-2"><span class="section-number-4">1.2</span> Cataloguing Personal Research Data with Morpho</h4>
  <div class="outline-text-4" id="text-1-2">
  
  
  <p>
  [Metacat](<a href="https://knb.ecoinformatics.org/knb/docs/intro.html">https://knb.ecoinformatics.org/knb/docs/intro.html</a>) is an
  online repository for data and metadata. It is a great resource for
  the publication of data, but not very useful for an individual
  scientist to use on their personal computer.  However
  [Morpho](<a href="https://knb.ecoinformatics.org/#tools/morpho">https://knb.ecoinformatics.org/#tools/morpho</a>) the Metadata
  Editor used by Metacat may be used locally by a researcher to
  catalogue their collection (and ultimately this will make publishing
  elements of the collection easier.)  Morpho uses the Ecological
  Metadata Language (EML) to author metadata with a graphical user
  interface wizard.
  </p>
  <p>
  I am using morpho 1.8 due to my group using older metacat server.
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-3" class="outline-4">
  <h4 id="sec-1-3"><span class="section-number-4">1.3</span> How Morpho Works</h4>
  <div class="outline-text-4" id="text-1-3">
  
  
  <p>
  When you install Morpho it creates a directory where you can run the
  program from, and another hidden directory called ".morpho" for it's
  database of all your metadata (and optionally any data you import to
  it).  Below is an image of mine, with a couple of test records I
  played around with (the XMLs/HTMLs) and a dataset I imported (the text
  file).
  </p>
  <ul>
  <li>~/.morpho/profiles/hanigan/data/hanigan/
  </li>
  </ul>
  
  <p>
  <img src="/images/morphodir1.png" alt="morphodir1.png">
  </p>
  <p>  
  Every time a modification is made to the metadata a new XML is saved here, with the major number being the ID of the package and incremented minor number to reflect the change.
  </p>
  <p>
  The GUI is tedious.
  </p>
  
  </div>
  
  </div>
  
  <div id="outline-container-1-4" class="outline-4">
  <h4 id="sec-1-4"><span class="section-number-4">1.4</span> Adding a dataset from my collection</h4>
  <div class="outline-text-4" id="text-1-4">
  
  
  <p>
  I have already got a good amount of metadata I generated when I published [the drought data](<a href="http://dx.doi.org/10.4225/13/50BBFD7E6727A">http://dx.doi.org/10.4225/13/50BBFD7E6727A</a>)
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-5" class="outline-4">
  <h4 id="sec-1-5"><span class="section-number-4">1.5</span> the drought dataset:</h4>
  <div class="outline-text-4" id="text-1-5">
  
  <p>    Hanigan, Ivan (2012): Monthly drought data for Australia 1890-2008
      using the Hutchinson Drought Index. Australian National University Data Commons.
      DOI: 10.4225/13/50BBFD7E6727A. 
  </p>
  <p>
  &lt;p&gt;&lt;/p&gt;
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-6" class="outline-4">
  <h4 id="sec-1-6"><span class="section-number-4">1.6</span> Step One: define the project that I will keep locally</h4>
  <div class="outline-text-4" id="text-1-6">
  
  
  <ul>
  <li>This is the Github repo <a href="https://github.com/swish-climate-impact-assessment/DROUGHT-BOM-GRIDS">https://github.com/swish-climate-impact-assessment/DROUGHT-BOM-GRIDS</a>
  </li>
  <li>I store this locally at ~/data/DROUGHT-BOM-GRIDS
  </li>
  </ul>
  
  
  </div>
  
  </div>
  
  <div id="outline-container-1-7" class="outline-4">
  <h4 id="sec-1-7"><span class="section-number-4">1.7</span> Contextual Metadata</h4>
  <div class="outline-text-4" id="text-1-7">
  
  
  </div>
  
  </div>
  
  <div id="outline-container-1-8" class="outline-4">
  <h4 id="sec-1-8"><span class="section-number-4">1.8</span> Abstract</h4>
  <div class="outline-text-4" id="text-1-8">
  
  
  <p>
  I originally wrote the abstract as the description for a RIF-CS metadata object to publish for the ANU library.
  </p>
  <p>
  I got the following instructions from a Librarian: The "informative abstract" method.
  </p>
  <ul>
  <li>The abstract should be a descriptive of the data, not the research.
  </li>
  <li>Briefly outline the relevant project or study and describe the contents of the data package. 
  </li>
  <li>Include geographic location, the primary objectives of the study, what data was collected (species or phenomena), the year range the data was collected in, and collection frequency if applicable.
  </li>
  <li>Describe methodology techniques or approaches only to the degree necessary for comprehension – don’t go into any detail.
  </li>
  <li>Cite references and/or links to any publications that are related to the data package.
  </li>
  <li>Single paragraph
  </li>
  <li>200-250 words
  </li>
  <li>Use active voice and past tense.
  </li>
  <li>Use short complete sentences.
  </li>
  <li>Express terms in both their abbreviated and spelled out form for search retrieval purposes.
  </li>
  </ul>
  
  
  </div>
  
  </div>
  
  <div id="outline-container-1-9" class="outline-4">
  <h4 id="sec-1-9"><span class="section-number-4">1.9</span> Australian FOR codes</h4>
  <div class="outline-text-4" id="text-1-9">
  
  <p>ANZSRC-FOR Codes: Australian and New Zealand Standard Research Classification – Fields of Research codes allow R&amp;D activity to be categorised according to the methodology used in the R&amp;D, rather than the activity of the unit performing the R&amp;D or the purpose of the R&amp;D.  
  <a href="http://www.abs.gov.au/Ausstats/abs@.nsf/Latestproducts/4AE1B46AE2048A28CA25741800044242?opendocument">http://www.abs.gov.au/Ausstats/abs@.nsf/Latestproducts/4AE1B46AE2048A28CA25741800044242?opendocument</a>
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-10" class="outline-4">
  <h4 id="sec-1-10"><span class="section-number-4">1.10</span> GCMD Keywords</h4>
  <div class="outline-text-4" id="text-1-10">
  
  <p>Olsen, L.M., G. Major, K. Shein, J. Scialdone, S. Ritz, T. Stevens, M. Morahan, A. Aleman, R. Vogel, S. Leicester, H. Weir, M. Meaux, S. Grebas, C.Solomon, M. Holland, T. Northcutt, R. A. Restrepo, R. Bilodeau, 2013. NASA/Global Change Master Directory (GCMD) Earth Science Keywords. Version 8.0.0.0.0 
  <a href="http://gcmd.nasa.gov/learn/keyword_list.html">http://gcmd.nasa.gov/learn/keyword_list.html</a>
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-11" class="outline-4">
  <h4 id="sec-1-11"><span class="section-number-4">1.11</span> Geographic coverage</h4>
  <div class="outline-text-4" id="text-1-11">
  
  <p>    &gt; require(devtools)
      &gt; install<sub>github</sub>("disentangle", "ivanhanigan")
      &gt; require(disentangle)
      &gt; morpho<sub>bounding</sub><sub>box</sub>(d)
                        X1                 X2                 X3
      1               &lt;NA&gt; 10.1356954574585 S               &lt;NA&gt;
      2 112.907211303711 E               &lt;NA&gt; 158.960372924805 E
      3               &lt;NA&gt; 54.7538909912109 S               &lt;NA&gt;
  </p>
  
  </div>
  
  </div>
  
  <div id="outline-container-1-12" class="outline-4">
  <h4 id="sec-1-12"><span class="section-number-4">1.12</span> Save the metadata</h4>
  <div class="outline-text-4" id="text-1-12">
  
  
  <ul>
  <li>the metadata is now ready to save to my .morpho catalogue
  </li>
  <li>without importing any data
  </li>
  </ul>
  
  
  <p>
  <img src="/images/morphoimg2.png" alt="morphoimg2.png">
  </p>
  <ul>
  <li>this appears as a new XML
  </li>
  </ul>
  
  
  <p>
  <img src="/images/morphoimg3.png" alt="morphoimg3.png">
  </p>
  <ul>
  <li>which looks like this
  </li>
  </ul>
  
  
  <p>
  <img src="/images/morphoimg4.png" alt="morphoimg4.png">
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-13" class="outline-4">
  <h4 id="sec-1-13"><span class="section-number-4">1.13</span> Additional Metadata</h4>
  <div class="outline-text-4" id="text-1-13">
  
  
  <p>
  As this is metadata only about the dataset, it is innapropriate to refer to related publications etc in these elements.  Luckily EML has the additionalMetadata and additionalLinks fields.  Just open the XML and paste the following in the bottom.
  </p>
  <p>
      &lt;additionalMetadata&gt;
        &lt;metadata&gt;
          &lt;additionalLinks&gt;
            &lt;url name="Hanigan, IC, Butler, CD, Kokic, PN, Hutchinson, MF. Suicide and Drought in New South Wales, Australia, 1970-2007. Proceedings of the National Academy of Science USA 2012, vol. 109 no. 35 13950-13955, doi: 10.1073/pnas.1112965109"&gt;<a href="http://dx.doi.org/10.1073/pnas.1112965109">http://dx.doi.org/10.1073/pnas.1112965109</a>&lt;/url&gt;
          &lt;/additionalLinks&gt;
        &lt;/metadata&gt;
      &lt;/additionalMetadata&gt;
  </p>
  <p>
  You can see this if you then open it up again in morpho and then under the documentation menu go to Add/Edit Documentation.
  </p>
  <p>
  <img src="/images/morphoimg5.png" alt="morphoimg5.png">
  </p></div>
  </div>
  </div>
  </div>
  
  </body>
  </html>
    
  
#+end_src  

** 2014-04-20-using-morpho-orgmode
*** Introduction

The collection of scientific data is undertaken at an individual level
by everybody in their own way. The layout of data collections that I
have seen is incredibly varied; spread across multiple files and folders which can
be difficult to navigate or search through. In some cases
these collections are incomprehensible to all but the individual themselves. Given
that a lot of projects are collaborative in nature and require
extensive sharing, it is important that scientists maintain their
data collection by some form of system that allows easy data extraction and
use in other projects. Therefore, the maintenance of a personal catalogue of datasets is an
important activity for scientists.

By cataloguing I mean that a file or database is kept that stores all the
information about the names of the datasets (and any other files the
data may be spread across), where the datasets are located, any
references (papers) that were developed from it and finally
important information regarding the conditions it
was formed under.

While this may seem laborious, it keeps track of all the data that one
has collected over time and gives one a reference system to find a
dataset of interest when sharing with collaborators. Datasets can be
saved in any filing system the scientist chooses, but with the help of
their personal data catalogue they will always know the status of
their data collection.

*** Cataloguing Personal Research Data with Morpho

[Metacat](https://knb.ecoinformatics.org/knb/docs/intro.html) is an
online repository for data and metadata. It is a great resource for
the publication of data, but not very useful for an individual
scientist to use on their personal computer.  However
[Morpho](https://knb.ecoinformatics.org/#tools/morpho) the Metadata
Editor used by Metacat may be used locally by a researcher to
catalogue their collection (and ultimately this will make publishing
elements of the collection easier.)  Morpho uses the Ecological
Metadata Language (EML) to author metadata with a graphical user
interface wizard.

I am using morpho 1.8 due to my group using older metacat server.

*** How Morpho Works

When you install Morpho it creates a directory where you can run the
program from, and another hidden directory called ".morpho" for it's
database of all your metadata (and optionally any data you import to
it).  Below is an image of mine, with a couple of test records I
played around with (the XMLs/HTMLs) and a dataset I imported (the text
file).

- ~/.morpho/profiles/hanigan/data/hanigan/

![morphodir1](/images/morphodir1.png)
  
Every time a modification is made to the metadata a new XML is saved here, with the major number being the ID of the package and incremented minor number to reflect the change.

The GUI is tedious.


*** Adding a dataset from my collection

I have already got a good amount of metadata I generated when I published [the drought data](http://dx.doi.org/10.4225/13/50BBFD7E6727A)

*** the drought dataset:
    Hanigan, Ivan (2012): Monthly drought data for Australia 1890-2008
    using the Hutchinson Drought Index. Australian National University Data Commons.
    DOI: 10.4225/13/50BBFD7E6727A. 

<p></p>

*** Step One: define the project that I will keep locally

- This is the Github repo https://github.com/swish-climate-impact-assessment/DROUGHT-BOM-GRIDS
- I store this locally at ~/data/DROUGHT-BOM-GRIDS

*** Contextual Metadata

*** Abstract

I originally wrote the abstract as the description for a RIF-CS metadata object to publish for the ANU library.

I got the following instructions from a Librarian: The "informative abstract" method.

- The abstract should be a descriptive of the data, not the research.
- Briefly outline the relevant project or study and describe the contents of the data package. 
- Include geographic location, the primary objectives of the study, what data was collected (species or phenomena), the year range the data was collected in, and collection frequency if applicable.
- Describe methodology techniques or approaches only to the degree necessary for comprehension – don’t go into any detail.
- Cite references and/or links to any publications that are related to the data package.
- Single paragraph
- 200-250 words
- Use active voice and past tense.
- Use short complete sentences.
- Express terms in both their abbreviated and spelled out form for search retrieval purposes.

*** Australian FOR codes
ANZSRC-FOR Codes: Australian and New Zealand Standard Research Classification – Fields of Research codes allow R&D activity to be categorised according to the methodology used in the R&D, rather than the activity of the unit performing the R&D or the purpose of the R&D.  
http://www.abs.gov.au/Ausstats/abs@.nsf/Latestproducts/4AE1B46AE2048A28CA25741800044242?opendocument

*** GCMD Keywords
Olsen, L.M., G. Major, K. Shein, J. Scialdone, S. Ritz, T. Stevens, M. Morahan, A. Aleman, R. Vogel, S. Leicester, H. Weir, M. Meaux, S. Grebas, C.Solomon, M. Holland, T. Northcutt, R. A. Restrepo, R. Bilodeau, 2013. NASA/Global Change Master Directory (GCMD) Earth Science Keywords. Version 8.0.0.0.0 
http://gcmd.nasa.gov/learn/keyword_list.html

*** Geographic coverage
    # I developed the following function to take a spatial object and convert it to the bounding box
    > require(devtools)
    > install_github("disentangle", "ivanhanigan")
    > require(disentangle)
    > morpho_bounding_box(d)
                      X1                 X2                 X3
    1               <NA> 10.1356954574585 S               <NA>
    2 112.907211303711 E               <NA> 158.960372924805 E
    3               <NA> 54.7538909912109 S               <NA>


*** Save the metadata

- the metadata is now ready to save to my .morpho catalogue
- without importing any data

![morphoimg2.png](/images/morphoimg2.png)

- this appears as a new XML

![morphoimg3.png](/images/morphoimg3.png)

- which looks like this

![morphoimg4.png](/images/morphoimg4.png)

*** Additional Metadata 

As this is metadata only about the dataset, it is innapropriate to refer to related publications etc in these elements.  Luckily EML has the additionalMetadata and additionalLinks fields.  Just open the XML and paste the following in the bottom.

    <additionalMetadata>
      <metadata>
        <additionalLinks>
          <url name="Hanigan, IC, Butler, CD, Kokic, PN, Hutchinson, MF. Suicide and Drought in New South Wales, Australia, 1970-2007. Proceedings of the National Academy of Science USA 2012, vol. 109 no. 35 13950-13955, doi: 10.1073/pnas.1112965109">http://dx.doi.org/10.1073/pnas.1112965109</url>
        </additionalLinks>
      </metadata>
    </additionalMetadata>

You can see this if you then open it up again in morpho and then under the documentation menu go to Add/Edit Documentation.

![morphoimg5.png](/images/morphoimg5.png)
** 2014-04-20-a-workaround-for-inserting-species-names-to-morpho
#+name:a-workaround-for-inserting-species-names-to-morpho-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-20-a-workaround-for-inserting-species-names-to-morpho.md :exports none :eval no :padline no
  ---
  name: a-workaround-for-inserting-species-names-to-morpho
  layout: post
  title: A Workaround For Inserting Species Names To Morpho
  date: 2014-04-20
  categories:
  - Data Documentation
  ---
  
  Morpho is a pretty minimal editor for EML really.  It gives you a set
  of generically useful data entry forms but sometimes a specific task
  is better achieved through edits made directly to the XML document.
  An example of this is inserting a large number of species names to the
  taxonomic coverage module. The form to include these requires
  individual data entry for each species.
  
  ![morpho-taxo.png](/images/morpho-taxo-smll.png)
  
  Which looks like this when published
  
  ![morpho-taxo2.png](/images/morpho-taxo2.1.png)
  
  Go to the morpho catalogue (found at ~/.morpho/profiles/hanigan/data/hanigan/) and take a look at how the XML is constructed.
  
  #### XML Code:
      <taxonomicCoverage>
        <taxonomicClassification>
          <taxonRankName>Genus</taxonRankName>
          <taxonRankValue>Dasycercus</taxonRankValue>
          <taxonomicClassification>
            <taxonRankName>Species</taxonRankName>
            <taxonRankValue>cristicauda</taxonRankValue>
            <commonName>Mulgara</commonName>
          </taxonomicClassification>
        </taxonomicClassification>
        <taxonomicClassification>
          <taxonRankName>Genus</taxonRankName>
          <taxonRankValue>Homo</taxonRankValue>
            <taxonomicClassification>
            <taxonRankName>Species</taxonRankName>
            <taxonRankValue>sapiens</taxonRankValue>
            <commonName>Modern Human</commonName>
          </taxonomicClassification>
        </taxonomicClassification>
      </taxonomicCoverage>
  
  
  
  <p></p>
  
  
  
  #### SO how to insert a large number of these 
  
  One could use the taxon import feature to import the details from a
  file if there is a large list. Morpho’s taxon import feature does not
  correctly import more than one column of taxon data so if you have
  Genus and Species to enter you will actually need to combine Genus and
  Species into a binomial Species rank in one column (beware that if the data are sourced from a datafile that uses the underscore to seperate the words then these will not be correctly imported).  
  
  Once you have formated your input list, then import this
  as a new data table and go to the taxonomic coverage form under the
  documentation menu.  Click on the option to "import taxon information
  from data table" and select the appropriate column, selecting
  'species' for the class.  This will populate the taxonomicCoverage module in the EML.  You can now remove that data table from the package to be tidy.
  
  This is what it looks like if you combine genus and species in the single column.
  
  ![morpho-taxo3.png](/images/morpho-taxo3.png)
  
  And here is the XML
  
  #### XML Code:
      <taxonomicCoverage scope="document">
        <taxonomicClassification>
          <taxonRankName>Species</taxonRankName>
          <taxonRankValue>Abelmoschus moschatus</taxonRankValue>
        </taxonomicClassification>
        <taxonomicClassification>
          <taxonRankName>Species</taxonRankName>
          <taxonRankValue>Abrus pector</taxonRankValue>
        </taxonomicClassification>
        <taxonomicClassification>
          <taxonRankName>Species</taxonRankName>
          <taxonRankValue>Abrus precatorius</taxonRankValue>
        </taxonomicClassification>
  
  <p></p>
  
  #### Morpho has problems subsequently editing a very long list
  
  We found that if a very large amount of taxonomic information is entered into Morpho
  we had issues modifying it. When you click on Documentation >
  Taxonomic Coverage to try and go in and edit nothing will
  happen. Morpho crashes when trying to open the Taxonomic Coverage
  because the list is long enough to cause “Out of Memory” error with
  the default configuration of Java heap space. It is a Morpho bug. The
  workaround is to edit the XML file manually.
  
  
#+end_src

** 2014-04-21-linking-eml-packages-by-umbrella-project-info
#+name:linking-eml-packages-by-umbrella-project-info-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-21-linking-eml-packages-by-umbrella-project-info.md :exports none :eval no :padline no
  ---
  name: linking-eml-packages-by-umbrella-project-info
  layout: post
  title: linking-eml-packages-by-umbrella-project-info
  date: 2014-04-21
  categories:
  - Data Documentation
  ---
  
  In Eml the optional "project" module provides an overall description
  of the larger-scale project or research context with which that
  dataset is associated. For the examples in our work the "project" will
  most often be an LTER (Longterm Ecological Research Network) site that
  directed the research.  Accordingly, the "title" here consists of the
  name of the LTER site. The "personnel" group contains the same
  elements as "creator" and "contact", with the addition of a mandatory
  "role" element, and it is used to identify the lead PI and/or
  information manager on the site. Other optional elements in the
  "project" module include "abstract", "funding",
  "studyAreaDescription", and "designDescription", each of which can be
  used to provide a richer textual description of the LTER site
  responsible for the research project being documented.  If used, the
  "abstract" includes basic information about the LTER site, such as its
  general history and administration, while "studyAreaDescription" is
  more of a physical description of the area where the site is
  located. This description may also include the "coverage" module,
  which is fully discussed on page XX of this handbook, or the
  "citation" module, covered on page XX. The "funding" tag is textual
  and self-explanatory, but "designDescription" is best used for a
  description of the site’s database information and availability.
  
  Morpho doesn't give all these options so you need to go to the EML file found in the "~/.morpho/..." directory and edit this with a text editor
  I think the order of the tags here might make a difference so I always put thye "abstract" tag after the "/personnel" tag.  I also think you might need this "para" tag:
  
  #### Code:linking-eml-packages-by-umbrella-project-inf
      <abstract> 
        <para>Prof McMichael set up this group to develop new methods of researching Environmental (especially Climate Change) and Health
        </para>
      </abstract>
  
  <p></p>
  
  So this gives the overarching project a valid reference, but how to provde the links for interested readers to find out more?  First we can include a link to the project homepage from the eml/dataset/abstract node, but also we can provide URLs in a machine-readable way by inserting an "additionalLinks" node at the bottom of the EML:
  
  #### Code:linking-eml-packages-by-umbrella-project-info
      <additionalMetadata>
        <metadata>
          <additionalLinks>
            <url name="The name of the homepage">http://...</url>
          </additionalLinks>
        </metadata>
      </additionalMetadata>
      
  
      
#+end_src

** 2014-04-24-using-reml-to-input-large-number-of-column-descriptions
#+name:using-reml-to-input-large-number-of-column-descriptions-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-24-using-reml-to-input-large-number-of-column-descriptions.md :exports none :eval no :padline no
  ---
  name: using-reml-to-input-large-number-of-column-descriptions
  layout: post
  title: Using Reml To Input Large Number Of Column Descriptions
  date: 2014-04-24
  categories:
  - Data Documentation
  tags: 
  - morpho
  - R-eml
  ---
  
  We recently hit an issue when using morpho to enter metadata for a large number of variables (~200).  The GUI form for entering definitions and units steps through each variable, but at about 60 or 70 it starts to slow down.  By the time we got to 160 it was taking more than 5 minutes to change to the next variable.  To safegaurd against losing work, we kept hitting "save for later" but this got slower and apeared to freeze at the last minute...  Not sure if that last save worked at all.
  
  So I;ve come back once more to the ROpenSci EML package which is looking like a really useful way to build metadata elements automatically, with Morpho being used to proved augmentation and finesse the documents.
  
  First thing I tried was the constructed Column Definitions and Unit Definitions example from [the README](https://github.com/ropensci/EML)
  
  #### R Code:
      #require(devtools)
      #install_github("EML", "ROpenSci")
      require(EML)
       
      # The example from orig doco
      dat = data.set(river = c("SAC",  "SAC",   "AM"),
                     spp   = c("king",  "king", "ccho"),
                     stg   = c("smolt", "parr", "smolt"),
                     ct    = c(293L,    410L,    210L),
                     col.defs = c("River site used for collection",
                                  "Species common name",
                                  "Life Stage",
                                  "count of live fish in traps"),
                     unit.defs = list(c(SAC = "The Sacramento River",
                                        AM = "The American River"),
                                      c(king = "King Salmon",
                                        ccho = "Coho Salmon"),
                                      c(parr = "third life stage",
                                        smolt = "fourth life stage"),
                                      "number"))
      str(dat)
      eml_config(creator="Carl Boettiger <cboettig@gmail.com>")
      eml_write(dat, file = "inst/doc/EML_example.xml")
      # now you can import this to morpho and have a look
      # note that for morpho 1.8 it wants to change the EML version from 2.1.1 to 2.1.0
      # and it can't show the data yet
      # so what we need to do is write this as a file to the morpho database
      # save and close, note which number it assigned
      dat <- data.frame(dat)
      morpho_db  <- "~/.morpho/profiles/hanigan/data/hanigan/"
      maxid  <-  1+max(as.numeric(dir(morpho_db)))
      filename <- file.path(morpho_db,maxid)
      # what is the number?
      filename
      write.csv(dat, filename, row.names =F, quote=F)
  
  
  <p></p>
  
  So now to finish what we need to add into the EML that morpho has created (22.1 in my case)  just needs the reference to the dataTable.
  
  #### EML Code:
      ...
      </dataFormat>
      <distribution scope="document"> <online> <url function="download">ecogrid://knb/hanigan.22.1</url>
      </online>
      <access authSystem="knb" order="denyFirst"><allow><principal>uid=datalibrarian,o=unaffiliated,dc=ecoinformatics,dc=org</principal>
      <permission>all</permission>
      </allow>
      <allow><principal>uid=hanigan,o=unaffiliated,dc=ecoinformatics,dc=org</principal>
      <permission>read</permission>
      </allow>
      </access>
      </distribution>
      </physical>
      ...
  
  <p></p>
  
  Which seems to have worked when we open it up again:
    
  ![moprho-wide1.png](/images/morpho-wide1.png)
  
  So now let;s try a large nuber of variables:
  
  #### R Code:
      # add lots of cols
      for(i in 5:100){
        dat[,i] <-  sample(rnorm(100,1,2), 3)
      }
      str(dat)
      ##  $ V95  : num  1.5708 -0.0936 2.2324
      ##  $ V96  : num  1.79 5.4 1.62
      ##  $ V97  : num  -1.141 0.653 5.365
      ##  $ V98  : num  1.738 -1.046 -0.135
      ##  $ V99  : num  3.6 -0.738 -1.877
      ##   [list output truncated]
  
      # firstly I make a liset of the unit definitions for the example
      unit.defs <- list(c(SAC = "The Sacramento River",
                         AM = "The American River"),
                       c(king = "King Salmon",
                         ccho = "Coho Salmon"),
                       c(parr = "third life stage",
                         smolt = "fourth life stage"))
      # then I add to it the definition for the constructed variables
      unit.defs[[3]]
      for(i in 4:100){
        unit.defs[[i]] <- "number"
      }
      unit.defs
  
      # and this can be passed to the data.set constructor
      dat <- data.set(dat,
                     col.defs = c("River site used for collection",
                                  "Species common name",
                                  "Life Stage",
                                  "count of live fish in traps",
                                 c(rep("count stuff", 95))),
                      unit.defs = unit.defs
                      )
      str(dat)
       
      eml_config(creator="Ivan Charles Hanigan <ivan.hanigan@gmail.com>")
      eml_write(dat, file = "inst/doc/EML_example_wide.xml")
      # import to morpho, save and close
      # create the dataset for morphos database
      dat <- data.frame(dat)
      morpho_db  <- "~/.morpho/profiles/hanigan/data/hanigan/"
      maxid  <-  1+max(as.numeric(dir(morpho_db)))
      filename <- file.path(morpho_db,maxid)
      # what is the number?
      filename
      write.csv(dat, filename, row.names =F, quote=F)
      # now add this into the EML morpho has created (25.2 in my case)
  
  <p></p>
  
  Which now seems to have attached the variable defintions and dataTable adequately.
  
  ![morpho-wide2.png](/images/morpho-wide2.png)
#+end_src

** 2014-04-25-tweaking-r-eml-package-outputs-with-morpho-and-failing-that-with-emacs
#+name:tweaking-r-eml-package-outputs-with-morpho-and-failing-that-with-emacs-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-25-tweaking-r-eml-package-outputs-with-morpho-and-failing-that-with-emacs.md :exports none :eval no :padline no
  ---
  name: tweaking-r-eml-package-outputs-with-morpho-and-failing-that-with-emacs
  layout: post
  title: Tweaking R Eml Package Outputs With Morpho And Failing That With Emacs
  date: 2014-04-25
  categories:
  - Data Documentation
  tags: 
  - morpho
  - R-eml
  ---
  
  I realised that the work I did yesterday had an error in it.  I'd
  created a list of unit.defs with one less than I needed.  So the
  variable V100 was given the definition of NA!  I can fix this by open
  that package in Morpho and go to the column and select it, then under
  the Data menu, choose Edit Column Documentation.  There we can change
  all the definitions.  Now I start thinking about changing the type
  from count to ArealDensity, numberPerMeterSquared.  To change all
  these new variables I don't want to go thru the GUI 95 times!  Change
  the first one and then look at the EML
  
  #### EML Code:
      <attribute id="1398382425052">
        <attributeName>V99</attributeName>
        <attributeDefinition>count stuff</attributeDefinition>
        <measurementScale>
          <ratio>
            <unit><standardUnit>number</standardUnit></unit>
            <numericDomain><numberType>real</numberType></numericDomain>
          </ratio>
        </measurementScale>
      </attribute>
      <attribute id="1398382385863">
        <attributeName>V100</attributeName>
        <attributeDefinition>A random variable</attributeDefinition>
        <measurementScale>
          <ratio>
            <unit><standardUnit>numberPerMeterSquared</standardUnit></unit>
            <numericDomain><numberType>real</numberType></numericDomain>
          </ratio>
        </measurementScale>
      </attribute>
  
  <p></p>
  
  So this looks like I can do a find and replace in Emacs so go to the
  "~/.morpho" database and make a copy of the appropriate EML (number was in the morpho saved) and rename it with the increment up one of the minor version. Open this and run the find and replace.
  
  #### Code:
      <standardUnit>number<
      to
      <standardUnit>numberPerMeterSquared<
  
  <p></p>
  
  Which was a much quicker way to redefine all these.  Save to our Metacat Network and it shows up as I wanted it to.
  
  ![morpho-wide3.png](/images/morpho-wide3.png)
  
  ## Conclusions
  - Morpho and a code editor can be used in conjunction to edit EML quite well
  - I suspect edits to the EML directly with a code editor are pretty dangerous
  - For eg if you do the wrong change then that EML will likely not be valid and Morpho will complain.
  - But the advantage of quickly modifying things like 100 variables unit definitions rather than opening every one in the GUI seems to be a worthwhile risk to me.
  
  
  
  
#+end_src

** 2014-04-29-using-r-eml-to-input-large-numbers-of-variables-part-2
#+name:using-r-eml-to-input-large-numbers-of-variables-part-2-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-29-using-r-eml-to-input-large-numbers-of-variables-part-2.md :exports none :eval no :padline no
  ---
  name: using-r-eml-to-input-large-numbers-of-variables-part-2
  layout: post
  title: using-r-eml-to-input-large-numbers-of-variables-part-2
  date: 2014-04-29
  categories:
  - Data Documentation
  tags: 
  - morpho
  - R-eml
  ---
  
  In my [previous post](/2014/04/using-reml-to-input-large-number-of-column-descriptions) I showed a workaround to input large number of variabels than Morpho could handle.  I have found out an interesting thing about the R EML package data.set approach.  The unit.defs depends on the type of the column in the data frame (R knows if you try to trick it).  Rather than describe all the levels of the factor vars, I wanted to just have simple descriptions for numeric or character type columns.  If numeric it should be number and if character it can be the name of the column.  Because I am just trying to sidestep the issue with morpho failing to input the 200 plus variables I just need to create a dataframe with either number or character (not factor).
  
  For an example:
  
  #### R Code:
      require(EML)
      fname <- dir("myData", full.names=T, pattern = 'csv')
      fname
      fname  <- "myData/paper_data.csv"  
      dat  <- read.csv(fname, stringsAsFactor=F)
      # the variable names include special characters such as % and [ so need to do some extra work
      names_dat  <- read.csv(fname, nrow=1, header=F, stringsAsFactor=F)
      names(dat) <- names_dat
      head(dat)
      nrow(dat)
      # the first 46 variables are nominal, thereafter they are all numeric
      str(dat[,1:46])
      str(dat[,47:49])
      # but these numerics are character for some reason
      table(dat[ , 47])
      # it is because the raw data had * instead of NA...  I could use na.strings when I call read.table above, or deal with it here
      # I'll just convert them to numerics now
      dat1 <- dat[,1:46]
      dat2 <- dat[,47:ncol(dat)]
      dat2[dat2 == "*"] <- NA
      for(i in 1:ncol(dat2)){
        dat2[,i]  <- as.numeric(dat2[ , i])
      }
      str(dat2)
      # good that has set them up properly, also make sure all the text are character type
      for(i in 1:ncol(dat1)){
        dat1[,i]  <- as.character(dat1[ , i])
      }
      # recombine
      dat <- cbind(dat1,dat2)
      str(dat)
      # then I add to it the definition for the constructed variables
      unit_defs <- list()
      for(i in 1:46){
          unit_defs[[i]] <- names(dat[i])
      }
      for(i in 47:ncol(dat)){
          unit_defs[[i]] <- "number"
      }
      unit_defs[1:20]
      col_defs <- names(dat)
      col_defs
      #names(dat)
      dat <- data.set(dat,
                     col.defs = col_defs,
                     unit.defs = unit_defs
                     )
      str(dat)
      
      eml_config(creator="Ivan Charles Hanigan <ivan.hanigan@gmail.com>")
      dir()
      oldwd <- getwd()
      setwd("myData")
      eml_write(dat, file = "test_eml.xml", title = "test_eml")
      setwd(oldwd)
  
  
  <p></p>
  
  ### Use Morpho to tidy up the Results

  - The result can be imported to Morpho and then edited from there
  - or you can use a code editor like emacs or notepad++ to do bulk find-and-replace operations to fix up issues

  ### Conclusions
  
  - Morpho failed with 200 plus variables
  - the R EML package succeeded to write the file
  - I needed to pay careful attention to the type of the variables in the data.frame before running the R EML functions
#+end_src
** 2014-04-29-workaround-for-installing-morpho-on-a-windows-network
#+name:workaround-for-installing-morpho-on-a-windows-network-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-29-workaround-for-installing-morpho-on-a-windows-network.md :exports none :eval no :padline no
  ---
  name: workaround-for-installing-morpho-on-a-windows-network
  layout: post
  title: workaround-for-installing-morpho-on-a-windows-network
  date: 2014-04-29
  categories:
  - Data Documentation
  tags:
  - morpho
  ---
  
  ### Introduction
  
  Morpho is an open source piece of software designed to host all kinds of ecological data.  It is used to describe data collections. We publish to Metacat using Morpho.  For technical reasons, we have our own server running an older version of the Metacat software so have to run an old version of Morpho (v1.8).
    
  ### Installation and configuration
  
  TERN specific instructions are replicated across:
  
  - [http://www.tern-supersites.net.au/index.php/data/repository-tutorial](http://www.tern-supersites.net.au/index.php/data/repository-tutorial)
  - [http://www.ltern.org.au/index.php/data/guides-and-tutorial](http://www.ltern.org.au/index.php/data/guides-and-tutorial)
  
  ### Morpho issue on Windows in our network environment
  
  The ANU Fenner School came across this issue. Our local IT department have discovered with Morpho (v1.8) Installation on Windows in our network environment, Morpho installs a hidden directory called ".morpho" and this is written to a PATH next to the User Desktop. This is actually on a network share with a very small quota.
  
  Therefore as Morpho writes data there it can easily exceed the quota causing the software to stop working.  All users of Morpho on such a network should check for the location of the ".morpho" directory and if it is located with such a restricted quota then alternative arrangements need to be made.
  
  At the ANU Fenner School we opted to set up local user accounts (the ".morpho" file is then on the C drive) and this user is accessible from the main User's account.  The Morpho files are therefore stored on the C drive which is of course a danger for hard disk failure and data loss.
  
  We feel that as long as the draft packages are saved to the networked Metacat (with the maximum access restrictions in force for draft work) then if the local hard disk dies then the draft data package is not lost but can be accessed again from a new Morpho install and the Metacat server.
  
  Issues remain about the long term solution to this problem but this will work in the short-term.
  
  We think you can also create a junction (symlink) so that .morpho/ can point to a different location (perhaps another network storage with bigger capacity and automated backup).
#+end_src

** 2014-05-02-morpho-has-an-issue-with-zero-length-strings-as-missing-data
#+name:morpho-has-an-issue-with-zero-length-strings-as-missing-data-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-05-02-morpho-has-an-issue-with-zero-length-strings-as-missing-data.md :exports none :eval no :padline no
  ---
  name: morpho-has-an-issue-with-zero-length-strings-as-missing-data
  layout: post
  title: morpho-has-an-issue-with-zero-length-strings-as-missing-data
  date: 2014-05-02
  categories:
  - Data Documentation
  tags: 
  - morpho
  - bugs
  ---
  
  We encountered a strange issue Morpho 1.8 has when ingesting a CSV with zero length strings as missing data.  An example of what this looks like is given below in the mulgara example dataset I;ve shown before.  I have added some rows with missing data as zero length strings (these are the ",," after the fictional value Treat = 0.5).
  
  #### R Code:
      datatext <- 'Treat, Before, After1, After2
      a,,-9999,9999
      a,,-9999,9999
      a,,-9999,9999
      a,,-9999,9999
      a,,-9999,9999
      a,,-9999,9999
      a,,-9999,9999
      a,,-9999,9999
      0,  2.833213344,    1.609437912,    2.48490665
      0,  1.791759469,    2.197224577,    2.079441542
      0,  3.044522438,    2.708050201,    3.135494216
      0,  2.772588722,    1.791759469,    2.197224577
      0,  1.098612289,    1.609437912,    2.63905733
      1,  2.944438979,    0.693147181,    1.791759469
      1,  2.564949357,    0.693147181,    1.791759469
      1,  2.564949357,    1.609437912,    1.609437912
      1,  0.693147181,    1.098612289,    1.098612289
      1,  1.609437912,    0,      1.098612289'
      analyte <- read.csv(textConnection(datatext))
      write.csv(analyte, "inst/extdata/morpho-bug-empty-na.csv", row.names = F, na= "", quote=F)
  
  <p></p>
  
  - Unfortunately for this blog entry, the example above doesn;t exhibit the problem!
  - you can see what happens by selecting the "treat consecutive delimiters as as one" option
  - showing that the data from the 3rd and 4th cols shifts to the right
  - this is what happened to us but we were not able to modify this behaviour by changing that option!
  - The problem only occurred when we had a file big file (200+ columns)
  - the problem occured at col 23, shown in the image below
  
  ![morpho-bug-empty-na3.png](/images/morpho-bug-empty-na3.png)
  
  - this column is ftyp[12] which has 62 rows of missing and then some text codes.
  - the next 24th column is  aerial[10] and it is this one that is then read incorrectly by morpho.  The importer makes the error of reading blanks for the first few rows and then *, even though in reality it is * and then date 1/06/2006 (shown in the image below)
  
  ![morpho-bug-empty-na2.1.png](/images/morpho-bug-empty-na2.1.png)
  
  - and finally col 25 fire[13] now appears as * and the date 1/06/2006 but it should be a different number of *s and the date 2/04/2007 further down
  
  ![morpho-bug-empty-na2.png](/images/morpho-bug-empty-na2.png)
  
  ### Workaround
  
  - to deal with this in this case we replaced all zero length strings as "NA"
  - this is probably a good idea in most cases, except when NA is not an appropriate value and so in those cases we replaced with the word "blank"
  
  ### Conclusions
  
  - This issue is probably rare and might be fixed in the newer version of Morpho
  - We don;t use new morpho because we are still using the old metacat
  - I thought it worth reporting here
      
#+end_src

** advanced EML for data integration
*** Adding the data location 
    https://im.lternet.edu/node/1119
    This element is found at these locations (XPath):
    /eml:eml/dataset/distribution
    /eml:eml/dataset/[entity]/physical/distribution 
     
    The <distribution> element appears at the dataset and entity
    levels and contains information on how the data described in the
    EML document can be accessed. The <distribution> element has one
    of three children for describing the location of the resource:
    <online>, <offline>, and <inline>.
     
    Offline Data: Use the <offline> element to describe restricted
    access data or data that is not available online. The minimum that
    should be included is the <mediumName> tag, if using the <offline>
    element.
     
    Inline Data: The <inline> element contains data that is stored
    directly within the EML document. Data included as text or string
    will be parsed as XML. If data are not to be parsed, encode them
    as “CDATA sections,” by surrounding them with
    “<![CDATA[“ and “]]>” tags.
     
    Online Data: The <online> element has two sub elements, <url>, and
    <onlineDescription> (optional).  <url> tags may have an optional
    attribute named function, which may be set to either “download” or
    “information”. If the URL provides only information about
    downloading the object but does not directly return the data
    stream, then the function attribute should be set to
    "information". If accessing the URL directly returns the data
    stream, then the function attribute should be set to "download".
    If the function attribute is omitted, then "download" is implied

*** Backing up and restoring your Morpho catalogue

- one option is metacat, but requires overhead of install/manage that server too
- just copy the .morpho folder to your backup drive
- test on another machine by install morpho
- copy .morpho to my ~/ drive
- start morpho
- next time want to test backups or bring this up to sync just overwrite .morpho and restart morpho?

- test upgrading to morpho 1.10, just use uninstaller (tools/morpho1.8/Uninstaller, java -jar uninstaller.jar) then install newer version  
** 2014-05-09-cwt-lter-data-submission-template-critique
#+name:cwt-lter-data-submission-template-critique-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-05-09-cwt-lter-data-submission-template-critique.md :exports none :eval no :padline no
---
name: 2014-05-09-cwt-lter-data-submission-template-critique
layout: post
title: cwt-lter-data-submission-template-critique
date: 2014-05-09
categories:
- Data Documentation
tags:
- morpho
---

- I recently reviewed a tool for collecting metadata about Long Term Ecological Resarch (LTER) data 
- it is just an Excel spreadsheet called cwt\_data\_subm\_template\_2013.xls 
- You can download a copy here [www.coweeta.uga.edu/resources/forms/cwt_data_subm_template_2013.xls](http://www.coweeta.uga.edu/resources/forms/cwt_data_subm_template_2013.xls)
- LTER is The U.S. Long-Term Ecological Research (LTER) network
- I made the following notes, this is not intended to be a nasty critique
- The following is a few Frank and Fearless comments I'll be using to compare the pros and cons of a variety of data documentation approaches

#### Critique

- opened first on windows, saw comments on cells with instructions
- opened next on linux with libreOffice and comments are gone
- opened at the last tab (split in two for no reason?)
- noticed recommended name "GCE site" = Site, otherwise "permanent plot" =	Plot?
- [GCE = Georgia Coastal Ecosystems LTER program](http://nsmn1.uh.edu/steve/research/gce/gce.htm)
- flip to first tab, point 4 suggests there is some export functionality I cannot see (a VBA script?)
- cell 11 a    NOTE: When submitting updated metadata or re-using templates please highlight fields with modified contents in yellow
- and use glitter pen??? (See this great post [called excel-is-not-your-lab-notebook!](http://practicaldatamanagement.wordpress.com/2013/12/16/excel-is-not-your-lab-notebook/)
- personnell tab OK
- instrumentation, variable measured is free text. ok but for eg "max temp", "temperature maxima", "maximum temperature (c)" "maximum temperature in 24 hours after 9am local time in degrees" etc
- too wide, last column was off my wide screen! noticed wasted real estate in column A


#### Moving on to the  tabular data sheet
- I don't like this "–  Paste or enter your data values into the 'Values' section (white cells), starting with the indicated cell"
- this is an invitation for clerical error! Too many "copy-and-paste" actions will inevtably introduce errors

I do like the extra metadata Column Name:

- Description:
- Units:
- Data type:
- Variable type:
- Number type:
- Precision:
- Code values:
- Calculations:
- QC: Minimum Valid:
- QC: Minimum Expected:
- QC: Maximum Expected:
- QC: Maximum Valid:
- QC: Custom:

#### Other issues:
– Fill in missing values in the table with NaN (not a number), including text fields, and do not skip columns
- but what about missing values imbued with other meanings (NA = not observed, censored etc)?
- ask users to format digit rounding in Excel?? oh no
- old excel users may still be restricted to 65,536 rows by 256 columns.
- non tabular sheet is ok
    
#+end_src
** 2014-05-17-using-additional-header-rows-for-metadata
#+name:using-additional-header-rows-for-metadata-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-05-17-using-additional-header-rows-for-metadata.md :exports none :eval no :padline no
  ---
  name: 2014-05-17-using-additional-header-rows-for-metadata
  layout: post
  title: using-additional-header-rows-for-metadata
  date: 2014-05-17
  categories:
  - Data Documentation
  ---
  
  
  <body>
  <div id="toc">
  <div id="toc_header">Table of Contents</div>
  <ul>
  <li>
  <a href="#toc_0">Comment on eMast recommendations</a>
  <ul>
  <li>
  <ul>
  <li>
  <a href="#toc_1">Introduction</a>
  </li>
  <li>
  <a href="#toc_2">R code</a>
  <ul>
  <li>
  <a href="#toc_3">Construct some fake data</a>
  </li>
  <li>
  <a href="#toc_4">Run the aggregation of trait data program provided in eMast doc</a>
  </li>
  <li>
  <a href="#toc_5">Minor modifications to make it work</a>
  </li>
  <li>
  <a href="#toc_6">Now finish off with the example code</a>
  </li>
  </ul>
  </li>
  </ul>
  </li>
  </ul>
  </li>
  </ul>
  </div>
  
  
  <h1 id="toc_0">Comment on eMast recommendations</h1>
  
  <p><a href="mailto:ivan.hanigan@anu.edu.au">ivan.hanigan@anu.edu.au</a></p>
  
  <h3 id="toc_1">Introduction</h3>
  
  <ul>
  <li>I was lucky to be forwarded a copy of the document &ldquo;DRAFT Best practices for collecting, processing and collating plant trait data&rdquo; (V0.0).</li>
  <li>What I like most about this is the statement on page nine under &ldquo;3. Best practice collection techniques&rdquo; 
  that &ldquo;Datasets should be maintained following two simple practices of formatting and cataloguing&rdquo;.</li>
  <li>I think the recomendations are very sensible but I have the following comment regarding the proposed file structure shown in the table </li>
  </ul>
  
  <p><img src="data:image/png;base64,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" alt="emast-format.png"/></p>
  
  <ul>
  <li>I have not used the second row for the units before, but rather have encoded this information in a second metadata file that I keep with the main data file.</li>
  <li>This second row does seem attractive </li>
  <li>BUT  as this might be interpreted as the first row of data after the header row of column names this needs extra code to be written to allow importation to statistics packages.</li>
  <li>While this can be easily handled by writing extra code to treat this first row separately,  this does seem a bit risky to expect ordinary data users to do so.</li>
  <li>I wonder if the intention of the authors is to include this in the column NAME rather than just in the column as the statement currently reads (&ldquo;the units of measurement and an expanded definition of the data recorded in each column&rdquo;) and the table shows?</li>
  <li>For example the R code given in the Appendix &ldquo;R script to aggregate unprocessed trait data into summary statistics ready for the EMP DATABASE&rdquo;</li>
  </ul>
  
  <h3 id="toc_2">R code</h3>
  
  <ul>
  <li>The eMast Document provides an interesting appendix with R codes.<br/></li>
  <li>The following is an attempt to make a vignette that will run with the example data provided. </li>
  </ul>
  
  <h4 id="toc_3">Construct some fake data</h4>
  
  <pre><code class="r">
  dat &lt;- read.csv(textConnection(&quot;Date    ,Latitude,Longitude,Genus,Species,Tree No.,Meas. No.,Photosynthesis,Air Temp.,Height\n         ,      oS,       oE,          ,       ,   , ,umol m-2 s-1, oC, m\n1/10/2004,-43.4444,140.1453 ,Eucalyptus,Saligna,  1,1,15.043,25.56,15\n1/10/2004,-43.4444,140.1453 ,Eucalyptus,Saligna,  1,2,15.998,25.56,15\n1/10/2004,-43.4444,140.1453 ,Eucalyptus,Saligna,  1,3,15.584,25.56,15\n&quot;))
  # write a couple of fake data files
  for (i in 1:2) {
      write.csv(dat, paste(&quot;Book&quot;, i, &quot;.csv&quot;, sep = &quot;&quot;), row.names = F)
  }
  # show me the data
  print(xtable(dat), type = &quot;html&quot;)
  </code></pre>
  
  <!-- html table generated in R 3.1.0 by xtable 1.7-1 package -->
  
  <!-- Wed May  7 16:19:23 2014 -->
  
  <TABLE border=1>
  <TR> <TH>  </TH> <TH> Date </TH> <TH> Latitude </TH> <TH> Longitude </TH> <TH> Genus </TH> <TH> Species </TH> <TH> Tree.No. </TH> <TH> Meas..No. </TH> <TH> Photosynthesis </TH> <TH> Air.Temp. </TH> <TH> Height </TH>  </TR>
    <TR> <TD align="right"> 1 </TD> <TD>           </TD> <TD>       oS </TD> <TD>        oE </TD> <TD>            </TD> <TD>         </TD> <TD align="right">  </TD> <TD align="right">  </TD> <TD> umol m-2 s-1 </TD> <TD>  oC </TD> <TD>  m </TD> </TR>
    <TR> <TD align="right"> 2 </TD> <TD> 1/10/2004 </TD> <TD> -43.4444 </TD> <TD> 140.1453  </TD> <TD> Eucalyptus </TD> <TD> Saligna </TD> <TD align="right">   1 </TD> <TD align="right">   1 </TD> <TD> 15.043 </TD> <TD> 25.56 </TD> <TD> 15 </TD> </TR>
    <TR> <TD align="right"> 3 </TD> <TD> 1/10/2004 </TD> <TD> -43.4444 </TD> <TD> 140.1453  </TD> <TD> Eucalyptus </TD> <TD> Saligna </TD> <TD align="right">   1 </TD> <TD align="right">   2 </TD> <TD> 15.998 </TD> <TD> 25.56 </TD> <TD> 15 </TD> </TR>
    <TR> <TD align="right"> 4 </TD> <TD> 1/10/2004 </TD> <TD> -43.4444 </TD> <TD> 140.1453  </TD> <TD> Eucalyptus </TD> <TD> Saligna </TD> <TD align="right">   1 </TD> <TD align="right">   3 </TD> <TD> 15.584 </TD> <TD> 25.56 </TD> <TD> 15 </TD> </TR>
     </TABLE>
  
  <h4 id="toc_4">Run the aggregation of trait data program provided in eMast doc</h4>
  
  <pre><code class="r">
  library(stringr)
  # This function summarises the data, one just needs to past the parameter of
  # interest and the quantities by which it varies around.
  do.sumy &lt;- function(pars, lab, dat) {
      epars &lt;- as.formula(pars)
      mu &lt;- aggregate(epars, data = dat, mean)
      md &lt;- aggregate(epars, data = dat, median)
      se &lt;- aggregate(epars, data = dat, sd)
      mx &lt;- aggregate(epars, data = dat, min)
      mn &lt;- aggregate(epars, data = dat, max)
      NN &lt;- aggregate(epars, data = dat, length)
      drp0 &lt;- unlist(strsplit(pars, &quot;\\+&quot;))
      drp &lt;- -length(drp0):-1
      df1 &lt;- cbind(mu, md[, drp], se[, drp], mx[, drp], mn[, drp], NN[, drp])
      df2 &lt;- cbind(df1, Parameter = lab)
      hd1 &lt;- gsub(&quot;^\\w.*.~&quot;, &quot;&quot;, drp0)
      names(df2) &lt;- c(hd1, &quot;Mean&quot;, &quot;Median&quot;, &quot;Std&quot;, &quot;Min&quot;, &quot;Max&quot;, &quot;N&quot;, &quot;Parameter&quot;)
      return(df2)
  }
  
  # Not Required setwd(&#39;~/where/is/the/data/?&#39;)
  files &lt;- list.files(pattern = &quot;*.csv&quot;)
  # files
  data &lt;- lapply(files, read.csv, header = T, stringsAsFactors = F, strip.white = T)
  </code></pre>
  
  <h4 id="toc_5">Minor modifications to make it work</h4>
  
  <ul>
  <li>I needed to write the following to read the csv with metadata row</li>
  </ul>
  
  <pre><code class="r">
  #### Notes str(data) as expected, these are sometimes imported as character due
  #### to the second row so need to fix it also because the data object is a list
  #### of data.frames, it is easier to run the example if we will just create
  #### individual data frames
  read_metadata_csv &lt;- function(filename) {
      dat &lt;- read.csv(filename, skip = 1)
      col.defs &lt;- names(read.csv(filename, nrow = 0))
      unit.defs &lt;- read.csv(filename, nrow = 1, stringsAsFactors = F)
      attributes(dat)$unit.defs &lt;- unit.defs[1, ]
      names(dat) &lt;- col.defs
      return(dat)
  }
  # files
  data &lt;- read_metadata_csv(files[1])
  # str(data)
  </code></pre>
  
  <h4 id="toc_6">Now finish off with the example code</h4>
  
  <pre><code class="r">#### NOTE this is not relevant here so commented out If the Genus and Species
  #### is not separate, then split it up split.spp &lt;- strsplit( data$Spp.Name, &#39;
  #### &#39; ) data$Genus &lt;- sapply( split.spp, &#39;[[&#39;, 1 ) data$Species &lt;- sapply(
  #### split.spp, &#39;[[&#39;, 2 )
  
  
  
  # Get the summary stats for each interesting trait
  Height &lt;- do.sumy(&quot;Height~Photosynthesis+Genus+Species&quot;, &quot;Height&quot;, data)
  # show me the data
  print(xtable(Height), type = &quot;html&quot;)
  </code></pre>
  
  <!-- html table generated in R 3.1.0 by xtable 1.7-1 package -->
  
  <!-- Wed May  7 16:19:23 2014 -->
  
  <TABLE border=1>
  <TR> <TH>  </TH> <TH> Photosynthesis </TH> <TH> Genus </TH> <TH> Species </TH> <TH> Mean </TH> <TH> Median </TH> <TH> Std </TH> <TH> Min </TH> <TH> Max </TH> <TH> N </TH> <TH> Parameter </TH>  </TR>
    <TR> <TD align="right"> 1 </TD> <TD align="right"> 15.04 </TD> <TD> Eucalyptus </TD> <TD> Saligna </TD> <TD align="right"> 15.00 </TD> <TD align="right">  15 </TD> <TD align="right">  </TD> <TD align="right">  15 </TD> <TD align="right">  15 </TD> <TD align="right">   1 </TD> <TD> Height </TD> </TR>
    <TR> <TD align="right"> 2 </TD> <TD align="right"> 15.58 </TD> <TD> Eucalyptus </TD> <TD> Saligna </TD> <TD align="right"> 15.00 </TD> <TD align="right">  15 </TD> <TD align="right">  </TD> <TD align="right">  15 </TD> <TD align="right">  15 </TD> <TD align="right">   1 </TD> <TD> Height </TD> </TR>
    <TR> <TD align="right"> 3 </TD> <TD align="right"> 16.00 </TD> <TD> Eucalyptus </TD> <TD> Saligna </TD> <TD align="right"> 15.00 </TD> <TD align="right">  15 </TD> <TD align="right">  </TD> <TD align="right">  15 </TD> <TD align="right">  15 </TD> <TD align="right">   1 </TD> <TD> Height </TD> </TR>
     </TABLE>
  
  <pre><code class="r">#### not available Vcmax &lt;- do.sumy( &#39;Vcmax25~CO2.treatment+Genus+Species&#39;,
  #### &#39;VCMAXM25&#39;, data ) Jmax &lt;- do.sumy( &#39;Jmax25~CO2.treatment+Genus+Species&#39;,
  #### &#39;JMAXM25&#39;, data ) VjVn &lt;- do.sumy( &#39;J.V~CO2.treatment+Genus+Species&#39;,
  #### &#39;VJVN&#39;, data ) Tleaf &lt;- do.sumy(
  #### &#39;Tleaf_avg~CO2.treatment+Genus+Species&#39;,&#39;TLEAF&#39;, data ) all.Y &lt;- rbind(
  #### Vcmax, Jmax, VjVn, Tleaf )
  
  ## # Re-arrange the columns to the correct order exp.dat1 &lt;- subset( all.Y,
  ## select=c(&#39;Genus&#39;,&#39;Species&#39;,&#39;Parameter&#39;,&#39;Mean&#39;,&#39;Median&#39;,&#39;Std&#39;,&#39;Min&#39;,&#39;Max&#39;,&#39;N&#39;,&#39;CO2.treatment&#39;)
  ## )
  
  ## # save it somewhere write.table( exp.dat1, &#39;choose/folder/to/save/to.csv&#39;,
  ## sep=&#39;,&#39;, row.names=F, col.names=T, na=&#39;&#39; )
  
  </code></pre>
  
  </body>
      
#+end_src

** 2014-04-xx-using-morpho-for-cataloguing-postgis-servers-org
*** Adding regarding the Data Location and Backups
  
These data are quite large and also geospatial, so I store these 
on a PostGIS server at the ANU library. The original data are stored
on a PostGIS server at NCEPH and the code I used to compute the
indices is on github.  So all I want to do with Morpho is document the
data, not import it.
*** notes
https://knb.ecoinformatics.org/#external//emlparser/docs/eml-2.1.1/./eml-physical.html#PhysicalDistributionType
PhysicalDistributionType 
	
Content of this field: 	Description of this field:
Elements: 	Use: 	How many:
A choice of (
A sequence of (
A choice of (
online	required	
OR
offline	required	
OR
inline	required	
)
access	optional	
)
OR
res:ReferencesGroup	 	 
)
Attributes: 	Use: 	Default Value:
id	optional
system	optional
scope	optional	document
	

    The PhysicalDistributionType contains the information required for retrieving the resource.

    It differs from the
    res:DistributionType
    :

    Generally, the PhysicalDisribtutionType is intended for download whereas the Type at the resource level is intended primarily for information.

    The phys:PhysicalDistributionType includes an optional access tree which can be used to override access rules applied at the resource level. Access for the documents included entities can then be managed individually.

    Also see individual sub elements for more information.



    and
    https://im.lternet.edu/node/1119
    This element is found at these locations (XPath):
    /eml:eml/dataset/distribution
    /eml:eml/dataset/[entity]/physical/distribution 
     
    The <distribution> element appears at the dataset and entity
    levels and contains information on how the data described in the
    EML document can be accessed. The <distribution> element has one
    of three children for describing the location of the resource:
    <online>, <offline>, and <inline>.
     
    Offline Data: Use the <offline> element to describe restricted
    access data or data that is not available online. The minimum that
    should be included is the <mediumName> tag, if using the <offline>
    element.
     
    Inline Data: The <inline> element contains data that is stored
    directly within the EML document. Data included as text or string
    will be parsed as XML. If data are not to be parsed, encode them
    as “CDATA sections,” by surrounding them with
    “<![CDATA[“ and “]]>” tags.
     
    Online Data: The <online> element has two sub elements, <url>, and
    <onlineDescription> (optional).  <url> tags may have an optional
    attribute named function, which may be set to either “download” or
    “information”. If the URL provides only information about
    downloading the object but does not directly return the data
    stream, then the function attribute should be set to
    "information". If accessing the URL directly returns the data
    stream, then the function attribute should be set to "download".
    If the function attribute is omitted, then "download" is implied
     
    An EML dataset should include at least one URL; at a minimum, this
    should be at the <dataset> level (XPath:
    /eml:eml/dataset/distribution/url), and may point to an
    application or website. This <url> function attribute can be set
    to either “information” or “download”.  However, a URL at the
    entity level (e.g, a dataTable at
    /eml:eml/dataset/dataTable/physical/distribution/url) should
    stream data to the requesting application and should include an
    attribute function with the value “download”.  In other words, at
    the entity level, the URL should lead directly to the data and not
    to a data catalog or intended-use page. For more information about
    describing a URL connection, see the EML documentation online.
     
    When used at the entity level, an alternative tag is available to
    <url>, <connection>. This element is discussed under data
    entities, below.
     
    As of EML 2.1, there is also an optional <access> element in a
    <distribution> tree at the data entity level
    (/eml:eml/dataset/[entity]/physical/distribution/access). This
    element is intended specifically for controlling access to the
    data entity itself. For more information on the <access> tree, see
    above, under the general access discussion.
<<<<<<< HEAD

** 2014-04-24-using-reml-to-input-large-number-of-column-descriptions
#+name:using-reml-to-input-large-number-of-column-descriptions-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-04-24-using-reml-to-input-large-number-of-column-descriptions.md :exports none :eval no :padline no
  ---
  name: using-reml-to-input-large-number-of-column-descriptions
  layout: post
  title: Using Reml To Input Large Number Of Column Descriptions
  date: 2014-04-24
  categories:
  - Data Documentation
  ---
  
  We recently hit an issue when using morpho to enter metadata for a large number of variables (~200).  The GUI form for entering definitions and units steps through each variable, but at about 60 or 70 it starts to slow down.  By the time we got to 160 it was taking more than 5 minutes to change to the next variable.  To safegaurd against losing work, we kept hitting "save for later" but this got slower and apeared to freeze at the last minute...  Not sure if that last save worked at all.
  
  So I;ve come back once more to the ROpenSci EML package which is looking like a really useful way to build metadata elements automatically, with Morpho being used to proved augmentation and finesse the documents.
  
  First thing I tried was the constructed Column Definitions and Unit Definitions example from [the README](https://github.com/ropensci/EML)
  
  #### R Code:
      #require(devtools)
      #install_github("EML", "ROpenSci")
      require(EML)
       
      # The example from orig doco
      dat = data.set(river = c("SAC",  "SAC",   "AM"),
                     spp   = c("king",  "king", "ccho"),
                     stg   = c("smolt", "parr", "smolt"),
                     ct    = c(293L,    410L,    210L),
                     col.defs = c("River site used for collection",
                                  "Species common name",
                                  "Life Stage",
                                  "count of live fish in traps"),
                     unit.defs = list(c(SAC = "The Sacramento River",
                                        AM = "The American River"),
                                      c(king = "King Salmon",
                                        ccho = "Coho Salmon"),
                                      c(parr = "third life stage",
                                        smolt = "fourth life stage"),
                                      "number"))
      str(dat)
      eml_config(creator="Carl Boettiger <cboettig@gmail.com>")
      eml_write(dat, file = "inst/doc/EML_example.xml")
      # now you can import this to morpho and have a look
      # note that for morpho 1.8 it wants to change the EML version from 2.1.1 to 2.1.0
      # and it can't show the data yet
      # so what we need to do is write this as a file to the morpho database
      # save and close, note which number it assigned
      dat <- data.frame(dat)
      morpho_db  <- "~/.morpho/profiles/hanigan/data/hanigan/"
      maxid  <-  1+max(as.numeric(dir(morpho_db)))
      filename <- file.path(morpho_db,maxid)
      # what is the number?
      filename
      write.csv(dat, filename, row.names =F, quote=F)
  
  
  <p></p>
  
  So now to finish what we need to add into the EML that morpho has created (22.1 in my case)  just needs the reference to the dataTable.
  
  #### EML Code:
      ...
      </dataFormat>
      <distribution scope="document"> <online> <url function="download">ecogrid://knb/hanigan.22.1</url>
      </online>
      <access authSystem="knb" order="denyFirst"><allow><principal>uid=datalibrarian,o=unaffiliated,dc=ecoinformatics,dc=org</principal>
      <permission>all</permission>
      </allow>
      <allow><principal>uid=hanigan,o=unaffiliated,dc=ecoinformatics,dc=org</principal>
      <permission>read</permission>
      </allow>
      </access>
      </distribution>
      </physical>
      ...
  
  <p></p>
  
  Which seems to have worked when we open it up again:
    
  ![moprho-wide1.png](/images/morpho-wide1.png)
  
  So now let;s try a large nuber of variables:
  
  #### R Code:
      # add lots of cols
      for(i in 5:100){
        dat[,i] <-  sample(rnorm(100,1,2), 3)
      }
      str(dat)
      ##  $ V95  : num  1.5708 -0.0936 2.2324
      ##  $ V96  : num  1.79 5.4 1.62
      ##  $ V97  : num  -1.141 0.653 5.365
      ##  $ V98  : num  1.738 -1.046 -0.135
      ##  $ V99  : num  3.6 -0.738 -1.877
      ##   [list output truncated]
                     unit.defs = list(c(SAC = "The Sacramento River",
                                        AM = "The American River"),
                                      c(king = "King Salmon",
                                        ccho = "Coho Salmon"),
                                      c(parr = "third life stage",
                                        smolt = "fourth life stage"))
      unit.defs[[3]]
      for(i in 4:100){
      unit.defs[[i]] <- "number"
      }
      unit.defs
      dat = data.set(dat,
                     col.defs = c("River site used for collection",
                                  "Species common name",
                                  "Life Stage",
                                  "count of live fish in traps",
      c(rep("count stuff", 95))
                       ),
      unit.defs = unit.defs
                       
        )
      str(dat)
       
      eml_config(creator="Ivan Charles Hanigan <ivan.hanigan@gmail.com>")
      eml_write(dat, file = "inst/doc/EML_example_wide.xml")
      # import to morpho, save and close
      dat <- data.frame(dat)
      morpho_db  <- "~/.morpho/profiles/hanigan/data/hanigan/"
      maxid  <-  1+max(as.numeric(dir(morpho_db)))
      filename <- file.path(morpho_db,maxid)
      # what is the number?
      filename
      write.csv(dat, filename, row.names =F, quote=F)
      # now add this into the EML morpho has created (25.2 in my case)
  
  <p></p>
  
  Which now seems to have attached the variable defintions and dataTable adequately.
  
  ![morpho-wide2.png](/images/morpho-wide2.png)
#+end_src

=======
>>>>>>> 97232c527e5291321d5a3bfd72d5b616c3f608b1

* Exploratory Data Analysis
* General Purpose
* Visualisation
** COMMENT QGIS
*** 2013-10-31-quantum-gis-visualisations

#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-31-quantum-gis-visualisations.md :exports none :eval no :padline no
  ---
  name: quantum-gis-visualisations 
  layout: post
  title: quantum-gis-visualisations
  date: 2013-10-31
  categories:
  - spatial
  ---
  
  - This is a quick post on Quantum GIS for spatial data visualisation
  - it is also a follow up on [this post about area concordance](http://swish-climate-impact-assessment.github.io/2013/06/test-gislibrary/)
  - Quantum GIS is getting pretty good but is still a bit tricky to make good looking maps
  - QGIS can use [remote PostGIS geodatabases on the Cloud as the backend](http://swish-climate-impact-assessment.github.io/2013/04/quantumgis-and-postgis/)
  
  #### R Code: use postgis to create area-concordance
      require(devtools)
      install_github("gisviz", "ivanhanigan")
      require(gisviz)
      require(swishdbtools)
      ch <- connect2postgres2("gislibrary")
      # make a temporary tablename, to avoid clobbering
      temp_table <- swish_temptable("gislibrary")
      temp_table <- paste("public", temp_table$table, sep = ".")
      temp_table
      # this is going to be public.foo11c7673416ea
       
      sql <- postgis_concordance(conn = ch, source_table = "abs_sla.nswsla91",
         source_zones_code = 'sla_id', target_table = "abs_sla.nswsla01",
         target_zones_code = "sla_code",
         into = temp_table, tolerance = 0.01,
         subset_target_table = "cast(sla_code as text) like '105%'", 
         eval = F) 
      cat(sql)
      dbSendQuery(ch, sql)
  
  <p></p>
  
  - now connect to PostGIS using QGIS [as described in this tute](http://swish-climate-impact-assessment.github.io/2013/04/quantumgis-and-postgis/)
  - and add the layer to the map
  - Style it how you like, I also added NSWSLA1991 over the top
  - go into the "new print composer"
  
  ![qgis-new-print-composer.png](/images/qgis-new-print-composer.png)
  
  ![qgis-add-new-map.png](/images/qgis-add-new-map.png)
  
  ### Results
  - hit the export to image and viola
  
  ![qgis-export-image.png](/images/qgis-export-image.png)
  
  ### Don't forget to clean up the database!
  #### R Code:
      dbSendQuery(ch, sprintf("drop table %s", temp_table))
#+end_src

** 2013-12-18-animations-using-R
#+name:animations-using-R-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-18-animations-using-R.md :exports none :eval no :padline no
  ---
  name: 2013-12-18-animations-using-R
  layout: post
  title: animations-using-R
  date: 2013-12-18
  categories:
  - research methods
  ---
  
  - following on from my previous posts about [animated maps](http://ivanhanigan.github.io/2013/07/animated-maps/), [spatio-temporal animations](http://ivanhanigan.github.io/2013/06/spatio-temporal-animations/) and animations [with buttons for go, stop and reverse](http://ivanhanigan.github.io/button/index.html)
  - Here is a quick note about how to do a simple animation with R to create a movie file (GIF)
  - To create this movie
  
  ![animation.gif](/animation/animation.gif)
  
  
  #### Code:animations-using-R
      if(!require(animation)) install.packages("animation");
      require(animation)
      saveGIF(
      {
      ani.options(nmax = 100, interval = 0.5)
      par(mar = c(3, 2.5, 0.5, 0.2), pch = 20, mgp = c(1.5, 0.5,0))
      buffon.needle(mat = matrix(c(1, 2, 1, 3), 2))
      },
      outdir = getwd()
      )
      
#+end_src

** COMMENT boxplots-split-code
#+name:boxplots-split
#+begin_src R :session *R* :tangle no :exports none :eval no
#### name:boxplots-split####
#work for GuoJing
boxplot(split(AllRespStacked$AvDailyTemp,AllRespStacked$month),xaxt="n")
axis(1, at=1:8,labels=c("Apr","May","Jun","Jul","Aug","Sep","Oct","Nov"))

#work for caroline
x<-rnorm(200,10)
y<-rnorm(200,5)
boxplot(split(y,ifelse(x<9,1,ifelse(x<10,2,ifelse(x<11,3,ifelse(x<12,4,5))))),medpch=1,medcol=1,medlwd=1,xaxt="n")
axis(1, at=1:5,labels=c("8-9","9-10","10-11","11-12","12-13"))
#+end_src

** COMMENT x-axis-labels-on-45-deg-angle-code
#+name:x-axis-labels-on-45-deg-angle
#+begin_src R :session *R* :tangle no :exports none :eval no
#### name:x-axis-labels-on-45-deg-angle####
# 
text(mp, par('usr')[3], labels = labels, srt = 45, adj = c(1.1,1.1), xpd = TRUE, cex=.9)


# X-Axis Labels on a 45-Degree Angle using R
# Posted on 20 May 2009 by jnlnet| 5 Comments
# 
# I’ve been trying to find a simpler bit of R code that will allow axis labels to be written in at an angle, and thanks to my obsessive scanning of the R-help mailing list I found a nice example (all credit to Uwe Ligges and Marc Schwartz for their approach). I’ve made a few cosmetic tweaks in moving the labels off of the x-axis and changing the labels.
# 
# The following code will produce the figure below:
# 
labels <- c('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December')
labels <- month.name[1:12]
mp <- barplot(1:12, axes = FALSE, axisnames = FALSE)
text(mp, par('usr')[3], labels = labels, srt = 45, adj = c(1.1,1.1), xpd = TRUE, cex=.9)
axis(2)
# 
#+end_src

* Statistical Modelling
** COMMENT Logistic Regression
*** COMMENT a-great-intro-2-logistic-regression
#+name:challenger-logistic-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-10-18-challenger-logistic.md :exports none :eval no :padline no
  ---
  name: a-great-intro-2-logistic-regression
  layout: post
  title: A Great Intro 2 Logistic Regression 
  date: 2013-10-18
  categories:
  - research methods
  ---
  
  This is a great example of logistic regression,  because it is pretty simple but covers good ground.  I got it from Peter Caley;s R tutorial workbook from Charles Darwin School of Environmental Research.  
  
  It is also a tragic example of the impact weather can have on health.  
  The colder it is the more likely the shuttle is to explode. 
  
  The problem was with the failure rate (and number of) O-rings that failed (n.fail) related to the temperature (temp).   
  
  #### R Code:
      #Load the data
      #The following R code will construct the dataset
      n.fail <- c(2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0)
      temp <- c(53, 66, 68, 70, 75, 78, 57, 67, 69, 70, 75, 79, 58, 67, 70, 72, 76, 81, 63, 67, 70, 73, 76)
      # there were 6 o rings for each of 23 attempts
      total <- rep(6,23)
      # probability of fail
      p.fail <- n.fail/total
      # Response = resp column bind them together  
      resp <- cbind(n.fail, total-n.fail)
       
      ###########################################################################
      # we can write text files easily once the data frame or matrix is in shape
      data <- as.data.frame(cbind(resp,temp))
      names(data) <- c('nfail','totalMinusNfail', 'temp')
      # write.csv(data, 'learnR-logistic-data.csv', row.names=F)
       
      ###########################################################################
      # and read it in again 
      # data2 <- read.csv('learnR-logistic-data.csv')
       
      ################################################################
      # name:learnR-logistic
      png('images/pfail.png')
      plot(temp, p.fail, pch=16, xlim=c(40,100), ylim=c(0,0.4))
      title('A plot of the proportion failed by temperature')
      dev.off()
  
  <p></p>
  
  ![pfail.png](/images/pfail.png)
       
  #### R Code:
      ###########################################################################
      # newnode: linear
      linear <- glm(resp ~ 1 + temp, family=binomial(link=logit))
      summary(linear)
      linearoutput <- summary(linear)
      linearoutput$coeff
       
      ###########################################################################
      # newnode: learnR-logistic
      cf <- linearoutput$coeff
      signif(cf[which(row.names(cf) == 'temp'),'Estimate'],2)
       
      ###########################################################################
      # newnode: learnR-logistic
      # write.csv(linearoutput$coeff,"challengerOfails.csv")
       
      ###########################################################################
      # newnode: learnR-logistic
       png('images/challengerLogistic.png')
       par(mfrow=c(2,2))
       plot(linear)
       dev.off()
       
  <p></p>
  
  ![challengerLogistic.png](/images/challengerLogistic.png)
  
  
  #### R Code:
      ####################################################################
      # newnode: learnR-logistic
      dummy <- data.frame(temp=seq(20,100,1))
      pred.prob <- predict.glm(linear, newdata=dummy, type="resp")
      png('images/pfailfit.png')
      plot(temp, p.fail, xlab="Launch Temperature (F)",
       ylab="Proportion Failing", pch=16, xlim=c(20,100), ylim=c(0,1.0))
      lines(dummy$temp, pred.prob)
      dev.off()
       
  <p></p>
  
  ![pfailfit.png](/images/pfailfit.png)
  
  #### R Code:
      ####################################################################
      resp <- as.data.frame(resp)
      resp$fail <- ifelse(resp$n.fail > 0, 1, 0)
      resp$temp <- temp
       
      png('images/fail.png')
      with(resp, plot(temp, fail, xlab="Launch Temperature (F)",ylab="Joint damage", pch=16, xlim=c(50,80), ylim=c(0,1.0))
           )
      dev.off()
  <p></p>
  
  ![fail.png](/images/fail.png)
  
  #### R Code:
       
      chal.logit <- glm(fail~temp,family=binomial, data = resp)
      summary(chal.logit)$coeff
       
      png('images/pfailfit2.png')
      cx <- c(50:80/1)
      cyhat <- coefficients(chal.logit)[c(1)] +
      coefficients(chal.logit)[c(2)]*cx
      cpihat <- exp(cyhat)/(1+exp(cyhat))
      with(resp,plot(temp,fail,xlab="Temperature",ylab="Damage",
      main="Incidence of Booster Field Joint Damage vs. Temperature", xlim = c(50,80))
           )
      lines(cx,cpihat)
      dev.off()
  
  <p></p>
  
  ![pfailfit2.png](/images/pfailfit2.png)
  
  
  
#+end_src

** Tree-Based Methods
*** COMMENT To read
http://r.789695.n4.nabble.com/In-rpart-how-is-quot-improve-quot-calculated-in-the-quot-class-quot-case-td3593770.html
 Jun 15, 2011; 6:21am
Re: In rpart, how is "improve" calculated? (in the "class" case)
Tal Galili
782 posts
	
Hi Ed,
Thank you for the reply!

Professor Atkinson already gave me that answer by pointing me to the technical
report of rpart that describes this:
*http://mayoresearch.mayo.edu/mayo/research/biostat/upload/61.pdf*

However, I was also only able to reproduce the "gini" impurity, and not the
"information" one.
I hope either Professor Atkinson or some other member of the list could help
out with this.

In the meantime, I also found a bug in the code I sent to the mailing list,
bellow is the fixed code (also more organized):


#+name:impurity
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:impurity


 # creating data
set.seed(1324)
y <- sample(c(0,1), 20, T)
x <- y
x[1:5] <- 0

# manually making the first split
obs_L <- y[x<.5]
obs_R <- y[x>.5]
n_L <- sum(x<.5)
n_R <- sum(x>.5)
n <- length(x)


calc.impurity <- function(func = gini)
{
impurity_root <- func(prop.table(table(y)))
 impurity_L <- func(prop.table(table(obs_L)))
 impurity_R <-func(prop.table(table(obs_R)))
 imp <- impurity_root - ((n_L/n)*impurity_l + (n_R/n)*impurity_R) # 0.3757
 imp*n
}

# for "gini"
require(rpart)
fit <- rpart(y~x, method = "class", parms=list(split='gini'))
fit$split[,3] # 5.384615
gini <- function(p) {sum(p*(1-p))}
calc.impurity(gini) # 5.384615 # success!


# for "information" I fail...

fit <- rpart(y~x, method = "class", parms=list(split='information'))
fit$split[,3] # why is improve here 6.84029 ?

entropy <- function(p) {
if(any(p==1)) return(0) # works for the case when y has only 0 and 1
categories...
 -sum(p*log(p))
 }
calc.impurity(entropy) # 9.247559 != 6.84029


#+end_src

** Misclassification Error Rate for Classification Trees

** Deviance Based Measures of Descriptive Power for Classification Trees
**** Computing-and-using-deviance-with-classification-trees-Ritschard, G. (2006).
I'm reading Ritschard, G. (2006). Computing and using the deviance with classification trees. In Compstat 2006 - Proceedings in Computational Statistics 17th Symposium Held in Rome, Italy, 2006. Retrieved from http://link.springer.com/chapter/10.1007%2F978-3-7908-1709-6_5

This is implemented in SPSS code. I'll try to develop R code to do these tests.

First I'll get the data out of their paper and fit the tree in figure 1

**** COMMENT DEPRECATED SEE BLOG sample-tree-data
#+name:tree-deviance
#+begin_src R :session *R* :tangle inst/doc/tree-data.r :eval no
  #########################################
  # func
  require(rpart)
  require(partykit) 
  
  
  # clean
  str(civst_gend_sector)
  
  # do
  fit <- rpart(civil_status ~ gender + activity_sector,
               data = civst_gend_sector, weights = number_of_cases,
               control=rpart.control(minsplit=1))
  # NB need minsplit to be adjusted for weights.
  summary(fit)
    
  # report
  plot(fit, margin=.1)
  text(fit, use.n = TRUE)
  title("fit")
  
  # nicer plots
  png("images/fit1.png", 1000, 480)
  plot(as.party(fit))
  dev.off()  
#+end_src
**** COMMENT cuts
***** COMMENT DEPRECATED get-data-from-pdf-code
#+name:get-data-from-pdf
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:get-data-from-pdf
  # these data are in a table in the pdf but not that easy to copy and paste.
  gender <- c("male", 
  "male", 
  "male", 
  "female",
  "female",
  "female",
  "male",
  "male",
  "male",
  "female",
  "female",
  "female",
  "male", 
  "male", 
  "male", 
  "female",
  "female",
  "female")
  
  civil_status <- c("married", "married", "married", "married", "married", "married",
  "single", "single", "single", "single", "single", "single",
  "divorced/widowed", "divorced/widowed", "divorced/widowed", "divorced/widowed",
  "divorced/widowed", "divorced/widowed")
  
  activity_sector <- c("primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary","primary",
  "secondary","tertiary")
  
  number_of_cases <- c(50, 40, 6, 0,
  14, 10, 5, 5,
  12, 50, 30, 18, 5, 8,
  10, 6, 2, 2)
  
  ls()
  civst_gend_sector <- as.data.frame(cbind(civil_status, gender, activity_sector, number_of_cases))
  
  # clean
  civst_gend_sector[4:6,]
  civst_gend_sector$number_of_cases <- as.numeric(as.character(civst_gend_sector$number_of_cases))
  civst_gend_sector  
  
  
#+end_src
**** Reproduce the figure from the paper
The figure in the paper can be checked against our results (and also the improved plot from the party package might be used).

[[file:images/fit1.png]]
**** One row per case or using weights?
Using the case weights like above is convenient especially when datasets are very large, but caused problems in model fitting for me (tree failed to compute a deviance when done this way but succeeded with a dataset expanded so the data.frame is transformed into one in which each row is an observation.
#+name:reassurance-re-weights
#+begin_src R :session *R* :tangle inst/doc/tree-data2.r :eval no
  ################################################################
  # name:reassurance-re-weights
   
  # just to reasure myself I understand what case weights do, I'll make
  # this into a survey dataset with one row per respondent
  df <- as.data.frame(matrix(NA, nrow = 0, ncol = 3))
  for(i in 1:nrow(civst_gend_sector))
      {
      #    i <- 1
          n <- civst_gend_sector$number_of_cases[i]
          if(n == 0) next
          for(j in 1:n)
              {
                df <- rbind(df, civst_gend_sector[i,1:3])              
              }
   
      }
  # save this for use later
  write.csv(df, "inst/extdata/civst_gend_sector_full.csv", row.names = F)
  # clean
  nrow(df)
  str(df)
  fit1 <- rpart(civil_status ~ gender + activity_sector, data = df)
  summary(fit1)
  
  # report
  par(mfrow=c(1,2), xpd = NA) 
  plot(fit)
  text(fit, use.n = TRUE)
  title("fit")
  plot(fit1)
  text(fit1, use.n = TRUE)
  title("fit1")
  # great these are the same which is what we'd hoped to see
  
#+end_src

**** COMMENT DEPRECATED, SEE BLOG Chisquare test of deviance for Classification trees
I want to use the deviance as well as the misclassification error rate for measuring the descriptive power of the tree.  Using the tree package we can access the deviance of the fitted Classification tree.  Ripley's tree package is the only one I found to give me deviance for classification trees, the other packages only return this for regression trees.

If we look at the reduction in deviance between the Null model and the fitted tree we can say that the tree explains about XYZ% of the variation. We can also test if this is a statistically significant reduction (based on a chi-squared test), but should also comment about how much explanation this is in practical terms.

**** COMMENT cut
The attached papers suggest a method to test differences between nested trees ie testing the difference with the root node with a Chi-square statistic (equivalent of the usual method used in logistic regression).
**** COMMENT reminder-of-method-in-logistic-regression-code
#+name:reminder-of-method-in-logistic-regression
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:reminder-of-method-in-logistic-regression
  # rewritten from http://data.princeton.edu/r/glms.html
  require(foreign)
  require(reshape)
  require(plyr)
  
  cuse <- read.dta("http://data.princeton.edu/wws509/datasets/cuse.dta")                  
  str(cuse)
  head(cuse)
  d2 <- cast(cuse,  age + educ + desire ~ cuse, value = 'n')
  head(arrange(d2, age, educ))
  d2
  lrfit <- glm(cbind(Yes, No) ~ age + educ + desire, data = d2, family = binomial)
  lrfit
  
  ## Recall that R sorts the levels of a factor in alphabetical order. Because <25 comes before 25-29, 30-39, and 40-49, it has been picked as the reference cell for age. Similarly, high is the reference cell for education because high comes before low! Finally, R picked no as the base for wantsMore.
  
  ## If you are unhappy about these choices you can (1) use relevel to change the base category, or (2) define your own indicator variables. I will use the latter approach by defining indicators for women with high education and women who want no more children:
  
  d2$noMore <- d2$desire == "Wants no more"
  d2$hiEduc <- d2$educ == "Some"
  
  
  lrfit <- glm(cbind(Yes, No) ~  age + hiEduc + noMore, data = d2, family = binomial)
  lrfit
  
  str(summary(lrfit))
#+end_src


**** TODO Check This: R function to calculate for classification trees
The Ritschard (2006) paper (with SPSS code) describes a complicated method that includes Needing to retrieve for each case: 
- leaf number and
- profile number

I really want to use the deviance as well as the misclassification error rate for measuring the descriptive power of the tree.
Ripley's tree package is the only one I found to give me deviance for classification trees.

The Ritschard papers suggest nice methods to test differences between nested trees ie testing the difference with the root node with a Chi-square statistic (equivalent of the usual method used in logistic regression).

Is this method employed widely in analysing survey data?
I haven't turned up many references to Ritschard since he wrote these.

So let's start simple first.  The following code follows the simpler approach:
- Take the difference in the deviance for the models (less complex model minus more complex model)
- Take the difference in degrees of freedom for the models
- difference between less complex and more complex model follows chi-square distribution

**** COMMENT http://www.stat.ufl.edu/~winner/sta6127/chapter15.ppt
slide 22 
Two statistics are used to test whether a model is appropriate: the Pearson chi-square statistic and the likelihood ratio (aka Deviance) statistic
slide 28
Under hypothesis that less complex (reduced) model is adequate, difference follows chi-square distribution
**** R-tree.chisq
**** R code
#+name:tree.chisq
#+begin_src R :session *R* :tangle R/tree.chisq.r :eval no
  ################################################################
  # name:tree.chisq
  tree.chisq <- function(null_model, fitted_model)
  {
      # TODO check if these are tree model class
      fit_dev  <- summary(fitted_model)$dev
      null_dev  <- summary(null_model)$dev    
      dev  <-  null_dev - fit_dev
      df  <- summary(fitted_model)$size - summary(null_model)$size
      sig  <- 1 - pchisq(dev, df)
      sprintf("Reduction in deviance is %s percent, p-value is %s (based on a chi-squared test)",
              ((null_dev - fit_dev) / null_dev) * 100,
              sig)
  }
  
#+end_src
**** test-tree.chisq
#+name:tree.chisq
#+begin_src R :session *R* :tangle tests/test-tree.chisq.r :eval no
  # func
  require(tree)
  require(devtools)
  install_github("TransformSurveyTools", "ivanhanigan")
  require(TransformSurveyTools)
  # load locally
  # fpath  <- "inst/extdata/civst_gend_sector_full.csv"
  # or via package
  fpath <- system.file("extdata", "civst_gend_sector_full.csv", package="TransformSurveyTools")
  civst_gend_sector  <- read.csv(fpath)
  
  # clean
  str(civst_gend_sector)
  
  # do
  variables  <- names(civst_gend_sector)
  y_variable  <- variables[1]
  x_variables  <- variables[-1]
  
  # NULL
  form0  <- reformulate("1",
                        response = y_variable)
  form0
  model0 <- tree(form0, data = civst_gend_sector, method = "class")
  print(model0)
  # FIT
  form1  <- reformulate(x_variables,
                        response = y_variable)
  form1
  model1 <- tree(form1, data = civst_gend_sector, method = "class")
  print(model1)
  summary(model1)
  plot(model1)
  text(model1,pretty = 0)
  tree.chisq(null_model = model0, fitted_model = model1)
    
#+end_src
***** COMMENT test- deprecated - broken
#+begin_src R :session *R* :tangle tests/test-tree.chisq.r :exports none :eval no
  ################################################################
  # name:tree.chisq
  # func
  require(tree)
  
  # load
  fpath  <- "inst/extdata/civst_gend_sector.csv"
  # or
  #fpath <- system.file("extdata", "my_raw_data.csv",
  # package="my_package")
  civst_gend_sector  <- read.csv(fpath)
  
  # clean
  str(civst_gend_sector)
  
  # do
  variables  <- names(civst_gend_sector)
  y_variable  <- variables[1]
  x_variables  <- variables[-c(1,4)]
  weight  <- civst_gend_sector[,variables[4]]
  # NULL
  form0  <- reformulate("1",
                        response = y_variable)
  form0
  model0 <- tree(form0, data = civst_gend_sector, method = "class", weights = weight)
  # FIT
  form1  <- reformulate(x_variables,
                        response = y_variable)
  form1
  model1 <- tree(form1, data = civst_gend_sector, method = "class", weights = weight)
  # this produces a NaN on node 4!
  ## > model1 <- tree(form1, data = civst_gend_sector, method = "class", weights = weight)
  ## > print(model1)
  ## node), split, n, deviance, yval, (yprob)
  ##       * denotes terminal node
  
  ## 1) root 273 534.00 married ( 0.12088 0.43956 0.43956 )  
  ##   2) gender: female 132 191.80 single ( 0.07576 0.18182 0.74242 )  
  ##     4) activity_sector: primary 56    NaN single ( 0.10714 0.00000 0.89286 ) *
  ##     5) activity_sector: secondary,tertiary 76 123.00 single ( 0.05263 0.31579 0.63158 ) *
  ##   3) gender: male 141 239.00 married ( 0.16312 0.68085 0.15603 )  
  ##     6) activity_sector: primary,secondary 113 145.70 married ( 0.11504 0.79646 0.08850 ) *
  ##     7) activity_sector: tertiary 28  59.41 single ( 0.35714 0.21429 0.42857 ) *
  model1 <- tree(form1, data = df, method = "class")
  ## > print(model1)
  ## node), split, n, deviance, yval, (yprob)
  ##       * denotes terminal node
  
  ## 1) root 273 534.00 married ( 0.12088 0.43956 0.43956 )  
  ##   2) gender: female 132 191.80 single ( 0.07576 0.18182 0.74242 )  
  ##     4) activity_sector: primary 56  38.14 single ( 0.10714 0.00000 0.89286 ) *
  ##     5) activity_sector: secondary,tertiary 76 123.00 single ( 0.05263 0.31579 0.63158 ) *
  ##   3) gender: male 141 239.00 married ( 0.16312 0.68085 0.15603 )  
  ##     6) activity_sector: primary,secondary 113 145.70 married ( 0.11504 0.79646 0.08850 ) *
  ##     7) activity_sector: tertiary 28  59.41 single ( 0.35714 0.21429 0.42857 ) *
  ## > 
  model1 <- tree(form1, data = df, method = "class")
  print(model1)
  plot(model1)
  # can't plot if used civst_gender_sector
  text(model1,pretty = NULL)
  
  
#+end_src
***** COMMENT man-tree.chisq
#+name:tree.chisq
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:tree.chisq

#+end_src
**** main-tree-model
#+name:tree.chisq
#+begin_src R :session *R* :tangle inst/doc/main.r :eval no
source("tests/test-tree.chisq.r")
#+end_src

** Deviance Measures and Descriptive Power for Regression Trees
*** rpart-deviance-explained-code
#+name:rpart_deviance_explained
#+begin_src R :session *R* :tangle R/rpart_deviance_explained.r :exports reports :eval no
  ################################################################
  # name:rpart_deviance_explained
  rpart_deviance_explained <- function(model_fit)
  {
    estat <- print(model_fit)$frame[,c("var","n","dev","yval")]
    null_deviance  <- estat[1,"dev"]
    residual_deviance  <-  sum(subset(estat, var == "<leaf>")$dev)
  
    dev_explained  <- (null_deviance - residual_deviance) / null_deviance
    return(dev_explained)
  }
  
#+end_src
*** rpart-deviance-explained-test
#+name:rpart_deviance_explained-test
#+begin_src R :session *R* :tangle no :exports reports :eval no
  ################################################################
  # name:rpart_deviance_explained-test
    
    
    
  # explanatory power
  require(rpart)
  require(tree)
  require(partykit)
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
  
  # load
  fpath <- system.file(file.path("extdata", "civst_gend_sector_full.csv"), package = "disentangle")
  fpath
  analyte  <- read.csv(fpath)
  str(analyte)
  
  # do
  fit  <- rpart(income ~ ., data = analyte)
  print(fit)
  par(xpd=T)
  plot(fit);text(fit)
  plot(as.party(fit))
  
  rpart_deviance_explained(fit)
  
  # compare with http://plantecology.syr.edu/fridley/bio793/cart.html
  #Output of the fitted model shows the partition structure.  The root
  #level (no splits) shows the total number of observations (1039),
  #the associated deviance (at the root equal to the null deviance, or
  #the response variable sum of squares (SSY): 
  ndev <- sum(sapply(analyte$income,function(x)(x-mean(analyte$income))^2))
  
  ## #followed by the mean response value for that subset (for the root,
  ## this is the overall mean).  Subsequent splits refer to these
  ## statistics for the associated data subsets, with final nodes
  ## (leaves) indicated by asterisks.  The summary function associated
  ## with tree lists the formula, the number of terminal nodes (or
  ## leaves), the residual mean deviance (along with the total residual
  ## deviance and N-nodes), and the 5-stat summary of the residuals.
  ## The total residual deviance is the residual sum of squares: 
    
  rdev <- sum(sapply(resid(fit),function(x)(x-mean(resid(fit)))^2)) 
  
  (ndev - rdev)/ndev
  
   
#+end_src

** COMMENT use-trees-for-selecting-amongst-multiple-working-hypotheses-code
#+name:use-trees-for-selecting-amongst-multiple-working-hypotheses
#+begin_src R :session *R* :tangle src/use-trees-for-selecting-amongst-multiple-working-hypotheses.r :exports reports :eval no
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
  # load
  fpath <- system.file(file.path("extdata", "civst_gend_sector_full.csv"), package = "disentangle")
  
  analyte  <- read.csv(fpath)
  analyte$random <- rnorm(nrow(analyte), 0 , 1)
  summary(analyte)
  # create a large number of randome variables
  for(i in 1:75)
    {
      analyte[,ncol(analyte) + 1] <- rnorm(nrow(analyte), 10 , 20)    
    }
  names(analyte)
  str(analyte)
  analyte_varlist <- as.data.frame(names(analyte))
  write.csv(analyte_varlist, "inst/extdata/civst_gend_sector_withrnorm.csv", row.names=F)
  # edit with spreadsheet to include H1, H2, H3
  analyte_varlist <- read.csv("inst/extdata/civst_gend_sector_withrnorm.csv", stringsAsFactor = F)
  str(analyte_varlist)
  
#+end_src


** COMMENT Terminology
*** COMMENT 2013-12-03-non-linear-relationships-vs-non-linear-models
**** orgmode version
#+TITLE:non-linear-model-vs-non-linear-relationship 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

***** non-linear-relationships-vs-non-linear-models

- I value precise language very highly
- this is because in multi-disciplinary teams it is easy to talk using the same words and mean different things
- in recent discussion about [[http://cran.r-project.org/web/packages/dlnm/index.html][Distributed Lag Non-linear Models]] I started to reflect on something that has bothered me for a While
- back in 2005 my old mate Prof Keith Dear picked me up on using the term "non-linear model" incorrectly and explained the maths...
- I kind of understood but promptly forgot and found a lot of people use the term non-linear model a bit carelessly
- Yesterday I was in a discussion about comparing non-linear relationships between different studies in a meta-analysis
- I immediatly felt uncomfortable when we started to discuss these as "non-linear models"
- so here is a quick bit of google fu (with a session at the coffee shop with Steve and Mishka) to remind me about the difference between 

***** Nonlinear Regression vs. Linear Regression

- the following comes from
- http://www.ats.ucla.edu/stat/sas/library/SASNLin_os.htm
- verbatim except for my attempt at mathjax notation in latex

A regression model is called nonlinear, if the derivatives
of the model with respect to the model parameters depends on one or
more parameters. This definition is essential to distinguish nonlinear
from curvilinear regression. A regression model is not necessarily
nonlinear if the graphed regression trend is curved. A polynomial
model such as this:

***** Model 1

$Y_{i} = \beta_{0} + \beta_{1} X_{i} + \beta_{2} X_{i}^2 + \epsilon_{i}$

- appears curved when y is plotted against x. It is, however, not a nonlinear model. To see this, take derivatives of y with respect to the parameters b0, b1
- dy/db0 = 1 
- dy/db1 = x 
- dy/db2 = x^2 


- None of these derivatives depends on a model parameter, the model is linear. In contrast, consider the log-logistic model 

***** Model 2

$Y_{i} = d + (a - d)/(1 + e^{b \times log(x/g)}) + \epsilon$

- Take derivatives with respect to d, for example: 

$dy/dd = 1 - 1/(1 + e^{b \times log(x/g)})$

- The derivative involves other parameters, hence the model is nonlinear.

***** Conclusions

- It is probably best to refer to the polynomial as a "non-linear relationship" in a linear model
- reserving "non-linear model" for things like Model 2

***** COMMENT Draft
http://www.ats.ucla.edu/stat/sas/library/SASNLin_os.htm
Nonlinear Regression vs. Linear Regression

    A regression model is called nonlinear, if the derivatives of the model with respect to the model parameters depends on one or more parameters. This definition is essential to distinguish nonlinear from curvilinear regression. A regression model is not necessarily nonlinear if the graphed regression trend is curved. A polynomial model such as 

Model 1

y = b0 + b1x + b2x^2 + b3x^3 + b4z  + e 

appears curved when y is plotted against x. It is, however, not a nonlinear model. To see this, take derivatives of y with respect to the parameters b0, b1, and b2 (and 3): 
dy/db0 = 1 
dy/db1 = x 
dy/db2 = x^2 
dy/db3 = x^3 

None of these derivatives depends on a model parameter, the model is linear. In contrast, consider the log-logistic model 

Model 2

y = d + (a - d)/(1 + exp{b log(x/g)}) + e 

Take derivatives with respect to d, for example: 

dy/dd = 1 - 1/(1 + exp{b log(x/g)})

The derivative involves other parameters, hence the model is nonlinear.

**** md version
#+name:non-linear-relationships-vs-non-linear-models-vis-a-vis-curvi-linear-terms-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-03-non-linear-relationships-vs-non-linear-models-vis-a-vis-curvi-linear-terms.md :exports none :eval no :padline no
---
name: 2013-12-03-non-linear-relationships-vs-non-linear-models-vis-a-vis-curvi-linear-terms
layout: post
title: non-linear-relationships-vs-non-linear-models-vis-a-vis-curvi-linear-terms
date: 2013-12-03
categories:
- research methods
---


<head>
<title>non-linear-model-vs-non-linear-relationship </title>
<meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1"/>
<meta name="title" content="non-linear-model-vs-non-linear-relationship "/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2013-12-03T17:29+1100"/>
<meta name="author" content="Ivan Hanigan"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  html { font-family: Times, serif; font-size: 12pt; }
  .title  { text-align: center; }
  .todo   { color: red; }
  .done   { color: green; }
  .tag    { background-color: #add8e6; font-weight:normal }
  .target { }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  {margin-left:auto; margin-right:0px;  text-align:right;}
  .left   {margin-left:0px;  margin-right:auto; text-align:left;}
  .center {margin-left:auto; margin-right:auto; text-align:center;}
  p.verse { margin-left: 3% }
  pre {
	border: 1pt solid #AEBDCC;
	background-color: #F3F5F7;
	padding: 5pt;
	font-family: courier, monospace;
        font-size: 90%;
        overflow:auto;
  }
  table { border-collapse: collapse; }
  td, th { vertical-align: top;  }
  th.right  { text-align:center;  }
  th.left   { text-align:center;   }
  th.center { text-align:center; }
  td.right  { text-align:right;  }
  td.left   { text-align:left;   }
  td.center { text-align:center; }
  dt { font-weight: bold; }
  div.figure { padding: 0.5em; }
  div.figure p { text-align: center; }
  div.inlinetask {
    padding:10px;
    border:2px solid gray;
    margin:10px;
    background: #ffffcc;
  }
  textarea { overflow-x: auto; }
  .linenr { font-size:smaller }
  .code-highlighted {background-color:#ffff00;}
  .org-info-js_info-navigation { border-style:none; }
  #org-info-js_console-label { font-size:10px; font-weight:bold;
                               white-space:nowrap; }
  .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                 font-weight:bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js">
/**
 *
 * @source: http://orgmode.org/mathjax/MathJax.js
 *
 * @licstart  The following is the entire license notice for the
 *  JavaScript code in http://orgmode.org/mathjax/MathJax.js.
 *
 * Copyright (C) 2012-2013  MathJax
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * @licend  The above is the entire license notice
 * for the JavaScript code in http://orgmode.org/mathjax/MathJax.js.
 *
 */

/*
@licstart  The following is the entire license notice for the
JavaScript code below.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code below is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code below.
*/
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>

<div id="preamble">

</div>

<div id="content">
<h1 class="title">non-linear-model-vs-non-linear-relationship </h1>


<hr/>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 non-linear-relationships-vs-non-linear-models</a>
<ul>
<li><a href="#sec-1-1">1.1 Nonlinear Regression vs. Linear Regression</a>
<ul>
<li><a href="#sec-1-1-1">1.1.1 Model 1</a></li>
<li><a href="#sec-1-1-2">1.1.2 Model 2</a></li>
</ul>
</li>
<li><a href="#sec-1-2">1.2 Conclusions</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> non-linear-relationships-vs-non-linear-models</h2>
<div class="outline-text-2" id="text-1">


<ul>
<li>I value precise language very highly
</li>
<li>this is because in multi-disciplinary teams it is easy to talk using the same words and mean different things
</li>
<li>in recent discussion about <a href="http://cran.r-project.org/web/packages/dlnm/index.html">Distributed Lag Non-linear Models</a> I started to reflect on something that has bothered me for a While
</li>
<li>back in 2005 my old mate Prof Keith Dear picked me up on using the term "non-linear model" incorrectly and explained the maths&hellip;
</li>
<li>I kind of understood but promptly forgot and found a lot of people use the term non-linear model a bit carelessly
</li>
<li>Yesterday I was in a discussion about comparing non-linear relationships between different studies in a meta-analysis
</li>
<li>I immediatly felt uncomfortable when we started to discuss these as "non-linear models"
</li>
<li>so here is a quick bit of google fu (with a session at the coffee shop with Steve and Mishka) to remind me about the difference between 
</li>
</ul>



</div>

<div id="outline-container-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Nonlinear Regression vs. Linear Regression</h3>
<div class="outline-text-3" id="text-1-1">


<ul>
<li>the following comes from
</li>
<li><a href="http://www.ats.ucla.edu/stat/sas/library/SASNLin_os.htm">http://www.ats.ucla.edu/stat/sas/library/SASNLin_os.htm</a>
</li>
<li>verbatim except for my attempt at mathjax notation in latex
</li>
</ul>


<p>
A regression model is called nonlinear, if the derivatives
of the model with respect to the model parameters depends on one or
more parameters. This definition is essential to distinguish nonlinear
from curvilinear regression. A regression model is not necessarily
nonlinear if the graphed regression trend is curved. A polynomial
model such as this:
</p>

</div>

<div id="outline-container-1-1-1" class="outline-4">
<h4 id="sec-1-1-1"><span class="section-number-4">1.1.1</span> Model 1</h4>
<div class="outline-text-4" id="text-1-1-1">




\(Y_{i} = \beta_{0} + \beta_{1} X_{i} + \beta_{2} X_{i}^2 + \epsilon_{i}\)

<ul>
<li>appears curved when y is plotted against x. It is, however, not a nonlinear model. To see this, take derivatives of y with respect to the parameters b0, b1
</li>
<li>dy/db0 = 1 
</li>
<li>dy/db1 = x 
</li>
<li>dy/db2 = x<sup>2</sup> 
</li>
</ul>



<ul>
<li>None of these derivatives depends on a model parameter, the model is linear. In contrast, consider the log-logistic model 
</li>
</ul>


</div>

</div>

<div id="outline-container-1-1-2" class="outline-4">
<h4 id="sec-1-1-2"><span class="section-number-4">1.1.2</span> Model 2</h4>
<div class="outline-text-4" id="text-1-1-2">




\(Y_{i} = d + (a - d)/(1 + e^{b \times log(x/g)}) + \epsilon\)

<ul>
<li>Take derivatives with respect to d, for example: 
</li>
</ul>




\(dy/dd = 1 - 1/(1 + e^{b \times log(x/g)})\)

<ul>
<li>The derivative involves other parameters, hence the model is nonlinear.
</li>
</ul>


</div>
</div>

</div>

<div id="outline-container-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> Conclusions</h3>
<div class="outline-text-3" id="text-1-2">


<ul>
<li>It is probably best to refer to the polynomial as a "non-linear relationship" in a linear model
</li>
<li>reserving "non-linear model" for things like Model 2
</li>
</ul>



</div>
</div>
</div>
</div>

</body>
</html>
#+end_src


* Bibliograph-ology
** 2013-11-20-sync-endnote-and-mendeley-references-using-r-xml
*** Intro
#+name:sync-endnote-and-mendeley-references-using-r-xml-header
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-20-sync-endnote-and-mendeley-using-r-xml.md :exports none :eval no :padline no
  ---
  name: 2013-11-20-sync-endnote-and-mendeley-using-r-xml
  layout: post
  title: sync-endnote-and-mendeley-references-using-r-xml
  date: 2013-11-20
  categories:
  - research methods
  ---
  
  #### Background
  - I use Mendeley (despite them being bought out by Elsevier, who used to sell guns)
  - My Colleagues use EndNote 
  - Need to sync, they find Endnote better for their workflow
  - I tried to export my Mendeley as XML and import to Endnote, but found many duplicates that took time to rectify 
  - (and the risk is there that the RefNo they used in the Doc will be the duplicate that I removed)
  
  #### Aims
  - test if R and the XML package can help find refs in Endnote that aren't in Mendeley
  - If so can I write those into an Mendeley import for seamless integrations
  - and what about going from Mendeley to Endnote?
  
  #### Methods
  - The R XML package seems an obvious place to start
  - before writing a function, just step thru the process
  
  #### Step 1: export XML from Mendeley and Endnote
  - In Mendeley Just select the refs in the list and then from the file menu
  - In Endnote it is also under File menu
  
  #### Step 2: R Code:
      # func
      # might need sudo apt-get install r-cran-xml?
      require(XML)
  
      # load
      dir()
      [1] "EndnoteCollection.xml"
          "MendeleyCollection.Data"
      [3] "MendeleyCollection.xml" 
      
      d1 <- xmlTreeParse("EndnoteCollection.xml", useInternal=T)
  
      # clean
      str(d1)
      # ooooh xml schmexemhel voodoo?
  
      # do
      top <- xmlRoot(d1)
      str(top)
      names(top)
      # top [[1]] # prints the whole thing
      top [[1]][[1]]
      top [[1]][[2]]
      # prints a record (1 or 2)
  
      # just messing around
      length(top[[1]])
      top [[1]][[120]]
      names(top [[1]][[120]])
      names(top [[1]][[120]][["contributors"]])
      names(top [[1]][[120]][["contributors"]][["authors"]])
      top [[1]][[120]][["contributors"]][["authors"]][[2]]
      
      i <- 110
      top [[1]][[i]]
      as.matrix(names(top [[1]][[i]]))
  
  #### OK so XML as a list.
  - I think if I do a merge of two author-date-title dataframes I can easily find the diffs
  
  
  #### TRY a square wheel
#+end_src
*** some crazy stuff
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-20-sync-endnote-and-mendeley-using-r-xml.md :exports none :eval no :padline no
  #### R Code:
      endnote_mendeley_df <- function(input_xml,
                                      nrow_to_try = 1000){
        d1 <- xmlTreeParse(input_xml, useInternal=T)
        top <- xmlRoot(d1)
       
        output <- matrix(ncol = 4, nrow = 0)
        for(i in 1:nrow_to_try)
        {
        # i = 1000
          if(is.na(xmlValue(top [[1]][[i]]))) break
          if(
            !is.na(xmlValue(top [[1]][[i]][["contributors"]][["authors"]][[2]]))
            )
          {
            author <- paste(xmlValue(top [[1]][[i]][["contributors"]][["authors"]][[1]]), "et al", " ")
          } else {
            author <- xmlValue(top [[1]][[i]][["contributors"]][["authors"]][[1]])
          }
          year <- xmlValue(top [[1]][[i]][["dates"]][["year"]])
          title <- xmlValue(top [[1]][[i]][["titles"]][[1]])
          endnoteref <- xmlValue(top [[1]][[i]][["rec-number"]])
          output <- rbind(output, c(author, year, title, endnoteref))
       
        }
        output <- as.data.frame(output)
        return(output)
      }
  
  #### R Test:
      output <- endnote_mendeley_df(
        input_xml = "EndnoteCollection.xml"
        ,
        nrow_to_try = 10
        )
  
      nrow(output)
      write.csv(output, "EndnoteCollection.csv", row.names = F)
      output  <- read.csv("EndnoteCollection.csv", stringsAsFactors = F)
      str(output)
      output[,1:2]
  
  #### R Do-read:
      endnote <- endnote_mendeley_df(
        input_xml = "EndnoteCollection.xml"
        )
      nrow(endnote)
      mendeley <- endnote_mendeley_df(
        input_xml = "MendeleyCollection.xml"
        )
      nrow(mendeley)
  
  #### R Do-concatenate and lowercase
      # TODO this is a really terrible way to do this.
      # FIXME find out how to compare the two better
      require(stringr)
      mendeley2 <- str_c(mendeley$V1, mendeley$V2, mendeley$V3)
      mendeley2 <- gsub(" ", "", mendeley2)
      mendeley2 <- gsub(",", "", mendeley2)
      mendeley2 <- tolower(mendeley2)
      mendeley2[1:5]
      mendeley$mendeley2 <- mendeley2
  
      # now do this again from endnote
      endnote2 <- str_c(endnote$V1, endnote$V2, endnote$V3)
      endnote2 <- gsub(" ", "", endnote2)
      endnote2 <- gsub(",", "", endnote2)
      endnote2 <- tolower(endnote2)
      endnote2[1:5]
      endnote$endnote2 <- endnote2
  
  #### R Do-merge:
      endnote_not_in_mendeley <- merge(endnote,
                                       mendeley,
                                       by.x = "endnote2",
                                       by.y = "mendeley2",
                                       all.x = T)
      str(endnote_not_in_mendeley)
      nrow(endnote_not_in_mendeley)
      head(endnote_not_in_mendeley)
      endnote_not_in_mendeley <- endnote_not_in_mendeley[
                                                         is.na(endnote_not_in_mendeley$V1.y),
                                                         ]
      nrow(endnote_not_in_mendeley)
      # 66 refs in endnote are not in mendeley
      write.csv(endnote_not_in_mendeley,
            "endnote_not_in_mendeley.csv", row.names = F)
  
#+end_src
*** Check in spreadsheet
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-20-sync-endnote-and-mendeley-using-r-xml.md :exports none :eval no :padline no
  
  #### Open this as spreadsheet and cross check
  - make a new column for comments
  - check off which ones were in AllDocuments and not in the Mendeley group
  - this diff was because of when I imported the Endnote XML but had not assigned these to the mendeley group
  - once have cleaned up the mendeley group export again and then check which are in mendeley but not in endnote
  
  #### First here is a note
  - about a way to speed up the checks, excluding false positives using fuzzy matching
  - my method relies on the author, date and title to be written the same in both ie initials then surname or visa verca
  - But this is not always true 
  - I previously used levenshtein string matching to identify strings that are close but not identical
  - [Try this link]( http://wiki.r-project.org/rwiki/doku.php?id=tips:data-strings:levenshtein)
  - [OR this link](http://rwiki.sciviews.org/doku.php?id=tips:data-strings:levenshtein)
  - TODO I will share this code as a GitHub Gist later!
  
  
  #### R Code: possibility to speed up Checks
      tmp1 <- mendeley[grep("Walker", mendeley$V1),"mendeley2"]
      tmp2 <- endnote[grep("Walker", endnote$V1),"endnote2"]
  
      # these differ slightly
      # B. Walker et al vs Walker, Brian et al
      source("~/Dropbox/tools/levenshtein.r")
      levenshtein(
          tmp1
          ,
          tmp2
          )
      # gives 92percent match
  
  
  #### R Code: Find mendeley refs without endnote
        endnote <- endnote_mendeley_df(
          input_xml = "EndnoteCollection.xml"
          )
        nrow(endnote)
        mendeley <- endnote_mendeley_df(
          input_xml = "MendeleyCollection2.xml"
          )
        nrow(mendeley)
#+end_src
*** Do concatenate and loercase    
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-20-sync-endnote-and-mendeley-using-r-xml.md :exports none :eval no :padline no
  
  #### R Code: Do-concatenate and lowercase
      require(stringr)
      mendeley2 <- str_c(mendeley$V1, mendeley$V2, mendeley$V3)
      mendeley2 <- gsub(" ", "", mendeley2)
      mendeley2 <- gsub(",", "", mendeley2)
      mendeley2 <- tolower(mendeley2)
      mendeley2[1:5]
      mendeley$mendeley2 <- mendeley2
  
      # now do this again from endnote
      endnote2 <- str_c(endnote$V1, endnote$V2, endnote$V3)
      endnote2 <- gsub(" ", "", endnote2)
      endnote2 <- gsub(",", "", endnote2)
      endnote2 <- tolower(endnote2)
      endnote2[1:5]
      endnote$endnote2 <- endnote2
  
  #### R Do-merge:
      mendeley_not_in_endnote <- merge(mendeley,
                                       endnote,
                                       by.y = "endnote2",
                                       by.x = "mendeley2",
                                       all.x = T)
      str(mendeley_not_in_endnote)
      nrow(mendeley_not_in_endnote)
      head(mendeley_not_in_endnote)
      mendeley_not_in_endnote <- mendeley_not_in_endnote[
                                                            is.na(mendeley_not_in_endnote$V1.y),
                                                            ]
      nrow(mendeley_not_in_endnote)
      # 92 refs in endnote are not in mendeley
      write.csv(mendeley_not_in_endnote,
            "mendeley_not_in_endnote.csv", row.names = F)
  #### Not all these 92 will be true
  - so let;s try the string matching
   
  #### R Code:
      source("~/Dropbox/tools/levenshtein.r")
      pcnt_threshold <- 0.6
      out_list <- matrix(ncol = 3, nrow = 0)
      #out_list <- read.csv("mendeley_not_in_endnote_fz_match.csv", stringsAsFactors = F)
      for(i in 36:nrow(mendeley_not_in_endnote))
          {
              print(i)
      #        i = 2
      tmp1 <- mendeley_not_in_endnote[i,1]
          for(j in 1:nrow(endnote))
              {
          #        j = 2
          if(exists("out")) rm(out)
          tmp2 <- endnote$endnote2[j]
          pcnt <- levenshtein(
                  tmp1
                  ,
                  tmp2
                  )
          #pcnt
          if(pcnt >= pcnt_threshold) out <- tmp2
          if(exists("out"))
              out_list <- rbind(out_list, c(tmp1, tmp2, pcnt))
          if(exists("out")) break
              }
              
          }
      out_list
      write.csv(out_list, "mendeley_not_in_endnote_fz_match.csv", row.names = F)
   
      
      
#+end_src
*** COMMENT TODO do something with these
#+begin_src R :session *R* :tangle no :exports none :eval no :padline no
  #### R Code: do something with these
  todo_stuff <- read.csv("endnote_not_in_mendeley.csv")
  authoryear <- str_c(todo_stuff$V1.x, todo_stuff$V2.x)
  
  input_xml <- "EndnoteCollection.xml"
  nrow_to_try <- 1000
  
  d1 <- xmlTreeParse(input_xml, useInternal=T)
  top <- xmlRoot(d1)
  for(i in authoryear)
      {
  #       i <- authoryear[3]
       auth <- strsplit(i, " et al  ")[[1]][1]
       yy <- strsplit(i, " et al  ")[[1]][2]
       
  for(j in 1:nrow_to_try)
    {
        print(j)
      #j = 1
    if(is.na(xmlValue(top [[1]][[j]]))) break
    if(is.na(xmlValue(top [[1]][[j]][["dates"]][["year"]]))) next
        
    if(
      xmlValue(top [[1]][[j]][["contributors"]][["authors"]][[1]]) == auth
        &
        xmlValue(top [[1]][[j]][["dates"]][["year"]]) == yy
       )
        {
            out <- top[[1]][j]
            #saveXML(out, sprintf("%s-%s.xml", auth, yy), encoding = "UTF-8")
            #sink(sprintf("%s-%s.xml", auth, yy))
            #cat(out)
            #sink()
            # TODO how to save out this XML NodeList
            if(exists("out")) break
        }
    }
           rm(out) 
   }
  
#+end_src

*** select out of mendeley and send to Endnote
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-20-sync-endnote-and-mendeley-using-r-xml.md :exports none :eval no :padline no
  
  #### R Code: Do-concatenate and lowercase
      require(stringr)
      out_list <- read.csv("mendeley_not_in_endnote_fz_match.csv", stringsAsFactors = F)
      mendeley2 <- read.csv("mendeley_not_in_endnote.csv", stringsAsFactors=F)
      mendeley2[1,]
      out_list[1,]
      mendeley2 <- merge(mendeley_not_in_endnote, out_list,
                         by.x = "mendeley2",
                         by.y = "V1", all.x = T)
      mendeley2[2,]
      mendeley2 <- mendeley2[is.na(mendeley2$V3),]
      nrow(mendeley2)
      # 48 records
      write.csv(mendeley2, "mendeley_not_in_endnote_best_estimate.csv", row.names=F)
  
  
  
#+end_src
*** results, conclude
#+begin_src R :session *R* :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-20-sync-endnote-and-mendeley-using-r-xml.md :exports none :eval no :padline no

#### Results
- I found that XML package in R can work with the Endnote and Mendeley export Files
- I think I made a lot of bad decisions about the way I went about  doing this!
- It seemed quite difficult to get the XML stuff to make sense to me
- I;ve heard that python has better libraries for working with XML
- the levenshtein string matching code proved useful again.  I should get out of the habit of looping and start using lapply etc to speed this up.
  
#### Conclusions
- This was an interesting if frustrating experiment
- The minor issues with importing from mendeley/endnote and deduplicating using their own tools was probably not worth writing all this half-baked R code.
- But I did learn more about working with XML in R (and realised this is probably not one of R's Strengths -- or mine for that matter!)

#+end_src

* Code Editors
* Workflow Tools
** R-newnode
*** COMMENT R-newnode
#+name:newnode
#+begin_src R :session *R* :tangle R/newnode.r :exports none :eval no
  ################################################################
  # name:newnode
  newnode<-function(name, inputs=NA, outputs=character(0), graph = 'nodes', newgraph=F, notes=F, code=NA, ttype=NA, plot = T){
    # USAGE
    # nodes <- newnode(  # adds to a graph called nodes
    # name = 'aquire the raw data'  # the name of the node being added 
    # inputs = REQUIRED c('external sources','collected by researcher') # single or multiple inputs to it
    # outputs = OPTIONAL c('file server','metadata','cleaning') # single or multiple outputs from it
    # append=F # append to existing graph?  if False remove old graph of that name and start new
    # TODO 
    # nodes <- addEdge(from='analyse using stats package',
    # to='new data in database server',graph=nodes,weights=1)
    # INIT
    # source('http://bioconductor.org/biocLite.R')
    # biocLite("Rgraphviz")
    # or may be needed for eg under ubuntu
    # biocLite("Rgraphviz", configure.args=c("--with-graphviz=/usr"))
    require(Rgraphviz)
    # FURTHER INFO
    # see the Rgraphviz examples
    # example(layoutGraph)
    # require(biocGraph) # for imageMap
    # TODO change names in following
    dsc <- name
    i <- inputs
    o <- outputs
    #   if(!exists('nodes')) {
    if(newgraph==T) {    
      nodes <- new("graphNEL", nodes=c(dsc),
                 edgemode="directed")
      # nodes <- addEdge(from=i, to=dsc, graph=nodes, 1)    
    } else {
      if(length(grep(dsc,nodes@nodes)) == 0) nodes <- addNode(node=dsc,object=nodes)
    }  
    if(sum(i %in% nodes@nodes) != length(i)) {
      inew <- i[!i %in% nodes@nodes]
      nodes <- addNode(node=inew,object=nodes)   
    }
    nodes <- addEdge(i, dsc, nodes, 1)
    #}
    if(length(o) > 0){
    if(sum(o %in% nodes@nodes) != length(o)) {
      onew <- o[!o %in% nodes@nodes]
      nodes <- addNode(node=onew,object=nodes)   
    }
    nodes <- addEdge(from=dsc, to=o, graph=nodes, 1)  
    }
    if(plot == T){
      try(silent=T,dev.off())
      plot(nodes,attrs=list(node=list(label="foo", fillcolor="grey",shape="ellipse", fixedsize=FALSE), edge=list(color="black")))
    }
    return(nodes)
  }
  
#+end_src
*** test-newnode
#+name:newnode
#+begin_src R :session *R* :tangle tests/test-newnode.r :exports reports :eval no
  ################################################################
  # name:newnode
  # REQUIRES GRAPHVIZ, AND TO INSTALL RGRAPHVIZ
  # source('http://bioconductor.org/biocLite.R')
  # biocLite("Rgraphviz")
  # or may be needed for eg under ubuntu
  # biocLite("Rgraphviz", configure.args=c("--with-graphviz=/usr"))
  # FURTHER INFO
  # see the Rgraphviz examples
  # example(layoutGraph)
  # require(biocGraph) # for imageMap
  
  # source("R/newnode.r")
  require(devtools)
  install_github("disentangle", "ivanhanigan")
  require(disentangle)
  newnode(
    name = "NAME"
    ,
    inputs="INPUT"
    ,
    outputs = "OUTPUT"
    ,
    graph = 'nodes'
    ,
    newgraph=T
    ,
    notes=F
    ,
    code=NA
    ,
    ttype=NA
    ,
    plot = T
    )
  
  nodes <- newnode("merge", c("d1", "d2", "d3"), c("EDA"),
                   newgraph =T)
  nodes <- newnode("qc", c("data1", "data2", "data3"), c("d1", "d2", "d3"))
  nodes <- newnode("modelling", "EDA")
  nodes <- newnode("model checking", "modelling", c("data checking", "reporting"))
  #require(disentangle)
  # either edit a spreadsheet with filenames, inputs and outputs 
  # filesList <- read.csv("exampleFilesList.csv", stringsAsFactors = F)
  # or 
  filesList <- read.csv(textConnection(
  'FILE,INPUTS,OUTPUTS,DESCRIPTION
  siteIDs,GPS,,latitude and longitude of sites
  weather,BoM,,weather data from BoM
  trapped,siteIDs,,counts of species caught in trap
  biomass,siteIDs,,
  corralations,"weather,trapped,biomass",report1,A study we published
  paper1,report1,"open access repository, data package",
  '), stringsAsFactors = F)
  # start the graph
  i <- 1
  nodes <- newnode(name = filesList[i,1],
                   inputs = strsplit(filesList$INPUTS, ",")[[i]],
                   outputs =
                   strsplit(filesList$OUTPUTS, ",")[[i]]
                   ,
                   newgraph=T)
   
  for(i in 2:nrow(filesList))
  {
    # i <- 2
    if(length(strsplit(filesList$OUTPUTS, ",")[[i]]) == 0)
    {
      nodes <- newnode(name = filesList[i,1],
                       inputs = strsplit(filesList$INPUTS, ",")[[i]]
      )    
    } else {
      nodes <- newnode(name = filesList[i,1],
                       inputs = strsplit(filesList$INPUTS, ",")[[i]],
                       outputs = strsplit(filesList$OUTPUTS, ",")[[i]]
      )
    }
  }
   
  #dev.copy2pdf(file='fileTransformations.pdf')
  #dev.off();
   
#+end_src
*** COMMENT TODO man-newnode
#+name:newnode
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:newnode

#+end_src

** 2013-11-25-setting-up-a-workflow-script
#+name:project-template-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-25-setting-up-a-workflow-with-code-chunks.md :exports none :eval no :padline no
  ---
  name: 2013-11-25-setting-up-a-workflow-with-code-chunks
  layout: post
  title: Setting Up A Workflow Script With Code Chunks
  date: 2013-11-25
  categories:
  - research methods
  ---
  
  This post describes some ideas and techniques I use to set up a "workflow script".  I use this term to refer to the structured combination of code, data and narrative that make an executable Reproducible Research Report (RRR).
  
  A lot of these ideas are inpsired by  a great paper by Kieran Healy called  "Choosing Your Workflow Applications" available at [https://github.com/kjhealy/workflow-paper](https://github.com/kjhealy/workflow-paper) to accompany [his Emacs Starter Kit](http://kieranhealyo.org/resources/emacs-starter-kit.html). My shortened version of his main points are:
  
  - 1 use a good code editor
  - 2 analyse data with scripts
  - 3 store your work simply and document it properly
  - 4 use a version control system
  - 5 Automate back ups 
  - 6 Avoid distracting gadgets
  
  #### Here's my current approach in each of these categories
  - 1 use Emacs with Orgmode (and kjhealy's drop-in set of useful defaults)
  - 2 Scripts that utilise the literate programming technique of mixing Code Chunks in with descriptive prose
  - 3 John Myles White's ProjectTemplate R Package and Josh Riech's LCFD paradigm 
  - 4 git and GitHub for version control
  
  5 Automated Backups and 6 Avoiding Gadgets are still somethings I find challenging
  
  #### 1 Use a good code editor
  I like using Emacs with Orgmode.
  
  - I have previously tried a variety of code editors from Tinn-r, NppToR, Rstudio and Eclipse.  
  - Emacs with Orgmode suits me the most because it has a great number of features especially the linkage with LaTeX or HTML export
  - A key reference to look at for reasons why Emacs is so good for scientific work is Eric Schulte et al ["A Multi-Language Computing Environment for Literate Programming"](www.jstatsoft.org/v46/i03‎) 
  - Here is a [link to a great orgmode description](http://doc.norang.ca/org-mode.html)
  - (this guy spends a lot of time on tweaking his set up)
  
  #### 2 Analyse data with Scripts (stitch together code chunks)
  I use Scripts but prefer to think of them as stitched together Code Chunks with prose into Compendia.
  
  - Compendia are documents that weave together Code and Prose into an executable report
  - The underlying philosophy is called Reproducible Research Reports
  - A very useful tool is a keyboard shortcut to quickly create a chunk for code
  - so you can be writing parts of the report like this: "Blah Blah Blah as shown in Figure X and Table Y"
  - then just hit the correct keys and WHAMM-O there is a new chunk ready for the code that creates Figure X and Table Y to be written.
  - Here is how I use Emacs to achieve this (the other editors I mentioned above also have the abiltiy to do this too).  The IPython Notebook does this stuff too but calls chunks "cells" for some reason.
  
  #### Emacs Code: Put this into the ~/.emacs.d/init.el file
      (define-skeleton chunk-skeleton
        "Info for a code chunk."
        "Title: "
        "*** " str "-code\n"
        "#+name:" str "\n"
        "#+begin_src R :session *R* :tangle src/" str ".r :exports reports :eval no\n"
        "#### name:" str " ####\n"
        "\n"
        "#+end_src\n"
      )
      (global-set-key [?\C-x ?\C-\\] 'chunk-skeleton)
  
  #### Using the Emacs Shortcut
  - now whenever you type Control-x control-\ a new code chunk will appear
  - you'll be typing "blah blah blah" and think I need a figure or table, just hit it.
  - move into the empty section and add some code
  - you can hit C-c ' to enter a org-babel code execution session that will be able to send these line by line to an R session
  - or within the main org buffer if your eval flag is set to yes then you can run the entire chunk (and return tabular output to the doc) using C-c C-c
  - To export the code chunks and create the modular code scripts without the narrative prose use C-c C-v t
  - this is called "tangling" and the chunks will be written out to the file specified in the chunk header ":tangle" flag
  
  #### Compiling the resulting Compendium
  - Emacs uses LaTeX or HTML to produce the Report
  - I find both of these outputs very pleasing
  - to compile to TEX use C-c C-e d
  - for HTML use C-c C-e h (FOR CODE HIGHLIGHTING INSTALL htmlize.el)
  - these commands will also evaluate all the chunks where ":eval" = yes to load the data and calculate the results fresh. 
  - AWESOME!
      
  #### 3 Store your work simply and document it properly
  - I use the [ProjectTemplate R package](http://www.johnmyleswhite.com/notebook/2010/08/26/projecttemplate/) to organise my code sections into modules
  - These modules are organised into the Reichian LCFD paradigm described first [on StackOverflow here](http://stackoverflow.com/a/1434424), and encoded into [the makeProject R package](http://cran.r-project.org/web/packages/makeProject/makeProject.pdf)
  - documentation is within the main orgmode script
  - data documentation is a whole other universe that I will deal with in a separate post
  
  #### 4 use a version control system using git and github
      # once you have the project via R
      R
      require(ProjectTemplate)
      create.project("AwesomeProject", minimal = T)
      q()
      # use the shell to start a git repo
      cd AwesomeProject
      git init
      # and commit the TODO
      git add TODO
      git commit -m "first commit"
      # tada!
  
  - Emacs can now be used to manage the git repo using the C-x g command
  - Rstudio has a really nice GUI for doing this inside it;s Project management interface too.
  
  #### Using Github or another Git Server
  - You can easily set up a Github repo for this now but it will be public
  - Alternatative is to set up your own private Git server.  I followed [these instructions to Running a Simple Git Server Using SSH](http://blog.goosoftware.co.uk/2012/02/07/quick-git-server/)
  - Either way once you have set up your remote git repo you need to set the remote tracking
  
  #### Git Code:
      cd /path/to/local/git/repo
      git remote add origin git@github-or-other-server:myname/myproject.git
      git push origin master
  
  #### 5 Automate back ups AND 6 Avoid distracting gadgets
  - OMG backups stress me out
  - ideally I would follow [this advice because "when it comes to losing your data the universe tends toward maximum irony. Don't push it."](http://www.jwz.org/blog/2007/09/psa-backups/)
  - But I don;t fully comply
  - Instead I generally use Dropbox for  basic project management admin stuff
  - I use github for code projects I am happy to share, I also pay for 10 private repos 
  - I Set up a git server at my workplace for extra projects but this is on a test server that is not backed up, and I am not really happy about this
  - In terms of Distracting Gadgets, I think that with the current tempo of new innovations related to new software tools for this type of work I should keep trying new things but I have pretty much settled into a comfortable zone with the gadgets I described here. 
  
  #### Conclusions
  - This is how I've worked for a couple of years
  - I find it very enjoyable, mostly productive but prone to the distractions of "distractions by gadgets"
  - The main thing I want to point out is the usage of Code Chunks in RRR scripts.
  - These things are awesome.
      
#+end_src

** 2013-12-01-graphviz-automagic-flowcharts
*** workflow_steps-code
#+begin_src R :session *R* :tangle no :exports reports :eval no :padline no
# ~/tools/transformations/workflow_steps.txt
Transformation
	description
		the thing 
	inputs
		the thing before
		another thing
	output
		the next thing
	notes
		the thing is this other thing	this is a really long description 
		blah blah asdfasdfasdfasdfasdfa 

Transformation
	description
		yet another thing
	inputs
		the next thing
	output
		a final thing
	notes
		this is a note

#+end_src

*** post
#+name:graphviz-automagic-flowcharts-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-01-graphviz-automagic-flowcharts.md :exports none :eval no :padline no
  ---
  name: 2013-12-01-graphviz-automagic-flowcharts
  layout: post
  title: graphviz-automagic-flowcharts
  date: 2013-12-01
  categories:
  - research methods 
  ---
  
  - Back in 2009 Joseph Guillaume worked with me on a complicated workflow
  - He came up with this python script to help keep track of the steps
  - The simple text file is a list of transformations, inputs and output
  - It is converted to the right format and graphviz creates a html page with pop-outs
  
  #### Simple text list
      Transformation
              description
                      the thing 
              inputs
                      the thing before
                      another thing
              output
                      the next thing
              notes
                      the thing is this other thing   this is a really long description 
                      blah blah asdfasdfasdfasdfasdfa 
       
      Transformation
              description
                      yet another thing
              inputs
                      the next thing
              output
                      a final thing
              notes
                      this is a note
  
  <p></p>
  
  - keep this in your work directory and update it whenever you add a step to the workflow
  - the list can be as big as you like (hundreds of steps), and entered in any order, the inputs/output relationships determine how the graph looks at the end
  - to run the script just do the one line

  #### Python code: run
      python transformations.py workflow_steps.txt index
  
  <p></p>
  - open the html page and click on a square box to bring up the pop-out
  - short text is shown, long text is replaced by an ellipse and only shown in pop-out
  
  #### Conclusions  
  - I've popped the script up as a [Github repo](https://github.com/ivanhanigan/transformations)
  - The example is in the [gh-pages branch](http://ivanhanigan.github.io/transformations/)
  
#+end_src

** 2013-12-24-a-few-best-practices-for-statistical-programming
#+name: a-few-best-practices-for-statistical-programming-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-24-a-few-best-practices-for-statistical-programming.md :exports none :eval no :padline no
---
name: 2013-12-24-a-few-best-practices-for-statistical-programming
layout: post
title: a-few-best-practices-for-statistical-programming
date: 2013-12-24
categories:
- research methods
---

- John Myles White invented the ProjectTemplate R Package
- This is a great application that helps streamline the process of creating a data analysis project
- Recently John posted about some tips for [best practices for statistical programming](http://www.johnmyleswhite.com/notebook/2013/01/24/writing-better-statistical-programs-in-r/)


#### Best Practices for Statistical Programming

- Write Out a Directed Acyclic Graph (DAG)
- Vectorize Your Operations
- Profile your code and understand where it spends its time
- Generate Data and Fit Models
- Correctness: always ensure that code infers  parameters of models given simulated data with known parameters.


#### Additional suggestions

- Unit Testing (use testthat)
- Create modular code with discrete chunks
- Write functions as much as possible, put these into a personal 'misc' package
   
#+end_src

* Graphical User Interfaces
** TODO ORACLE XE APEX / HTMLDB
*** Drill down reports


in oracle the method to create the drill down reports is

   1)create tables
   2)create pkeys and foriegn keys
   3)create sequences
   4)create triggers
   5)create blank pages
   6)create new page
   7)          choose form
   8)          choose form on report
   9)          select the report to go on the blank page
  10)        let the form create a new page
  11)create a hidden item on report page IE :P2_IDNO
  12)change report regions source SQL to 'WHERE [IDNO/FILEID ETC] = :P2_IDNO
  13)set up the link on the previous page if applicable
in the form page set the default value for say IDNO to PL/SQL expression & = :P2_IDNO for eg

** TODO web2py
*** refs
http://stackoverflow.com/questions/6514680/gui-interface-for-sqlite-data-entry-in-python
http://killer-web-development.com/section/1/0
# dogs and owners
http://web2py.com/books/default/chapter/29/07/forms-and-validators
http://stackoverflow.com/questions/11905471/web2py-show-a-different-reference-field-than-id
*** Exploratory
[[~/tools/web2py/applications/pitch/pitch-overview.org]]
* Version Control
** 2013-11-19-git-can-be-simple-or-very-complicated
#+name:git-can-be-simple-or-very-complicated-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-19-git-can-be-simple-or-very-complicated.md :exports none :eval no :padline no
---
name: 2013-11-19-git-can-be-simple-or-very-complicated
layout: post
title: git-can-be-simple-or-very-complicated
date: 2013-11-19
categories:
- research methods
---
    
- Git is a Distributed Version Control System.
- The [centerforopenscience.org](centerforopenscience.org) has developed the Open Science Framework  which is they say "a simplified front end to the powerful and popular version control system Git".
- I use Github a lot for extending the local features into an online space
- So I finally got around to poking the open science framework with the [Hutchinson Drought Index project](https://openscienceframework.org/project/pyts3/)
- It turns out to be too simplified, and not have very many of the feature I love about Git and GitHub :-(
- For eg it is not really distributed in that you don't get to sync your local repo with the onlin version
- you upload a script or dataset, then you continue editing locally until you want to commit and then you have to upload again, one file at a time with the GUI rather than "git add ." and "git push".
- I recommend having a look, it might work for you, but if you want more power checkout Yihui's suggestions for using github [http://yihui.name/en/2011/12/how-to-become-an-efficient-and-collaborative-r-programmer/](http://yihui.name/en/2011/12/how-to-become-an-efficient-and-collaborative-r-programmer/)
- and [http://yihui.name/en/2013/06/fix-typo-in-documentation/](http://yihui.name/en/2013/06/fix-typo-in-documentation/)

#### In general I don't think simple front-end's should be a barrier to accessing a sophisticated back-end!

#+end_src

** 2013-12-09-bitbucket-has-unlimited-private-git-repositories-for-universities
#+name:bitbucket-has-unlimited-private-git-repositories-for-universities-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-09-bitbucket-has-unlimited-private-git-repositories-for-universities.md :exports none :eval no :padline no
---
name: 2013-12-09-bitbucket-has-unlimited-private-git-repositories-for-universities
layout: post
title: bitbucket-has-unlimited-private-git-repositories-for-universities
date: 2013-12-09
categories:
- research methods
---

- I just got introduced to bitbucket, an alternative to Github
- I've used Github for a couple of years and have been paying for extra private repositories 
- I did not realise that bitbucket worked with git too (I thought it was just for Mercurial)
- it offers unlimited public and private repository and unlimited users (to collaborate) if you have the Academic plan.
- when you sign up with your academic email address, [you automatically get an unlimited academic plan]( http://blog.bitbucket.org/2011/04/01/free-unlimited-user-source-code-hosting-for-university-students/)

#+end_src

** 2013-12-09-dual-code-repository-and-project-website
#+name:dual-code-repository-and-project-website-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-09-dual-code-repository-and-project-website.md :exports none :eval no :padline no
  ---
  name: 2013-12-09-dual-code-repository-and-project-website
  layout: post
  title: dual-code-repository-and-project-website
  date: 2013-12-09
  categories:
  - research methods
  ---
  
  - I really like the idea of using github or bitbucket for a dual code repository and project website
  - in Github I set up the master branch with the R package code
  - and set up the website using the gh-pages branch 
  - it has to be called gh-pages, and add an index.html, it will appear at your-username.github.com/repo-name
  
  #### Github

  - The best bit about doing this on github is that the R package "devtools" can be used to install the package (so long as you can compile the package)
  - on windows you may need to install Rtools and configure the path

  #### R Code: install_github
      require(devtools)
      install_github("repo-name", "github-account-name")

  #### Bitbucket

  - I recently took these notes about setting up a website on Bitbucket
  - I am not sure about how this would work for R packages (the devtools installer mentioned above is a great tool for developing)
  - but with unlimited private repositories this seems like a good platform for my "open notebook - selected content" (I need to be selective about what I share and what I keep restricted access only)  
  - the page is available for "your-account".bitbucket.org
  - create a new repo on the web UI 
  - I kept the repo private, but the pages will be public,
  - added issue tracking and Wiki
  
  #### using git shell
      mkdir ~/projects/your-account.bitbucket.org
      cd ~/projects/your-account.bitbucket.org
      git init
      git remote add origin ssh://git@bitbucket.org/your-account/your-account.bitbucket.org.git
      touch index.org
      # use emacs to make changes and publish the html (C-c C-e h)
       
      git commit -m "First commit"
      git push -u origin master
  
  - now it is online at http://your-account.bitbucket.org/
  
  - More info at:
  [https://confluence.atlassian.com/display/BITBUCKET/Publishing+a+Website+on+Bitbucket](https://confluence.atlassian.com/display/BITBUCKET/Publishing+a+Website+on+Bitbucket)
      
#+end_src

* Latex/Sweave/orgmode/knitr
** Orgmode headers
*** 2013-11-26-a-sharp-looking-orgmode-latex-export-header
**** raw
    [[~/Dropbox/projects/tools/LaTeX templates/Sweave/SweaveExample1.Rnw]]
see [[./src/SharpReportTemplate.org]]
**** blogged
#+name:a-sharp-looking-orgmode-latex-export-header-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-26-a-sharp-looking-orgmode-latex-export-header.md :exports none :eval no :padline no
  ---
  name: 2013-11-26-a-sharp-looking-orgmode-latex-export-header
  layout: post
  title: a-sharp-looking-orgmode-latex-export-header
  date: 2013-11-26
  categories:
  - research methods
  ---
  
  - I got this header for a nice looking report from Bull, G. (2011). Example Sweave Document. SharpStatistics.co.uk.
  - This has a bunch of useful parameters, but I just really like the header and footer on pages 2 onward
  - The original was a Sweave file.  I really like Sweave but orgmode allows other languages as well as R to be inter-woven into the script
  - An alternative to Sweave is knitr and is still on my todo list, but this works well at the moment
  - I also like how you can quickly change this to a Beamer presentation style.
  - Once this is in your file use C-c C-e d to export and compile the PDF
  - This example is available at [this link](/pdfs/SharpReportTemplate.pdf)
  
  #### Emacs orgmode Code: Put this into your .org file
      ,#+TITLE: Sharp Report Template
      ,#+AUTHOR: Ivan Hanigan
      ,#+email: ivan.hanigan@anu.edu.au
      ,#+LaTeX_CLASS: article
      ,#+LaTeX_CLASS_OPTIONS: [a4paper]
      ,#+LaTeX_HEADER: \usepackage{amssymb,amsmath}
      ,#+LaTeX_HEADER: \usepackage{fancyhdr} %For headers and footers
      ,#+LaTeX_HEADER: \pagestyle{fancy} %For headers and footers
      ,#+LaTeX_HEADER: \usepackage{lastpage} %For getting page x of y
      ,#+LaTeX_HEADER: \usepackage{float} %Allows the figures to be positioned and formatted nicely
      ,#+LaTeX_HEADER: \floatstyle{boxed} %using this
      ,#+LaTeX_HEADER: \restylefloat{figure} %and this command
      ,#+LaTeX_HEADER: \usepackage{url} %Formatting of yrls
      ,#+LaTeX_HEADER: \lhead{ivanhanigan.github.com}
      ,#+LaTeX_HEADER: \chead{}
      ,#+LaTeX_HEADER: \rhead{\today}
      ,#+LaTeX_HEADER: \lfoot{Draft}
      ,#+LaTeX_HEADER: \cfoot{}
      ,#+LaTeX_HEADER: \rfoot{\thepage\ of \pageref{LastPage}}
      ,#+LATEX: \tableofcontents
      
      ,* Introduction
      This is a sharp looking report template I got from an R blogger \cite{Bull2011}.
      
      The pages after the first page have a nice looking header, footer and page number.
      \clearpage
      
      ,* Section 1
      In the Org file you can see some hidden R code that computes a linear regression and returns the results shown in Table \ref{ATable}.
      \input{ATable.tex}
      \clearpage
      ,*** COMMENT some-code
      ,#+name:some-code
      ,#+begin_src R :session *R* :tangle no :exports none :eval yes
      #### name:some-code ####
      x<-rnorm(100,10,5)
      y<-rnorm(100,20,15)
      fit <- lm(y~x)
      library(xtable)
      sink("ATable.tex")
      xtable(fit, caption="Example Table",digits=4,table.placement="H",label="ATable")
      sink()
      ,#+end_src
      
      ,#+RESULTS: some-code
      
      
      
      ,* References
      \bibliographystyle{apalike}
      \bibliography{/home/ivan_hanigan/references/library}
      
      
  
#+end_src

** LaTeX templates
** COMMENT 2013-12-13-open-access-journal-templates-for-latex-with-emacs-orgmode
#+name:open-access-journal-templates-for-latex-with-emacs-orgmode-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-13-open-access-journal-templates-for-latex-with-emacs-orgmode.md :exports none :eval no :padline no
  ---
  name: 2013-12-13-open-access-journal-templates-for-latex-with-emacs-orgmode
  layout: post
  title: open-access-journal-templates-for-latex-with-emacs-orgmode
  date: 2013-12-13
  categories:
  - research methods
  ---
  
  - I appreciate all the arguments for using OA journals
  - Using a LaTeX template is also attractive
  - This post is a record of some experiences with the BioMedCentral (BMC) template and the Public Library of Science (PLOS) templates
  - implemented with my favourite editor for everything Emacs Orgmode.
  
  #### BMC seemed like a good option
  
  - I started this journey 6 months ago with the BMC template
  - because I pitch my work mostly at the health science community BMC seemed logical
  - It turns out I downloaded their old LaTeX template and it SUCKED
  - If you Download [the template and bibliography stuff](http://www.biomedcentral.com/authors/tex) now it looks better
  - But I am suspicious now because of the last little while I've been struggling so I've got a skeptical approach
  - First copy the stuff to a test dir
  - then use TexWorks to test compiling it
  - try deleting the provided BBL file, this reveales that the BIB file has to be compiled with bibtex to work
  - orgmode produces BBL files when evaluated but I don't know if it'll be smooth with the template
  
  #### PLOS seems like a smoother option
  
  - Download from [the LaTeX template site](http://www.plosone.org/static/latexGuidelines)
  - First thing I notice is there is no BIB file, Yay!
  - just make sure  bibliographystyle and bibliography are set
  - Looks like it isn't trying so hard
  
  
  
      
#+end_src

** COMMENT add toc to knitr
tangle to like JBB-overview.Rmd
#+name:JBB-overview-header
#+begin_src R :session shell :tangle no :exports none :eval no :padline no
Jervis Bay Booderee Database EDA
========================================================

- This is a Reproducible Report of the Exploratory Data Analysis (EDA).
- The source code is in the private bitbucket repository.
- This is just the critical R code for the data package stuff.

```{r echo=FALSE, eval=F, results='hide'}
require(knitr)
require(markdown)
knit2html('JBB-overview.Rmd', options = c('toc', markdown::markdownHTMLOptions(TRUE)))
```

``` {r echo=FALSE, results='hide'}
require(xtable)
require(disentangle)
require(rgdal)
require(sqldf)
```
#+end_src

** 2014-02-12-template-Reproducible-Research-with-R-TEX-and-Sweave
#+name:template-Reproducible-Research-with-R-TEX-and-Sweave-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-02-12-template-reproducible-research-with-r-tex-and-sweave.md :exports none :eval no :padline no
---
name: template-reproducible-research-with-r-tex-and-sweave
layout: post
title: Template Reproducible Research with R TEX and Sweave
date: 2014-02-12
categories:
- research methods
---

- Last year I wrote to a Professor to let them know some numbers that quantified their effect estimate (computed be exponentiating their beta coefficient) described in their results section was inconsistent with the numbers in their table (the raw coefficients).
- Happily the recalculation showed that they had underestimated the effect size and their conclusions were not wrong, but erroneously conservative.
- Previously I would use Sweave documents to keep track of all my calculations, but I was still copy-and-pasting the key numbers into the text.
- I've become more interested now in using Inline R Outputs (called Sexpr - S expressions)
- This is also the first time I've created a report using the Palatino font, on the advice of a new colleague of mine.
- I popped up a [Github repo with a Sweave template for Reproducible Reports with a few notes I made](https://github.com/ivanhanigan/DataDocumentation).  Which looks like

![/images/sexpr.png](/images/sexpr.png)

- The [PDF output is here](https://github.com/ivanhanigan/DataDocumentation/blob/master/src/sexpr.pdf)

- The [Sweave file is here](https://github.com/ivanhanigan/DataDocumentation/blob/master/src/sexpr.Rnw)

#+end_src

** 2014-05-17-reproducible-research-reports-using-emacs-orgmode-export-to-knitr
#+name:reproducible-research-reports-using-emacs-orgmode-export-to-knitr-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-05-17-reproducible-research-reports-using-emacs-orgmode-export-to-knitr.md :exports none :eval no :padline no
  ---
  name: reproducible-research-reports-using-emacs-orgmode-export-to-knitr
  layout: post
  title: reproducible-research-reports-using-emacs-orgmode-export-to-knitr
  date: 2014-05-17
  categories:
  - research methods
  ---
  
  - Emacs orgmode is so good for Reproducible Research Reports.  Check out the paper by Eric Schulte et al ["A Multi-Language Computing Environment for Literate Programming"](http://www.jstatsoft.org/v46/i03%E2%80%8E)
  - it provides a good export function to convert the code file into a html or latex report using C-c C-e h OR C-c C-e l respectively.
  - but I have found there are some limitations with these export reports compared to knitr
  - primarily the limitation of the need to include the images as seperate files whereas knitr encodes these explicitly in the report is the one I dislike the most
  - another limitation is the way that tables are handled
  - HOWEVER the code editing features of Emacs orgmode are so superior to the other options I have tried to write knitr documents in that I feel it is worth trying to find some middle ground.
  - I have been happy for a little while using a method of writing documents in Emacs orgmode and exporting the text and code Chunks to a knitr RMD file, and then compiling that file to create the report.
  - I have set up an example using the classic Challenger Space Shuttle logistic regression [in this file](https://bitbucket.org/ivanhanigan/eda-template/raw/3f8d20253bf6a2389ed720033edf171ca74ca796/emacs2knitr.org)
  
  ### The Output
  
  <body>
  <div id="toc">
  <div id="toc_header">Table of Contents</div>
  <ul>
  <li>
  <a href="#toc_0">Reproducible Research Report using Emacs orgmode to knitr</a>
  <ul>
  <li>
  <ul>
  <li>
  <a href="#toc_1">Introduction</a>
  </li>
  <li>
  <a href="#toc_2">logistic regression of the challenger disaster</a>
  <ul>
  <li>
  <a href="#toc_3">name:create-data</a>
  </li>
  <li>
  <a href="#toc_4">fit model</a>
  </li>
  </ul>
  </li>
  <li>
  <a href="#toc_5">Model Diagnostics</a>
  </li>
  <li>
  <a href="#toc_6">plot-model</a>
  </li>
  </ul>
  </li>
  </ul>
  </li>
  </ul>
  </div>
  
  
  <h1 id="toc_0">Reproducible Research Report using Emacs orgmode to knitr</h1>
  
  <p><a href="mailto:ivan.hanigan@anu.edu.au">ivan.hanigan@anu.edu.au</a></p>
  
  <h3 id="toc_1">Introduction</h3>
  
  <ul>
  <li>This is an example or a Reproducible Research Report.</li>
  <li>The report is the output of a program written in Emacs orgmode, which constructs a knitr document and creates this HTML output.</li>
  </ul>
  
  <h3 id="toc_2">logistic regression of the challenger disaster</h3>
  
  <p>The problem was with the failure rate (and number of) O-rings that failed (n.fail) related to the temperature (temp).</p>
  
  <h4 id="toc_3">name:create-data</h4>
  
  <pre><code class="r"># n.fail = failed o rings
  # totalMinusNfail = total-n.fail
  # total = there were 6 o rings for each of 23 attempts
  # pfail = probability of fail pFail &lt;- n.fail/total
  # temp = temperature (F)
  
  dat &lt;- read.csv(textConnection(
  &quot;nfail, totalMinusNfail, total,     pFail,       temp
  2,               4,     6,          0.3333333,   53
  0,               6,     6,          0.0000000,   66
  0,               6,     6,          0.0000000,   68
  1,               5,     6,          0.1666667,   70
  0,               6,     6,          0.0000000,   75
  0,               6,     6,          0.0000000,   78
  1,               5,     6,          0.1666667,   57
  0,               6,     6,          0.0000000,   67
  0,               6,     6,          0.0000000,   69
  1,               5,     6,          0.1666667,   70
  2,               4,     6,          0.3333333,   75
  0,               6,     6,          0.0000000,   79
  1,               5,     6,          0.1666667,   58
  0,               6,     6,          0.0000000,   67
  0,               6,     6,          0.0000000,   70
  0,               6,     6,          0.0000000,   72
  0,               6,     6,          0.0000000,   76
  0,               6,     6,          0.0000000,   81
  1,               5,     6,          0.1666667,   63
  0,               6,     6,          0.0000000,   67
  0,               6,     6,          0.0000000,   70
  0,               6,     6,          0.0000000,   73
  0,               6,     6,          0.0000000,   76
  &quot;))
  </code></pre>
  
  <!-- html table generated in R 3.1.0 by xtable 1.7-1 package -->
  
  <!-- Sat May 17 23:50:22 2014 -->
  
  <TABLE border=1>
  <TR> <TH> nfail </TH> <TH> totalMinusNfail </TH> <TH> total </TH> <TH> pFail </TH> <TH> temp </TH>  </TR>
    <TR> <TD align="right">   2 </TD> <TD align="right">   4 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.33 </TD> <TD align="right">  53 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  66 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  68 </TD> </TR>
    <TR> <TD align="right">   1 </TD> <TD align="right">   5 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.17 </TD> <TD align="right">  70 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  75 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  78 </TD> </TR>
    <TR> <TD align="right">   1 </TD> <TD align="right">   5 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.17 </TD> <TD align="right">  57 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  67 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  69 </TD> </TR>
    <TR> <TD align="right">   1 </TD> <TD align="right">   5 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.17 </TD> <TD align="right">  70 </TD> </TR>
    <TR> <TD align="right">   2 </TD> <TD align="right">   4 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.33 </TD> <TD align="right">  75 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  79 </TD> </TR>
    <TR> <TD align="right">   1 </TD> <TD align="right">   5 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.17 </TD> <TD align="right">  58 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  67 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  70 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  72 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  76 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  81 </TD> </TR>
    <TR> <TD align="right">   1 </TD> <TD align="right">   5 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.17 </TD> <TD align="right">  63 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  67 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  70 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  73 </TD> </TR>
    <TR> <TD align="right">   0 </TD> <TD align="right">   6 </TD> <TD align="right">   6 </TD> <TD align="right"> 0.00 </TD> <TD align="right">  76 </TD> </TR>
     </TABLE>
  
  <pre><code class="r">#### learnR-logistic
  png(&quot;pfail.png&quot;)
  with(dat, plot(temp, pFail, pch = 16, xlim = c(40, 100), ylim = c(0, 0.4)))
  title(&quot;A plot of the proportion failed by temperature&quot;)
  dev.off()
  </code></pre>
  
  <p>pdf 
    2 </p>
  
  <p><img src="data:image/png;base64,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" alt="pfail.png"/></p>
  
  <h4 id="toc_4">fit model</h4>
  
  <pre><code class="r"># newnode: linear names(dat)
  resp &lt;- cbind(dat$nfail, dat$totalMinusNfail)
  temp &lt;- dat$temp
  linear &lt;- glm(resp ~ 1 + temp, family = binomial(link = logit))
  # TODO this just prints the codes not the table?  xtable(linear, type =
  # &#39;html&#39;)
  </code></pre>
  
  <h3 id="toc_5">Model Diagnostics</h3>
  
  <pre><code class="r">cf &lt;- linearoutput$coeff
  signif(cf[which(row.names(cf) == &quot;temp&quot;), &quot;Estimate&quot;], 2)
  </code></pre>
  
  <p>[1] -0.12</p>
  
  <pre><code class="r">png(&quot;challengerLogistic.png&quot;)
  par(mfrow = c(2, 2))
  plot(linear)
  dev.off()
  </code></pre>
  
  <p>pdf 
    2 </p>
  
  <p><img src="data:image/png;base64,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" alt="challengerLogistic.png"/></p>
  
  <h3 id="toc_6">plot-model</h3>
  
  <pre><code class="r">dummy &lt;- data.frame(temp = seq(20, 100, 1))
  pred.prob &lt;- predict.glm(linear, newdata = dummy, type = &quot;resp&quot;)
  png(&quot;pfailfit.png&quot;)
  with(dat, plot(temp, pFail, xlab = &quot;Launch Temperature (F)&quot;, ylab = &quot;Proportion Failing&quot;, 
      pch = 16, xlim = c(20, 100), ylim = c(0, 1)))
  lines(dummy$temp, pred.prob)
  dev.off()
  </code></pre>
  
  <p>pdf 
    2 </p>
  
  <p><img src="data:image/png;base64,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" alt="pfailfit.png"/></p>
  
  </body>
  
  
  
#+end_src

* R Packages
* Project Management
** Gantt Charts
*** taskjuggler gantt-tj3-code
#+name:gantt-tj3
#+begin_src R :session *R* :tangle src/gantt-tj3.r :exports reports :eval no
  http://permalink.gmane.org/gmane.emacs.orgmode/52844
  d.tchin | 29 Feb 2012 20:11
  Re: taskjuggler3 export
  
  Hi, 
  
  I use the following testtj3.org file that I export to taskjuggler 3.0 :
  
  ,----------------------------------------------------------------------------
  |#+TITLE:     testtj3.org                                               
                    
  |#+PROPERTY: Effort_ALL 2d 5d 10d 20d 30d 35d 50d                             
  |                                                                             
  |* Action list                                          :taskjuggler_project:  
  |** TODO Test tj3 A                                                           
  |    :PROPERTIES:                                                            
  |    :Effort:   1w                                                            
  |    :allocate: toA                                      
  |    :END:                                                            
  |** TODO Test tj3 B                                                           
  |    :PROPERTIES:                                                             
  |    :Effort:   1w                                                            
  |    :allocate: toB                                                           
  |    :BLOCKER:  previous-sibling                                              
  |    :END:                                                                    
  |** TODO Test 2 tj3     
  |    :PROPERTIES:                                                             
  |    :Effort:   2w                                                            
  |    :allocate:  toA                                                          
  |    :BLOCKER:  previous-sibling                                
  |    :END:                                                                    
  |** TODO Test 2 tj3 B                                                        
  |    :PROPERTIES:                                                             
  |    :Effort:   2w                                                           
  |    :allocate: toB 
  |    :BLOCKER: previous-sibling                                               
  |    :END:                                                                    
  |* Ressources                                          :taskjuggler_resource: 
  |** A                                                                         
  |    :PROPERTIES:                                                             
  |    :resource_id: toA                                                        
  |    :END:                                                               
  |** B                                                                         
  |    :PROPERTIES:                                       
  |    :resource_id: toB                                   
  |    :END:                                       
  |                                                                             
  |# Local Variables:                                                           
  |# org-export-taskjuggler-target-version: 3.0   
  |# org-export-taskjuggler-default-reports: ("include \"gantexport.tji\"")      
  |# End:                                                                    
  `----------------------------------------------------------------------------
  
  As you can see, I define in the org-export-taskjuggler-default-reports 
  variable at the end of the file that I want to use gantexport.tji where the 
  gant output directives are defined. This file is in the same directory as org 
  file.
  
  The gantexport.tji is the following :
  
  ,-----------------------------------------------------------------------------
  |### begin report definition                                                   
  |                                                                              
  |taskreport "Gantt Chart" {                                                    
  |  headline "Project Gantt Chart"                                              
  |  columns hierarchindex, name, start, end, effort, duration, completed, 
  chart  
  |  timeformat "%Y-%m-%d"       
  |  hideresource 1                                                              
  |  formats html                                                                
  |  loadunit shortauto                                                          
  |}                                                                            
  `-----------------------------------------------------------------------------
  
  Then the instruction tj3 testtj3.tjp generate the gant chart accessible 
  in "Gantt Chart.html" file.
  
  Hope that can help.
  
  
#+end_src

*** 2013-12-01-gantt-charts-for-health-professionals
#+name:gantt-charts-for-health-professionals-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-01-gantt-charts-for-health-professionals.md :exports none :eval no :padline no
  ---
  name: 2013-12-01-gantt-charts-for-health-professionals
  layout: post
  title: Gantt Charts For Health Professionals
  date: 2013-12-01
  categories:
  - research methods
  ---
  
  - Gantt Charts are a method used in Project Management to visualise the task list and progress with a calendar.
  - The title of this post comes from [Dr Tomas Aragon's paper 'Project Management for Health Professionals'](http://berkeley.academia.edu/TomasAragon/Teaching/31679/Project_Management_for_Health_Professionals)
  - There is also an accompanying [Tutorial](http://medepi.com/2012/02/05/project-mgmt/)
  - Dr Aragon also has a couple of suggestions for software to use for creating Gantt Charts [on this page](http://medepi.com/2011/11/29/software-recs/)
  - I haven't used those but here are some I have used
  
  #### Gantter
  
  - This is an online tool, that can integrate with Google Drive [http://www.gantter.com/](http://www.gantter.com/)
  - It also imports MS Project files
  
  #### Taskjuggler
  
  - Emacs orgmode can be used with a Ruby package called Taskjuggler (tj3)
  - The command C-c C-e j will export a file such as this description ready for conversion [http://orgmode.org/worg/org-tutorials/org-taskjuggler.html](http://orgmode.org/worg/org-tutorials/org-taskjuggler.html)
  - I also needed to include this suggested by d.tchin 29 Feb 2012,  [http://permalink.gmane.org/gmane.emacs.orgmode/52844](http://permalink.gmane.org/gmane.emacs.orgmode/52844)
  - an example I use for a template is in my [disentangle Github repo](https://raw.github.com/ivanhanigan/disentangle/gh-pages/gantt-tj3/gantt-tj3.org)
  - which produces [this output](http://ivanhanigan.github.io/disentangle/gantt-tj3/Gantt%20Chart.html)
  
  ![gantt-tj3.png](/images/gantt-tj3.png)
  
      
#+end_src

** 2013-12-02-research-protocol-we-used-for-our-bushfire-project
#+name:research-protocol-we-used-for-our-bushfire-project-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-02-research-protocol-we-used-for-our-bushfire-project.md :exports none :eval no :padline no
  ---
  name: 2013-12-02-research-protocol-we-used-for-our-bushfire-project
  layout: post
  title: research-protocol-we-used-for-our-bushfire-project
  date: 2013-12-02
  categories:
  - research methods
  ---

  - For a three year project on Bushfire smoke and Health we used the following structure in a wiki
  
  #### Sections:
      A.Background        
      B.Proposals         
      C.Approvals         
      D.Budget    
      E.Datasets  
      F.Analysis  
      G.Literature        
      H.Communication     
      I.Correspondance    
      J.Meetings  
      K.Completion        
      ContactDetails      
      README
      TODO        
  
  #### Conclusion
  - it worked quite well in the first year.
  - we didn't use it much after that.
  - it is still on the ANU webserver.  I sometimes refer back to it now, a couple of years later.

    
#+end_src

** 2013-12-02-research-protocol-for-manitoba-centre-for-health-policy-raw-U-Manitoba Centre for Health Policy Guidelines
These guidelines come from:

\noindent http://umanitoba.ca/faculties/medicine/units/mchp/protocol/media/manage_guidelines.pdf\\

Most of the material below is taken verbatim from the original. Unfortunately many of the items described below have links to internal MCHP documents that we cannot access.  Nonetheless the structure of the guidelines provides a useful skeleton to frame our thinking. 

The following areas should be reviewed with project team members near the beginning of the study and throughout the
project as needed:
- Confidentiality
- Project team
- File organization and documentation development
- Communication
- Administrative
- Report Preparation
- Project Completion
*** Confidentiality
Maintaining data access
*** Project Team Makeup
Roles and contact information should be documented on the project website for the following, where applicable (information may also be included on level of access approved for each team member).

**** Principal Investigator 
This is the lead person on the project, who assumes responsibility for delivering the project. The PI makes decisions on project direction and analysis requirements, with input from programmers and the research coordinator (an iterative process). If there is more than one PI (e.g., multi-site studies), overall responsibility for the study needs to be determined, and how the required work will be allocated and coordinated among the co-investigators. Researcher Workgroup website (internal link) 

**** Research Coordinator
Th RC is always assigned to deliverables and is usually brought in on other types of projects involving multiple sites, investigators and/or programmers. Responsibilities include project documentation, project management (e.g., ensuring that timelines are met, ensuring that project specifications are being followed), and working with both investigator(s) and the Programmer Coordinator throughout the project to coordinate project requirements. 

**** The Programmer Coordinator 
The PC is a central management role who facilitates assignment of programming resources to projects, ensuring the best possible match among programmers and investigators.
Research Coordinator Workgroup website(internal link) 

**** Programmer Analyst
This is primarily responsible for programming and related programming documentation (such that the purpose of the program and how results were derived can be understood by others). However, a major role may be taken in the analyses of the project as well, and this will characteristically vary with the project.
Programmer Analyst Workgroup website(internal link) 

**** Research Support
This is primarily responsible for preparing the final product (i.e., the report), including editing and formatting of final graphs and manuscript and using Reference Manager to set up the references. Research support also normally sets up and attends working group meetings. All requests for research support go through the Office Manager.

*** Project Team considerations
**** Roles
It is important to clarify everyone's roles at the beginning of the project; for example, whether the investigator routinely expects basic graphs and/or programming logs from the programmer.

**** Continuity
It is highly desirable to keep the same personnel, from the start of the project, where possible. It can take some time to develop a cohesive working relationship, particularly if work styles are not initially compatible. Furthermore, requesting others to temporarily fill in for team absences is generally best avoided, particularly for programming tasks (unless there is an extended period of absence). The original programmer will know best the potential impact of any changes that may need to be made to programming code.

**** Access levels
Access to MCHP internal resources (e.g., Windows, Unix) need to be assessed for all team members and set up as appropriate to their roles on the project.

**** Working group
A WG is always set up for deliverables (and frequently for other projects):
Terms of Reference for working group (internal)

**** Atmospherics
*** File organization and Documentation Development.
All project-related documentation, including key e-mails used to update project methodology, should be saved within the project directory. Resources for directory setup and file development include:
**** Managing MCHP resources
This includes various process documents as well as an overview of the documentation process for incorporating research carried out by MCHP into online resources: Documentation Management Guide (internal)
**** MCHP directory structure
A detailed outline of how the Windows environment is structured at MCHP
**** Managing project files
How files and sub-directories should be organized and named as per the MCHP Guide to Managing Project Files (internal pdf). Information that may be suitable for incorporating into MCHP online resources should be identified; for example, a Concept Development section for subsequent integration of a new concept(s) into the MCHP
Concept Dictionary. The deliverable glossary is another resource typically integrated into the MCHP Glossary.
**** Recommended Directories
NOTE this is a diversion from the MCHP guidelines.  These recommended directories are from a combination of sources that we have synthesised.
***** Background: concise summaries: possibly many documents for main project and any main analyses based on the 1:3:25 paradigm: one page of main messages; a three-page executive summary; 25 pages of detailed findings.
*****  Proposals: for documents related to grant applications.
*****  Approvals: for ethics applications.
*****  Budget: spreadsheets and so-forth.
*****  Data
******  dataset1
******  dataset2
*****  Paper1
******  Data
*******  merged dataset1 and 2
******  Analysis (also see http://projecttemplate.net for a programmer oriented template)
*******  exploratory analyses
*******  data cleaning
*******  main analysis
*******  sensitivity analysis
*******  data checking
*******  model checking
*******  internal review
******  Document
*******  Draft
*******  Journal1
********  rejected? :-(
*******  Journal2
********  Response to reviews
******  Versions: folders named by date - dump entire copies of the project at certain milestones/change points
******  Archiving final data with final published paper
*****  Papers 2, 3, etc: same structure as paper 1 hopefully the project spawns several papers 
*****  Communication: details of communication with stakeholders and decision makers
*****  Meetings: for organisation and records of meetings
*****  Contact details. table contacts lists
*****  Completion: checklists to make sure project completion is systematic.  Factor in a critical reflection of lessons learnt.
*****  References
*** Communication
Project communication should be in written form, wherever possible, to serve as reference for project documentation. Access and confidentiality clearance levels for all involved in the project will determine whether separate communication plans need to be considered for confidential information.
**** E-mail
provides opportunities for feedback/ discussion from everyone and for documenting key project decisions. Responses on any given issue would normally be copied to every project member, with the expectation of receiving feedback within a reasonable period of time - e.g.,a few days). The Research Coordinator should be copied on ALL project correspondence in order to keep the information up to date on the project website.
***** E-mail etiquette (internal) 
**** Meetings
Regularly-scheduled meetings or conference calls should include all project members where possible. Research Coordinators typically arrange project team meetings and take meeting minutes, while Research Support typically arranges the Working Group meetings.
***** Tips for taking notes (internal)
***** Outlook calendar
Used for booking rooms, it displays information on room availability and may include schedules of team members.
*** Administrative
**** Time entry 
Time spent on projects should be entered by all MCHP employees who are members of the project team.
***** website for time entry (internal) 
***** procedures for time entry (internal)

*** Report preparation
This includes:
- Policies - e.g., Dissemination of Research Findings
- Standards - e.g., deliverable production, use of logos, web publishing
- Guidelines - e.g., producing PDFs, powerpoint, and Reference Manager files
- Other resources - e.g., e-mail etiquette, technical resources, photos.

**** Reliability and Validity Checks
Making sure the numbers "make sense". Carrying out these checks requires spelling out who will do which checks.
***** Data Validity Checks 
A variety of things to check for at various stages of the study. Programming can be reviewed, for example, by checking to ensure all programs have used the right exclusions, the correct definitions, etc. , and output has been accurately transferred to graphs, tables, and maps for the report.
***** Discrepancies between data sources
In this case it is MCHP and Manitoba Health Reports - an example of cross-checking against another source of data.
*** Project Completion
Several steps need to take place to "finish" the project:
**** Final Project Meeting. 
Wind-up or debriefing meetings are held shortly after public release of a deliverable. Such meetings provide all team members with an opportunity to communicate what worked/did not work in bringing the project to completion, providing lessons learned for future deliverables.
**** Final Documentation Review. 
Findings from the wind-up meeting should be used to update and finalize the project website (including entering the date of release of report/paper). Both Windows and Unix project directories should be reviewed to ensure that only those SAS programs relevant to project analyses are kept (and well-documented) for future reference. Any related files which may be stored in a user directory should be moved to the project directory.
**** System Cleanup. 
When the project is complete, the Systems Administrator should be informed. Project directories, including program files and output data sets, will be archived to tape or CD. Tape backups are retained for a 5-year period before being destroyed so any project may be restored up to five years after completion.
**** Integration of new material to institution repository
This is with MCHP resource repository - a general overview of this process is described in General Documentation Process {internal}.
** 2013-12-02-research-protocol-for-manitoba-centre-for-health-policy
#+name:research-protocol-for-manitoba-centre-for-health-policy-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-12-02-research-protocol-for-manitoba-centre-for-health-policy.md :exports none :eval no :padline no
  ---
  name: 2013-12-02-research-protocol-for-manitoba-centre-for-health-policy
  layout: post
  title: research-protocol-for-manitoba-centre-for-health-policy
  date: 2013-12-02
  categories:
  - research methods
  ---
  
  - When we started planning for a three year project on bushfire smoke we did some planning
  - We had a deep discussion about this research management protocol from [University Manitoba Centre for Health Policy](http://umanitoba.ca/faculties/medicine/units/community_health_sciences/departmental_units/mchp/protocol/media/manage_guidelines.pdf)

  
  <div id="content">
  <h1 class="title">Data Management Plan Checklist</h1>
  
  
  <div id="table-of-contents">
  <h2>Table of Contents</h2>
  <div id="text-table-of-contents">
  <ul>
  <li><a href="#sec-1">1 U-Manitoba Centre for Health Policy Guidelines</a>
  <ul>
  <li><a href="#sec-1-1">1.1 Confidentiality</a></li>
  <li><a href="#sec-1-2">1.2 Project Team Makeup</a>
  <ul>
  <li><a href="#sec-1-2-1">1.2.1 Principal Investigator</a></li>
  <li><a href="#sec-1-2-2">1.2.2 Research Coordinator</a></li>
  <li><a href="#sec-1-2-3">1.2.3 The Programmer Coordinator</a></li>
  <li><a href="#sec-1-2-4">1.2.4 Programmer Analyst</a></li>
  <li><a href="#sec-1-2-5">1.2.5 Research Support</a></li>
  </ul>
  </li>
  <li><a href="#sec-1-3">1.3 Project Team considerations</a>
  <ul>
  <li><a href="#sec-1-3-1">1.3.1 Roles</a></li>
  <li><a href="#sec-1-3-2">1.3.2 Continuity</a></li>
  <li><a href="#sec-1-3-3">1.3.3 Access levels</a></li>
  <li><a href="#sec-1-3-4">1.3.4 Working group</a></li>
  <li><a href="#sec-1-3-5">1.3.5 Atmospherics</a></li>
  </ul>
  </li>
  <li><a href="#sec-1-4">1.4 File organization and Documentation Development.</a>
  <ul>
  <li><a href="#sec-1-4-1">1.4.1 Managing MCHP resources</a></li>
  <li><a href="#sec-1-4-2">1.4.2 MCHP directory structure</a></li>
  <li><a href="#sec-1-4-3">1.4.3 Managing project files</a></li>
  <li><a href="#sec-1-4-4">1.4.4 Recommended Directories</a></li>
  </ul>
  </li>
  <li><a href="#sec-1-5">1.5 Communication</a>
  <ul>
  <li><a href="#sec-1-5-1">1.5.1 E-mail</a></li>
  <li><a href="#sec-1-5-2">1.5.2 Meetings</a></li>
  </ul>
  </li>
  <li><a href="#sec-1-6">1.6 Administrative</a>
  <ul>
  <li><a href="#sec-1-6-1">1.6.1 Time entry</a></li>
  </ul>
  </li>
  <li><a href="#sec-1-7">1.7 Report preparation</a>
  <ul>
  <li><a href="#sec-1-7-1">1.7.1 Reliability and Validity Checks</a></li>
  </ul>
  </li>
  <li><a href="#sec-1-8">1.8 Project Completion</a>
  <ul>
  <li><a href="#sec-1-8-1">1.8.1 Final Project Meeting.</a></li>
  <li><a href="#sec-1-8-2">1.8.2 Final Documentation Review.</a></li>
  <li><a href="#sec-1-8-3">1.8.3 System Cleanup.</a></li>
  <li><a href="#sec-1-8-4">1.8.4 Integration of new material to institution repository</a></li>
  </ul>
  </li>
  </ul>
  </li>
  </ul>
  </div>
  </div>
  
  <div id="outline-container-1" class="outline-2">
  <h2 id="sec-1"><span class="section-number-2">1</span> U-Manitoba Centre for Health Policy Guidelines</h2>
  <div class="outline-text-2" id="text-1">
  
  <p>These guidelines come from:
  </p>
  <p>
  \noindent <a href="http://umanitoba.ca/faculties/medicine/units/mchp/protocol/media/manage_guidelines.pdf">http://umanitoba.ca/faculties/medicine/units/mchp/protocol/media/manage_guidelines.pdf</a><br/>
  </p>
  <p>
  Most of the material below is taken verbatim from the original. Unfortunately many of the items described below have links to internal MCHP documents that we cannot access.  Nonetheless the structure of the guidelines provides a useful skeleton to frame our thinking. 
  </p>
  <p>
  The following areas should be reviewed with project team members near the beginning of the study and throughout the
  project as needed:
  </p><ul>
  <li>Confidentiality
  </li>
  <li>Project team
  </li>
  <li>File organization and documentation development
  </li>
  <li>Communication
  </li>
  <li>Administrative
  </li>
  <li>Report Preparation
  </li>
  <li>Project Completion
  </li>
  </ul>
  
  
  </div>
  
  <div id="outline-container-1-1" class="outline-3">
  <h3 id="sec-1-1"><span class="section-number-3">1.1</span> Confidentiality</h3>
  <div class="outline-text-3" id="text-1-1">
  
  <p>Maintaining data access
  </p></div>
  
  </div>
  
  <div id="outline-container-1-2" class="outline-3">
  <h3 id="sec-1-2"><span class="section-number-3">1.2</span> Project Team Makeup</h3>
  <div class="outline-text-3" id="text-1-2">
  
  <p>Roles and contact information should be documented on the project website for the following, where applicable (information may also be included on level of access approved for each team member).
  </p>
  
  </div>
  
  <div id="outline-container-1-2-1" class="outline-4">
  <h4 id="sec-1-2-1"><span class="section-number-4">1.2.1</span> Principal Investigator</h4>
  <div class="outline-text-4" id="text-1-2-1">
  
  <p>This is the lead person on the project, who assumes responsibility for delivering the project. The PI makes decisions on project direction and analysis requirements, with input from programmers and the research coordinator (an iterative process). If there is more than one PI (e.g., multi-site studies), overall responsibility for the study needs to be determined, and how the required work will be allocated and coordinated among the co-investigators. Researcher Workgroup website (internal link) 
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-2-2" class="outline-4">
  <h4 id="sec-1-2-2"><span class="section-number-4">1.2.2</span> Research Coordinator</h4>
  <div class="outline-text-4" id="text-1-2-2">
  
  <p>Th RC is always assigned to deliverables and is usually brought in on other types of projects involving multiple sites, investigators and/or programmers. Responsibilities include project documentation, project management (e.g., ensuring that timelines are met, ensuring that project specifications are being followed), and working with both investigator(s) and the Programmer Coordinator throughout the project to coordinate project requirements. 
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-2-3" class="outline-4">
  <h4 id="sec-1-2-3"><span class="section-number-4">1.2.3</span> The Programmer Coordinator</h4>
  <div class="outline-text-4" id="text-1-2-3">
  
  <p>The PC is a central management role who facilitates assignment of programming resources to projects, ensuring the best possible match among programmers and investigators.
  Research Coordinator Workgroup website(internal link) 
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-2-4" class="outline-4">
  <h4 id="sec-1-2-4"><span class="section-number-4">1.2.4</span> Programmer Analyst</h4>
  <div class="outline-text-4" id="text-1-2-4">
  
  <p>This is primarily responsible for programming and related programming documentation (such that the purpose of the program and how results were derived can be understood by others). However, a major role may be taken in the analyses of the project as well, and this will characteristically vary with the project.
  Programmer Analyst Workgroup website(internal link) 
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-2-5" class="outline-4">
  <h4 id="sec-1-2-5"><span class="section-number-4">1.2.5</span> Research Support</h4>
  <div class="outline-text-4" id="text-1-2-5">
  
  <p>This is primarily responsible for preparing the final product (i.e., the report), including editing and formatting of final graphs and manuscript and using Reference Manager to set up the references. Research support also normally sets up and attends working group meetings. All requests for research support go through the Office Manager.
  </p>
  </div>
  </div>
  
  </div>
  
  <div id="outline-container-1-3" class="outline-3">
  <h3 id="sec-1-3"><span class="section-number-3">1.3</span> Project Team considerations</h3>
  <div class="outline-text-3" id="text-1-3">
  
  
  </div>
  
  <div id="outline-container-1-3-1" class="outline-4">
  <h4 id="sec-1-3-1"><span class="section-number-4">1.3.1</span> Roles</h4>
  <div class="outline-text-4" id="text-1-3-1">
  
  <p>It is important to clarify everyone's roles at the beginning of the project; for example, whether the investigator routinely expects basic graphs and/or programming logs from the programmer.
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-3-2" class="outline-4">
  <h4 id="sec-1-3-2"><span class="section-number-4">1.3.2</span> Continuity</h4>
  <div class="outline-text-4" id="text-1-3-2">
  
  <p>It is highly desirable to keep the same personnel, from the start of the project, where possible. It can take some time to develop a cohesive working relationship, particularly if work styles are not initially compatible. Furthermore, requesting others to temporarily fill in for team absences is generally best avoided, particularly for programming tasks (unless there is an extended period of absence). The original programmer will know best the potential impact of any changes that may need to be made to programming code.
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-3-3" class="outline-4">
  <h4 id="sec-1-3-3"><span class="section-number-4">1.3.3</span> Access levels</h4>
  <div class="outline-text-4" id="text-1-3-3">
  
  <p>Access to MCHP internal resources (e.g., Windows, Unix) need to be assessed for all team members and set up as appropriate to their roles on the project.
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-3-4" class="outline-4">
  <h4 id="sec-1-3-4"><span class="section-number-4">1.3.4</span> Working group</h4>
  <div class="outline-text-4" id="text-1-3-4">
  
  <p>A WG is always set up for deliverables (and frequently for other projects):
  Terms of Reference for working group (internal)
  </p>
  </div>
  
  </div>
  
  <div id="outline-container-1-3-5" class="outline-4">
  <h4 id="sec-1-3-5"><span class="section-number-4">1.3.5</span> Atmospherics</h4>
  <div class="outline-text-4" id="text-1-3-5">
  
  </div>
  </div>
  
  </div>
  
  <div id="outline-container-1-4" class="outline-3">
  <h3 id="sec-1-4"><span class="section-number-3">1.4</span> File organization and Documentation Development.</h3>
  <div class="outline-text-3" id="text-1-4">
  
  <p>All project-related documentation, including key e-mails used to update project methodology, should be saved within the project directory. Resources for directory setup and file development include:
  </p>
  </div>
  
  <div id="outline-container-1-4-1" class="outline-4">
  <h4 id="sec-1-4-1"><span class="section-number-4">1.4.1</span> Managing MCHP resources</h4>
  <div class="outline-text-4" id="text-1-4-1">
  
  <p>This includes various process documents as well as an overview of the documentation process for incorporating research carried out by MCHP into online resources: Documentation Management Guide (internal)
  </p></div>
  
  </div>
  
  <div id="outline-container-1-4-2" class="outline-4">
  <h4 id="sec-1-4-2"><span class="section-number-4">1.4.2</span> MCHP directory structure</h4>
  <div class="outline-text-4" id="text-1-4-2">
  
  <p>A detailed outline of how the Windows environment is structured at MCHP
  </p></div>
  
  </div>
  
  <div id="outline-container-1-4-3" class="outline-4">
  <h4 id="sec-1-4-3"><span class="section-number-4">1.4.3</span> Managing project files</h4>
  <div class="outline-text-4" id="text-1-4-3">
  
  <p>How files and sub-directories should be organized and named as per the MCHP Guide to Managing Project Files (internal pdf). Information that may be suitable for incorporating into MCHP online resources should be identified; for example, a Concept Development section for subsequent integration of a new concept(s) into the MCHP
  Concept Dictionary. The deliverable glossary is another resource typically integrated into the MCHP Glossary.
  </p></div>
  
  </div>
  
  <div id="outline-container-1-4-4" class="outline-4">
  <h4 id="sec-1-4-4"><span class="section-number-4">1.4.4</span> Recommended Directories</h4>
  <div class="outline-text-4" id="text-1-4-4">
  
  <p>NOTE this is a diversion from the MCHP guidelines.  These recommended directories are from a combination of sources that we have synthesised.
  </p><ul>
  <li id="sec-1-4-4-1">Background: concise summaries: possibly many documents for main project and any main analyses based on the 1:3:25 paradigm: one page of main messages; a three-page executive summary; 25 pages of detailed findings.<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-2">Proposals: for documents related to grant applications.<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-3">Approvals: for ethics applications.<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-4">Budget: spreadsheets and so-forth.<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-5">Data<br/>
  <ul>
  <li id="sec-1-4-4-5-1">dataset1<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-5-2">dataset2<br/>
  </li>
  </ul>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6">Paper1<br/>
  <ul>
  <li id="sec-1-4-4-6-1">Data<br/>
  <ul>
  <li id="sec-1-4-4-6-1-1">merged dataset1 and 2<br/>
  </li>
  </ul>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2">Analysis (also see <a href="http://projecttemplate.net">http://projecttemplate.net</a> for a programmer oriented template)<br/>
  <ul>
  <li id="sec-1-4-4-6-2-1">exploratory analyses<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2-2">data cleaning<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2-3">main analysis<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2-4">sensitivity analysis<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2-5">data checking<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2-6">model checking<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-2-7">internal review<br/>
  </li>
  </ul>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-3">Document<br/>
  <ul>
  <li id="sec-1-4-4-6-3-1">Draft<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-3-2">Journal1<br/>
  <ul>
  <li id="sec-1-4-4-6-3-2-1">rejected? :-(<br/>
  </li>
  </ul>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-3-3">Journal2<br/>
  <ul>
  <li id="sec-1-4-4-6-3-3-1">Response to reviews<br/>
  </li>
  </ul>
  </li>
  </ul>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-4">Versions: folders named by date - dump entire copies of the project at certain milestones/change points<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-6-5">Archiving final data with final published paper<br/>
  </li>
  </ul>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-7">Papers 2, 3, etc: same structure as paper 1 hopefully the project spawns several papers<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-8">Communication: details of communication with stakeholders and decision makers<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-9">Meetings: for organisation and records of meetings<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-10">Contact details. table contacts lists<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-11">Completion: checklists to make sure project completion is systematic.  Factor in a critical reflection of lessons learnt.<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-4-4-12">References<br/>
  </li>
  </ul>
  </div>
  </div>
  
  </div>
  
  <div id="outline-container-1-5" class="outline-3">
  <h3 id="sec-1-5"><span class="section-number-3">1.5</span> Communication</h3>
  <div class="outline-text-3" id="text-1-5">
  
  <p>Project communication should be in written form, wherever possible, to serve as reference for project documentation. Access and confidentiality clearance levels for all involved in the project will determine whether separate communication plans need to be considered for confidential information.
  </p>
  </div>
  
  <div id="outline-container-1-5-1" class="outline-4">
  <h4 id="sec-1-5-1"><span class="section-number-4">1.5.1</span> E-mail</h4>
  <div class="outline-text-4" id="text-1-5-1">
  
  <p>provides opportunities for feedback/ discussion from everyone and for documenting key project decisions. Responses on any given issue would normally be copied to every project member, with the expectation of receiving feedback within a reasonable period of time - e.g.,a few days). The Research Coordinator should be copied on ALL project correspondence in order to keep the information up to date on the project website.
  </p><ul>
  <li id="sec-1-5-1-1">E-mail etiquette (internal)<br/>
  </li>
  </ul>
  </div>
  
  </div>
  
  <div id="outline-container-1-5-2" class="outline-4">
  <h4 id="sec-1-5-2"><span class="section-number-4">1.5.2</span> Meetings</h4>
  <div class="outline-text-4" id="text-1-5-2">
  
  <p>Regularly-scheduled meetings or conference calls should include all project members where possible. Research Coordinators typically arrange project team meetings and take meeting minutes, while Research Support typically arranges the Working Group meetings.
  </p><ul>
  <li id="sec-1-5-2-1">Tips for taking notes (internal)<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-5-2-2">Outlook calendar<br/>
  Used for booking rooms, it displays information on room availability and may include schedules of team members.
  </li>
  </ul>
  </div>
  </div>
  
  </div>
  
  <div id="outline-container-1-6" class="outline-3">
  <h3 id="sec-1-6"><span class="section-number-3">1.6</span> Administrative</h3>
  <div class="outline-text-3" id="text-1-6">
  
  
  </div>
  
  <div id="outline-container-1-6-1" class="outline-4">
  <h4 id="sec-1-6-1"><span class="section-number-4">1.6.1</span> Time entry</h4>
  <div class="outline-text-4" id="text-1-6-1">
  
  <p>Time spent on projects should be entered by all MCHP employees who are members of the project team.
  </p><ul>
  <li id="sec-1-6-1-1">website for time entry (internal)<br/>
  </li>
  </ul>
  <ul>
  <li id="sec-1-6-1-2">procedures for time entry (internal)<br/>
  
  </li>
  </ul>
  </div>
  </div>
  
  </div>
  
  <div id="outline-container-1-7" class="outline-3">
  <h3 id="sec-1-7"><span class="section-number-3">1.7</span> Report preparation</h3>
  <div class="outline-text-3" id="text-1-7">
  
  <p>This includes:
  </p><ul>
  <li>Policies - e.g., Dissemination of Research Findings
  </li>
  <li>Standards - e.g., deliverable production, use of logos, web publishing
  </li>
  <li>Guidelines - e.g., producing PDFs, powerpoint, and Reference Manager files
  </li>
  <li>Other resources - e.g., e-mail etiquette, technical resources, photos.
  </li>
  </ul>
  
  
  
  </div>
  
  <div id="outline-container-1-7-1" class="outline-4">
  <h4 id="sec-1-7-1"><span class="section-number-4">1.7.1</span> Reliability and Validity Checks</h4>
  <div class="outline-text-4" id="text-1-7-1">
  
  <p>Making sure the numbers "make sense". Carrying out these checks requires spelling out who will do which checks.
  </p><ul>
  <li id="sec-1-7-1-1">Data Validity Checks<br/>
  A variety of things to check for at various stages of the study. Programming can be reviewed, for example, by checking to ensure all programs have used the right exclusions, the correct definitions, etc. , and output has been accurately transferred to graphs, tables, and maps for the report.
  </li>
  </ul>
  <ul>
  <li id="sec-1-7-1-2">Discrepancies between data sources<br/>
  In this case it is MCHP and Manitoba Health Reports - an example of cross-checking against another source of data.
  </li>
  </ul>
  </div>
  </div>
  
  </div>
  
  <div id="outline-container-1-8" class="outline-3">
  <h3 id="sec-1-8"><span class="section-number-3">1.8</span> Project Completion</h3>
  <div class="outline-text-3" id="text-1-8">
  
  <p>Several steps need to take place to "finish" the project:
  </p>
  </div>
  
  <div id="outline-container-1-8-1" class="outline-4">
  <h4 id="sec-1-8-1"><span class="section-number-4">1.8.1</span> Final Project Meeting.</h4>
  <div class="outline-text-4" id="text-1-8-1">
  
  <p>Wind-up or debriefing meetings are held shortly after public release of a deliverable. Such meetings provide all team members with an opportunity to communicate what worked/did not work in bringing the project to completion, providing lessons learned for future deliverables.
  </p></div>
  
  </div>
  
  <div id="outline-container-1-8-2" class="outline-4">
  <h4 id="sec-1-8-2"><span class="section-number-4">1.8.2</span> Final Documentation Review.</h4>
  <div class="outline-text-4" id="text-1-8-2">
  
  <p>Findings from the wind-up meeting should be used to update and finalize the project website (including entering the date of release of report/paper). Both Windows and Unix project directories should be reviewed to ensure that only those SAS programs relevant to project analyses are kept (and well-documented) for future reference. Any related files which may be stored in a user directory should be moved to the project directory.
  </p></div>
  
  </div>
  
  <div id="outline-container-1-8-3" class="outline-4">
  <h4 id="sec-1-8-3"><span class="section-number-4">1.8.3</span> System Cleanup.</h4>
  <div class="outline-text-4" id="text-1-8-3">
  
  <p>When the project is complete, the Systems Administrator should be informed. Project directories, including program files and output data sets, will be archived to tape or CD. Tape backups are retained for a 5-year period before being destroyed so any project may be restored up to five years after completion.
  </p></div>
  
  </div>
  
  <div id="outline-container-1-8-4" class="outline-4">
  <h4 id="sec-1-8-4"><span class="section-number-4">1.8.4</span> Integration of new material to institution repository</h4>
  <div class="outline-text-4" id="text-1-8-4">
  
  <p>This is with MCHP resource repository - a general overview of this process is described in General Documentation Process {internal}.
  </p></div>
  </div>
  </div>
  </div>
  </div>
  
  </body>
      
#+end_src

** 2014-02-22-gantting-like-a-hacker
#+name:gantting-like-a-hacker-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-02-22-gantting-like-a-hacker.md :exports none :eval no :padline no
  ---
  name: gantting-like-a-hacker
  layout: post
  title: gantting-like-a-hacker
  date: 2014-02-22
  categories:
  - research methods
  ---
  
  ### Background
  - ["Blogging like a Hacker"](http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html) has become a paradigm for programmers who want to link their code to their blogs.
  - I've followed this paradigm for a while to support my scientific projects, enhancing their transparency and reproducibility.
  - I've started a new project where I need to also manage project management and planning (following [Tomas Aragon's tutorial](http://medepi.com/2012/02/05/project-mgmt/))
  - I propose that the same methods I use in scientific programming and blogging like a hacker can be used in "Gantting like a Hacker"  
  - The title for this post is also influenced by the poste over at [Geek | Manager](http://blog.geekmanager.co.uk/2007/05/02/using-the-best-plan-format/).
  - That post says taht "Premature Gannting" is the act of making a "huge Gantt chart (often in MS Project)."
  - Gannting like a Hacker is doing this in a scripted environment, without relying on closed-source proprietry software such as the Windoze options.  
  - The community of bloggers (mostly geeks) who are following a style of blogging that originated with the invention of Jekyll, [unveiled in this post by Tom Preston-Werner](http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html); GitHub’s co-founder (aka mojombo).
  - This experiment uses Taskjuggler and Emacs Orgmode
  
  ### Materials and Methods
  
  - Use Ubuntu 12.04 Long Term Support (LTS)
  - with Ruby 
  
  #### Code:install task juggler
      gem install taskjuggler
  
  <p></p>
  
  ### Gantt charts with Emacs Orgmode
  
  - I'm using an Emacs tool to use TaskJuggler to handle the task scheduling and creation of Gantt chart suitable for [a Pointy-haired Boss](http://orgmode.org/worg/org-tutorials/org-taskjuggler.html). 
  - I hated using the Orgmode script to compile the parts of the Gantt chart so I wrote [this R script](https://raw.github.com/ivanhanigan/disentangle/gh-pages/gantt-tj3/gantt-tj3-build.R) to convert a spreadsheet into an Orgmode script
  - the spreadsheet is organised in a fairly simple way shown below.
  
  ![alttext](/images/gantt-chart-sheet.png)
  
  ### Results
  - and executing my script will convert this into a Emacs orgmode file that will export to a taskjuggler file (use C-c C-e j) and viola!
  
  ![alttext](/images/gantt-chart.png)
  
  ### Conclusions
  
  - This simplifies the Orgmode taskjuggler creation
  - A drawback is that it has to go through the Emacs export function.
  
#+end_src

** 2014-03-29-project-templates-that-initialize-a-new-project-with-a-skeleton-automatically
** R-AdminTemplate
*** R-R-AdminTemplate
#+name:R-AdminTemplate
#+begin_src R :session *R* :tangle R/AdminTemplate.r :exports none :eval no
  ################################################################
  # name:R-AdminTemplate
  AdminTemplate <- function(rootdir = getwd()){
    setwd(rootdir)
    dir.create(file.path(rootdir,'01_planning'))
    dir.create(file.path(rootdir,'01_planning','proposal'))
    dir.create(file.path(rootdir,'01_planning','scheduling'))
    dir.create(file.path(rootdir,'02_budget'))
    dir.create(file.path(rootdir,'03_communication'))
    dir.create(file.path(rootdir,'04_reporting_and_meetings'))
    file.create(file.path(rootdir,'contact_details.txt'))
    file.create(file.path(rootdir,'README.md'))
    }
  
#+end_src
*** test-R-AdminTemplate
#+name:R-AdminTemplate
#+begin_src R :session *R* :tangle tests/test-R-AdminTemplate.r :exports none :eval no
  ################################################################
  # name:R-AdminTemplate
  setwd("~/Dropbox/Z_New_T_Drive/Resource Management/IT Infrastructure/PhenocamsAndImageryServer")
  AdminTemplate()
#+end_src
*** man-R-AdminTemplate
#+name:R-AdminTemplate
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:R-AdminTemplate

#+end_src

*** blog
#+name:project-templates-that-initialize-a-new-project-with-a-skeleton-automatically-header
#+begin_src R :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2014-03-29-project-templates-that-initialize-a-new-project-with-a-skeleton-automatically.md :exports none :eval no :padline no
  ---
  name: project-templates-that-initialize-a-new-project-with-a-skeleton-automatically
  layout: post
  title: Project Templates That Initialize A New Project With A Skeleton Automatically
  date: 2014-03-29
  categories:
  - research methods
  ---
  
  - I have been using [John Myles Whites ProjectTemplate R package](http://projecttemplate.net/) for ages
  - I really like the ease with which I can get up and running a new project
  - and the ease with which I can pick up an old project and start adding new work
    
  #### Quote from John's first post
      My inspiration for this approach comes from the rails command from
      Ruby on Rails, which initializes a new Rails project with the proper
      skeletal structure automatically. Also taken from Rails is
      ProjectTemplate’s approach of preferring convention over
      configuration: the automatic data and library loading as well as the
      automatic testing work out of the box because assumptions are made
      about the directory structure and naming conventions that will be used
  
  <p></p>
    
  [http://www.johnmyleswhite.com/notebook/2010/08/26/projecttemplate/](http://www.johnmyleswhite.com/notebook/2010/08/26/projecttemplate/)
  
  - I dont know anything about RoR but this philosophy works really well for my R programming too
  
  #### R Code
      if(!require(ProjectTemplate)) install.packages(ProjectTemplate); require(ProjectTemplate)
      setwd("~/projects")
      create.project("my-project")
      setwd('my-project')
      dir()
      ##  [1] "cache"       "config"      "data"        "diagnostics" "doc"        
      ##  [6] "graphs"      "lib"         "logs"        "munge"       "profiling"  
      ## [11] "README"      "reports"     "src"         "tests"       "TODO"   
      ##### these are very sensible default directories to create a modular
      ##### analysis workflow.  See the project homepage for descriptions
       
      # now all you need to do whenever you start a new day 
      load.project()
      # and your workspace will be recreated and any new data automagically analysed in
      # the manner you want
  
  <p></p>
  
  #### Project Administration
  
  - I;ve found that these directories do not work so well for the administration of my projects and so I put together a different set of automatic defaults
  - Ive based it on the [University of Manitoba Centre for Health Policy](http://ivanhanigan.github.io/2013/12/research-protocol-for-manitoba-centre-for-health-policy/)- along with some other sources I can recall
  #### The full set
      # A.Background        
      # B.Proposals 
      # C.Approvals 
      # D.Budget    
      # E.Datasets  
      # F.Analysis  
      # G.Literature        
      # H.Communication             
      # I.Correspondance    
      # J.Meetings  
      # K.Completion        
      # ContactDetails.txt  
      # README.md
      # TODO.txt    
  
  <p></p>
    
  #### R Code: my subset
      AdminTemplate <- function(rootdir = getwd()){
        setwd(rootdir)
        dir.create(file.path(rootdir,'01_planning'))
        dir.create(file.path(rootdir,'01_planning','proposal'))
        dir.create(file.path(rootdir,'01_planning','scheduling'))
        dir.create(file.path(rootdir,'02_budget'))
        dir.create(file.path(rootdir,'03_communication'))
        dir.create(file.path(rootdir,'04_reporting_and_meetings'))
        file.create(file.path(rootdir,'contact_details.txt'))
        file.create(file.path(rootdir,'README.md'))
        }
  
  <p></p>
  
  
  #### Conclusion
  
  - hopefully by formalising some of these into my workflow I will find my projects easier to navigate through
  - and pick up or put down as needed
#+end_src

* Research Protocols
** 2013-11-27-sharing-and-extending-research-protocols
#+name:sharing-and-extending-research-protocols-header
#+begin_src markdown :tangle ~/projects/ivanhanigan.github.com.raw/_posts/2013-11-27-sharing-and-extending-research-protocols.md :exports none :eval no :padline no
  ---   
  name: 2013-11-27-sharing-and-extending-research-protocols
  layout: post
  title: sharing-and-extending-research-protocols
  date: 2013-11-27
  categories:
  - research methods
  ---
  
  - Last week I started a new discussion about sharing and extending research protocols.
  
  #### My Colleague sent me a link to the [Prometheus Wiki](http://prometheuswiki.publish.csiro.au/tiki-custom_home.php)​
      a site for sharing research protocols. The idea is to give people
      a place to post research protocols since everyone develops them
      and then mentions them in papers but they rarely make it online in
      a usable format. We see this as a big bottleneck in the rate of
      knowledge discovery. Since users will always want to change and
      adapt a given protocol for changing applications or new technology
      or just to improve it. This sort of thing is done with open source
      all the time (i.e. git) but how you'd do it with an online
      protocol based out of a wiki is unknown. The current version of
      the website is not very flexible and doesn't really enable the
      sort of dynamic collaboration that I envision would make this a
      really useful tool. Git seems like an obvious conceptual starting
      point but there'd need to be a front end markup system in place
      that was integrated with that git-type backend. Since you've
      mentioned git a few times and the open science project, I thought
      you might find this interesting to think about. any suggestions or
      inspirations would be welcomed
  <p></p>
  #### My past experience
  
  - I have previously tried to use a wiki for the development of new sections in an existing study protocol on estimating the effects of bushfire smoke air pollution and human health.
  - We combined elements of two major air pollution/health study protocols (one from Europe, one from America) with local considerations and decisions made within our team.
  - On reflection all this was mostly useful for me, to a lesser extent the other programmer and I don't think the project manager or statistician ever even looked at any of this.
  
  #### Jeff Leek's current approach using GitHub
  
  I have been keeping an eye on the work by Jeff Leek on putting protocols onto Github and inviting collaboration to edit and extend them [as he says](http://simplystatistics.org/2013/10/07/the-leek-group-policy-for-developing-sustainable-r-packages/):
  
      I put it on Github because I'm still not 100% sure I got it
      right... I would welcome feedback/pull requests on how we can
      improve the policy to make it better
  
  <p></p>
  #### Leek Group policies and protocols on github so far
  
  - [https://github.com/jtleek/rpackages](https://github.com/jtleek/rpackages) accompanied by [this post](http://simplystatistics.org/2013/10/07/the-leek-group-policy-for-developing-sustainable-r-packages/)
  - [https://github.com/jtleek/reviews](https://github.com/jtleek/reviews) accompanied by [this post](http://simplystatistics.org/2013/10/23/the-leek-group-guide-to-reviewing-scientific-papers/)
  - [https://github.com/jtleek/datasharing](https://github.com/jtleek/datasharing) accompanied by [this post](http://simplystatistics.org/2013/11/14/the-leek-group-guide-to-sharing-data-with-a-statistician-to-speed-collaboration/)
  
  #### I forked "datasharing" for my own. Renamed: "How to share data to avoid misunderstanding"
  
  - I liked the datasharing policy so much [I forked it for my own collaborations](http://ivanhanigan.github.io/datasharing/).
  - I initially just made a minor recommendation to one of the lines in the original using the great Github feature that if you edit a repo you don't have access to, it forks the repo and creates a feature branch behind the scenes. After you submit the changes (which is a commit) it puts you right into the pull request form.
  - Therefore it can all be done on the GitHub site. I submitted [the pull request without leaving my web browser](https://github.com/jtleek/datasharing/pull/11).
  - But then I thought I would have done things a bit differently.  In particular I'd like a webpage with a table of contents, and a nicer looking landing page.
  - so I cloned my fork of the repo, then created a new branch called gh-pages, then copied the original to a new file called index.org, added some Emacs Orgmode HTML export magic and then "C-c C-e h" and WHAMM-O I've got my own version for extending with at [http://ivanhanigan.github.io/datasharing/](http://ivanhanigan.github.io/datasharing/).
  
  #### The code version:
      git clone git@github.com:ivanhanigan/datasharing.git ~/tools/datasharing
      cd ~/tools/datasharing
      git checkout -b gh-pages
      mv README.md index.org
      touch README.md
      # edits to index.org, "C-c C-e h" and WHAMM-O
      git add index.org index.html README.md
      git push origin gh-pages
  
  <p></p>
  
  - In this way I think people can share and collaborate easily [(if they know git)](http://yihui.name/en/2013/06/fix-typo-in-documentation/)
  - as well as easily take work started by someone else and extend it for their own work.
  - I wonder a little bit about how much of my extensions I should offer back to Jeff Leek as the original author.
  - I guess he can always track what I do to it via the link back to his original shown in [https://github.com/jtleek/datasharing/network](https://github.com/jtleek/datasharing/network)
  
  #### PS Jeff Leek uses github a lot!
  As he says in [this post from the future-of-statistics unconference](http://simplystatistics.org/2013/11/21/future-of-statistics-take-home-messages-futureofstats/):
  
      You can read it on Github here (https://github.com/jtleek/futureofstats).
      I put it on Github for two reasons:
       
      - I agree with Hadley's statement that the future of statistics is on Github.
      - I summarized them based on my interpretation and would love
        collaboration on the document. If you want to add your new
        thoughts/summaries, add a new section with your bullet pointed
        ideas and send me a pull request!
  <p></p>
  #### Conclusions
  
  - Jeff Leek is on to something really interesting with these github policies and protocols
  - I find the look of his plain markdown README.md pages a bit un-inspiring
  - but then I spend too much of my time tweaking my html by far (while Jeff is getting on with the real work of publishing papers)
  
  
  
  
  
  
  
  
  
  
  
#+end_src

* Operating Systems
* Linux - Ubuntu 
*** COMMENT TODO bash profile-code
#+name:bash profile
#+begin_src R :session *R* :tangle no :exports none :eval no
# put in ~/.bash_profile
# then source ~/.bash_profile
alias build_r="cd ~/tools/disentangle;git add .;git commit -m 'storage';git checkout master;git checkout gh-pages -- R/*;git add .;git commit -am 'Latest build.';git push;git checkout gh-pages"
alias br="build_r"
#+end_src

* Big Data Tips
* Writing
** COMMENT Review Template
\noindent{\textbf{ Background  }} 
- The main issue is 
- The author's question are about 
- It is important because 

\noindent{\textbf{ Method  }} 
- Data: 
- What outcome measures? What exposure measures?
- Do they deal with confounding variables?
- What data analysis approach? (Statistical? Simulation? Narrative?)
- Generalisability

\noindent{\textbf{ Results  }} 
- Do they show their data along with their models?
- Do they report all the details?

\noindent{\textbf{ Discussion}} 


\noindent{\textbf{ Principal findings  }} 
- What happened / what was found?
- Does the result of the analysis support the author's theory / question about the issue?

\noindent{\textbf{ Strengths  }} 
- Quality of data?
- Control of confounders?
- Do models use a robust accepted method?
- Is causality criteria addressed?

\noindent{\textbf{ Weaknesses  }} 
- Population size?
- Alternative exposure variables not included?

\noindent{\textbf{ Comparison with other studies  }} 
- How do these results compare with other studies?

\noindent{\textbf{ What do the results mean?  }} 
- What are the main unanswered questions?
- What are the implications for researchers in this field?

\noindent{\textbf{ What are the policy implications?  }} 
- Who in the policy community will read this?
- What main message will they take from this?
- What should they do?

\noindent{\textbf{ Conclusion }} 
- What are the main unanswered questions?
- What are the implications for researchers in this field?

\noindent{\textbf{ What are the policy implications? }} 
- Who in the policy community will read this?
- What main message will they take from this?
- What should they do?

\noindent{\textbf{ Conclusion }} 
- So what is the main 'take-home' message?
- How do you rate the paper overall?
